{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFn4MYfePl73",
    "outputId": "64055ed6-0939-424c-da19-4c42224f14c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\.conda\\envs\\mt_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: 800000 100000 100000\n",
      "🔄 Resuming from checkpoint: checkpoint_baseline.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_28892\\798033649.py:183: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded scaler state from checkpoint.\n",
      "Resumed from epoch 26, best val loss = 2.4229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30:   0%|                                                                        | 0/12500 [00:00<?, ?batch/s]C:\\Users\\Ayush\\.conda\\envs\\mt_env\\lib\\site-packages\\torch\\nn\\functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 27/30: 100%|████████████████████████████████████████████████████████████| 12500/12500 [13:56<00:00, 14.94batch/s]\n",
      "C:\\Users\\Ayush\\.conda\\envs\\mt_env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:502: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\NestedTensorImpl.cpp:180.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 1.5976 | Val Loss: 2.4865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|████████████████████████████████████████████████████████████| 12500/12500 [13:56<00:00, 14.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 1.5685 | Val Loss: 2.4935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|████████████████████████████████████████████████████████████| 12500/12500 [13:54<00:00, 14.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 1.5502 | Val Loss: 2.4999\n",
      "⏹️ Early stopping triggered.\n",
      "🎯 Training complete.\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Imports & Setup\n",
    "# =====================\n",
    "!pip install -q datasets sentencepiece sacrebleu torch torchvision torchaudio tqdm\n",
    "\n",
    "import os, random\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import sentencepiece as spm\n",
    "import sacrebleu\n",
    "\n",
    "# =====================\n",
    "# Config\n",
    "# =====================\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "VOCAB_SIZE = 16000\n",
    "BATCH_SIZE = 64\n",
    "MAX_LEN = 64\n",
    "MAX_GEN_LEN = 64\n",
    "EPOCHS = 30\n",
    "CLIP = 1.0\n",
    "LEARNING_RATE = 3e-4\n",
    "BEAM_SIZE = 5\n",
    "BEST_MODEL_PATH = Path(\"best_model_baseline.pt\")\n",
    "CHECKPOINT_PATH = Path(\"checkpoint_baseline.pt\")\n",
    "PATIENCE = 5  # early stopping patience\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# =====================\n",
    "# Load dataset (up to 1M)\n",
    "# =====================\n",
    "full_dataset = load_dataset(\"ai4bharat/samanantar\", \"hi\", split=\"train\")\n",
    "full_dataset = full_dataset.shuffle(seed=SEED)\n",
    "\n",
    "NUM_EXAMPLES = min(1_000_000, len(full_dataset))\n",
    "subset = full_dataset.select(range(NUM_EXAMPLES))\n",
    "\n",
    "# Split 80% train, 10% val, 10% test\n",
    "train_end = int(0.8 * len(subset))\n",
    "val_end = int(0.9 * len(subset))\n",
    "train_data = subset.select(range(0, train_end))\n",
    "val_data = subset.select(range(train_end, val_end))\n",
    "test_data = subset.select(range(val_end, len(subset)))\n",
    "\n",
    "print(\"Dataset sizes:\", len(train_data), len(val_data), len(test_data))\n",
    "\n",
    "# =====================\n",
    "# SentencePiece\n",
    "# =====================\n",
    "SP_EN_MODEL = Path(\"spm_en.model\")\n",
    "SP_HI_MODEL = Path(\"spm_hi.model\")\n",
    "\n",
    "def write_lines(dataset_split, src_path, tgt_path):\n",
    "    with open(src_path, \"w\", encoding=\"utf-8\") as sf, open(tgt_path, \"w\", encoding=\"utf-8\") as tf:\n",
    "        for ex in dataset_split:\n",
    "            sf.write(ex[\"src\"].strip().lower() + \"\\n\")\n",
    "            tf.write(ex[\"tgt\"].strip() + \"\\n\")\n",
    "\n",
    "write_lines(train_data, \"train.en\", \"train.hi\")\n",
    "\n",
    "if not SP_EN_MODEL.exists() or not SP_HI_MODEL.exists():\n",
    "    print(\"Training SentencePiece...\")\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f\"--input=train.en --model_prefix=spm_en --vocab_size={VOCAB_SIZE} \"\n",
    "        f\"--character_coverage=1.0 --model_type=unigram\"\n",
    "    )\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f\"--input=train.hi --model_prefix=spm_hi --vocab_size={VOCAB_SIZE} \"\n",
    "        f\"--character_coverage=0.9995 --model_type=unigram\"\n",
    "    )\n",
    "\n",
    "sp_en = spm.SentencePieceProcessor()\n",
    "sp_hi = spm.SentencePieceProcessor()\n",
    "sp_en.load(str(SP_EN_MODEL))\n",
    "sp_hi.load(str(SP_HI_MODEL))\n",
    "\n",
    "PAD_EN, BOS_EN, EOS_EN = 0, 1, 2\n",
    "PAD_HI, BOS_HI, EOS_HI = 0, 1, 2\n",
    "\n",
    "# =====================\n",
    "# Dataset & DataLoader\n",
    "# =====================\n",
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, dataset, src_sp, tgt_sp, max_len=MAX_LEN):\n",
    "        self.dataset = dataset\n",
    "        self.src_sp = src_sp\n",
    "        self.tgt_sp = tgt_sp\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_text = self.dataset[idx][\"src\"].lower()\n",
    "        tgt_text = self.dataset[idx][\"tgt\"]\n",
    "        src_ids = [BOS_EN] + self.src_sp.encode(src_text)[:self.max_len-2] + [EOS_EN]\n",
    "        tgt_ids = [BOS_HI] + self.tgt_sp.encode(tgt_text)[:self.max_len-2] + [EOS_HI]\n",
    "        src_ids += [PAD_EN] * (self.max_len - len(src_ids))\n",
    "        tgt_ids += [PAD_HI] * (self.max_len - len(tgt_ids))\n",
    "        return torch.tensor(src_ids), torch.tensor(tgt_ids)\n",
    "\n",
    "def get_loader(dataset_split, shuffle=True):\n",
    "    return DataLoader(NMTDataset(dataset_split, sp_en, sp_hi),\n",
    "                      batch_size=BATCH_SIZE, shuffle=shuffle)\n",
    "\n",
    "train_loader = get_loader(train_data)\n",
    "val_loader = get_loader(val_data)\n",
    "test_loader = get_loader(test_data, shuffle=False)\n",
    "\n",
    "# =====================\n",
    "# Masks\n",
    "# =====================\n",
    "def create_padding_mask(seq, lang='en'):\n",
    "    pad_id = PAD_EN if lang == 'en' else PAD_HI\n",
    "    return (seq == pad_id)\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    return torch.triu(torch.ones(sz, sz, device=DEVICE) * float('-inf'), diagonal=1)\n",
    "\n",
    "# =====================\n",
    "# Transformer Model\n",
    "# =====================\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=512, nhead=8,\n",
    "                 num_layers=3, dim_feedforward=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab, d_model, padding_idx=PAD_EN)\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab, d_model, padding_idx=PAD_HI)\n",
    "        self.pos_enc = nn.Parameter(torch.zeros(1, MAX_LEN, d_model))\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            num_encoder_layers=num_layers, num_decoder_layers=num_layers,\n",
    "            dim_feedforward=dim_feedforward, dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab)\n",
    "\n",
    "    def encode(self, src, src_key_padding_mask):\n",
    "        src_emb = self.src_emb(src) + self.pos_enc[:, :src.size(1), :]\n",
    "        return self.transformer.encoder(src_emb, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask):\n",
    "        tgt_emb = self.tgt_emb(tgt) + self.pos_enc[:, :tgt.size(1), :]\n",
    "        return self.transformer.decoder(\n",
    "            tgt_emb, memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_key_padding_mask=memory_key_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None,\n",
    "                memory_key_padding_mask=None, tgt_mask=None):\n",
    "        memory = self.encode(src, src_key_padding_mask)\n",
    "        output = self.decode(tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask)\n",
    "        return self.fc_out(output)\n",
    "\n",
    "# =====================\n",
    "# Training Setup\n",
    "# =====================\n",
    "model = TransformerModel(len(sp_en), len(sp_hi)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_HI)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=LEARNING_RATE, steps_per_epoch=len(train_loader), epochs=EPOCHS\n",
    ")\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "# ---- Resume if checkpoint exists ----\n",
    "start_epoch = 1\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    print(f\"🔄 Resuming from checkpoint: {CHECKPOINT_PATH}\")\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "    # Handle optional scaler\n",
    "    if \"scaler_state_dict\" in checkpoint:\n",
    "        scaler.load_state_dict(checkpoint[\"scaler_state_dict\"])\n",
    "        print(\"✅ Loaded scaler state from checkpoint.\")\n",
    "    else:\n",
    "        print(\"⚠️ No scaler state found in checkpoint — continuing without it.\")\n",
    "    start_epoch = checkpoint.get(\"epoch\", 0) + 1\n",
    "    best_val_loss = checkpoint.get(\"best_val_loss\", float(\"inf\"))\n",
    "    epochs_no_improve = checkpoint.get(\"epochs_no_improve\", 0)\n",
    "    print(f\"Resumed from epoch {start_epoch-1}, best val loss = {best_val_loss:.4f}\")\n",
    "\n",
    "# =====================\n",
    "# Training Loop\n",
    "# =====================\n",
    "for epoch in range(start_epoch, EPOCHS + 1):\n",
    "    # ---- Train ----\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for src, tgt in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\", unit=\"batch\"):\n",
    "        src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "        src_mask = create_padding_mask(src, 'en')\n",
    "        tgt_input, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "        tgt_mask = generate_square_subsequent_mask(tgt_input.size(1))\n",
    "        tgt_key_padding_mask = create_padding_mask(tgt_input, 'hi')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type=\"cuda\"):\n",
    "            logits = model(\n",
    "                src, tgt_input,\n",
    "                src_key_padding_mask=src_mask,\n",
    "                tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                memory_key_padding_mask=src_mask,\n",
    "                tgt_mask=tgt_mask\n",
    "            )\n",
    "            loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in val_loader:\n",
    "            src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "            src_mask = create_padding_mask(src, 'en')\n",
    "            tgt_input, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "            tgt_mask = generate_square_subsequent_mask(tgt_input.size(1))\n",
    "            tgt_key_padding_mask = create_padding_mask(tgt_input, 'hi')\n",
    "\n",
    "            logits = model(\n",
    "                src, tgt_input,\n",
    "                src_key_padding_mask=src_mask,\n",
    "                tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                memory_key_padding_mask=src_mask,\n",
    "                tgt_mask=tgt_mask\n",
    "            )\n",
    "            loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # ---- Save Checkpoint ----\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "        \"scaler_state_dict\": scaler.state_dict(),\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "        \"epochs_no_improve\": epochs_no_improve,\n",
    "    }, CHECKPOINT_PATH)\n",
    "\n",
    "    # ---- Early Stopping ----\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        print(\"✅ New best model saved!\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(\"⏹️ Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"🎯 Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmTpXAxePl7_",
    "outputId": "c99d3aa8-7a7c-46d6-fbe6-e6ccf3fb6589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Full checkpoint saved as 'checkpoint_baseline.pt'\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Save Full Checkpoint\n",
    "# =====================\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'scheduler_state_dict': scheduler.state_dict(),\n",
    "    'best_val_loss': best_val_loss,\n",
    "    'config': {\n",
    "        'VOCAB_SIZE': VOCAB_SIZE,\n",
    "        'MAX_LEN': MAX_LEN,\n",
    "        'EPOCHS': EPOCHS,\n",
    "        'LEARNING_RATE': LEARNING_RATE,\n",
    "        'CLIP': CLIP,\n",
    "        'BATCH_SIZE': BATCH_SIZE\n",
    "    }\n",
    "}, \"checkpoint_baseline.pt\")\n",
    "\n",
    "print(\"✅ Full checkpoint saved as 'checkpoint_baseline.pt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZ-pZJCEPl8A",
    "outputId": "3abad2c1-7877-436b-dbe3-cd45635c305c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Config saved to config.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "config = {\n",
    "    \"VOCAB_SIZE\": VOCAB_SIZE,\n",
    "    \"MAX_LEN\": MAX_LEN,\n",
    "    \"EPOCHS\": EPOCHS,\n",
    "    \"LEARNING_RATE\": LEARNING_RATE,\n",
    "    \"CLIP\": CLIP,\n",
    "    \"BATCH_SIZE\": BATCH_SIZE,\n",
    "    \"DEVICE\": DEVICE\n",
    "}\n",
    "\n",
    "with open(\"config.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "print(\"✅ Config saved to config.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bT0fKEzjPl8B",
    "outputId": "6321463a-0aab-42c3-b33b-c4a202d7ea1e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_28892\\2853380784.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded best model for evaluation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 1563/1563 [09:34<00:00,  2.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌍 Test BLEU score: 8.58\n",
      "\n",
      "🔍 Sample Translations:\n",
      "\n",
      "EN: Its movement was captured on CCTV.\n",
      "HI (Reference): उनकी यह हरकत सीसीटीवी में कैद हो गई।\n",
      "HI (Predicted): यह सीसीटीवी में कैद हो गया।\n",
      "--------------------------------------------------\n",
      "\n",
      "EN: \"The two leaders \"\"discussed bilateral ties, including development partnership and cooperation in counter-terrorism and international fora,\"\" he said in the tweet.\"\n",
      "HI (Reference): ट्वीट में उन्होंने कहा कि दोनों नेताओं ने ‘‘विकास साझेदारी और आतंकवाद के खिलाफ तथा अंतरराष्ट्रीय मंचों पर सहयोग समेत द्विपक्षीय संबंधों’’ पर चर्चा की।\n",
      "HI (Predicted): उन्होंने ट्वीट किया, ‘‘दोनों नेताओं ने द्विपक्षीय संबंधों को तोड़ा, जिसमें विकास साझेदारी और आतंकवाद विरोधी और अंतर्राष्‍ट्रीय मंचों पर सहयोग शामिल हैं।\n",
      "--------------------------------------------------\n",
      "\n",
      "EN: These are Allahabad Bank, United Bank of India, Corporation Bank, IDBI Bank, Uco Bank, Bank of India, Central Bank of India, Indian Overseas Bank, Oriental Bank of Commerce, Dena Bank and Bank of Maharashtra.\n",
      "HI (Reference): देना बैंक, इलाहाबाद बैंक, यूनाइटेड बैंक ऑफ इंडिया, कॉरपोरेशन बैंक, आईडीबीआई बैंक, यूको बैंक, बैंक ऑफ इंडिया, सेंट्रल बैंक ऑफ इंडिया, इंडियन ओवरसीज बैंक, ओरिएंटल बैंक ऑफ कॉमर्स और बैंक ऑफ महाराष्ट्र।\n",
      "HI (Predicted): ये हैं- बैंक ऑफ इंडिया, ओरिएंटल बैंक ऑफ कॉमर्स, बैंक ऑफ इंडिया, आईडीबीआई बैंक, यूको बैंक, सेंट्रल बैंक ऑफ इंडिया, इंडियन ओवरसीज बैंक, ओरियंटल बैंक ऑफ कॉमर्स, देना बैंक ऑफ महाराष्ट्र।\n",
      "--------------------------------------------------\n",
      "\n",
      "EN: Those who remember Allah standing, sitting, and lying on their sides, and reflect on the creation of the heavens and the earth [and say], Our Lord, You have not created this in vain! Immaculate are You! Save us from the punishment of the Fire.\n",
      "HI (Reference): जो लोग उठते बैठते करवट लेते (अलगरज़ हर हाल में) ख़ुदा का ज़िक्र करते हैं और आसमानों और ज़मीन की बनावट में ग़ौर व फ़िक्र करते हैं और (बेसाख्ता) कह उठते हैं कि ख़ुदावन्दा तूने इसको बेकार पैदा नहीं किया तू (फेले अबस से) पाक व पाकीज़ा है बस हमको दोज़क के अज़ाब से बचा\n",
      "HI (Predicted): जो लोग अल्लाह की ओर खड़े हुए बैठे हैं और अपने किनारों पर झूठ बोलते हैं और आकाशों और धरती की संरचना पर प्रतिबिंबित होते हैं, और तुम हमारा रब हमने इस व्यर्थता को पैदा नहीं किया। तुम तो हम पर आग की यातना से बच गए\n",
      "--------------------------------------------------\n",
      "\n",
      "EN: I am not scared of them.\n",
      "HI (Reference): मैं उनकी धमकियों से डरने वाली नहीं हूं।\n",
      "HI (Predicted): मैं उनसे डर नहीं रहा हूं।\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# ✅ Evaluation on Test Set\n",
    "# =====================\n",
    "from torch.nn.functional import log_softmax\n",
    "import math\n",
    "\n",
    "# ---- Load best model ----\n",
    "model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "print(\"✅ Loaded best model for evaluation.\")\n",
    "\n",
    "# =====================\n",
    "# Greedy Decoding\n",
    "# =====================\n",
    "def greedy_decode(model, src, max_len=MAX_GEN_LEN):\n",
    "    model.eval()\n",
    "    src_mask = create_padding_mask(src, 'en')\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.full((src.size(0), 1), BOS_HI, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    for i in range(max_len - 1):\n",
    "        tgt_mask = generate_square_subsequent_mask(ys.size(1))\n",
    "        tgt_key_padding_mask = create_padding_mask(ys, 'hi')\n",
    "\n",
    "        out = model.decode(\n",
    "            ys, memory, tgt_mask=tgt_mask,\n",
    "            memory_key_padding_mask=src_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "        out = model.fc_out(out[:, -1, :])\n",
    "        next_word = out.argmax(dim=-1, keepdim=True)\n",
    "        ys = torch.cat([ys, next_word], dim=1)\n",
    "\n",
    "        # Stop if EOS is reached for all\n",
    "        if torch.all(next_word.squeeze() == EOS_HI):\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# =====================\n",
    "# Beam Search Decoding\n",
    "# =====================\n",
    "def beam_search_decode(model, src, beam_size=BEAM_SIZE, max_len=MAX_GEN_LEN):\n",
    "    model.eval()\n",
    "    src_mask = create_padding_mask(src, 'en')\n",
    "    memory = model.encode(src, src_mask)\n",
    "\n",
    "    batch_size = src.size(0)\n",
    "    results = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        beams = [(torch.tensor([[BOS_HI]], device=DEVICE), 0.0)]\n",
    "        for _ in range(max_len - 1):\n",
    "            new_beams = []\n",
    "            for seq, score in beams:\n",
    "                if seq[0, -1].item() == EOS_HI:\n",
    "                    new_beams.append((seq, score))\n",
    "                    continue\n",
    "\n",
    "                tgt_mask = generate_square_subsequent_mask(seq.size(1))\n",
    "                tgt_key_padding_mask = create_padding_mask(seq, 'hi')\n",
    "                out = model.decode(\n",
    "                    seq, memory[i:i+1],\n",
    "                    tgt_mask=tgt_mask,\n",
    "                    memory_key_padding_mask=src_mask[i:i+1],\n",
    "                    tgt_key_padding_mask=tgt_key_padding_mask\n",
    "                )\n",
    "                logits = model.fc_out(out[:, -1, :])\n",
    "                log_probs = log_softmax(logits, dim=-1)\n",
    "                topk_log_probs, topk_indices = torch.topk(log_probs, beam_size)\n",
    "\n",
    "                for k in range(beam_size):\n",
    "                    next_seq = torch.cat([seq, topk_indices[:, k].unsqueeze(1)], dim=1)\n",
    "                    new_beams.append((next_seq, score + topk_log_probs[0, k].item()))\n",
    "\n",
    "            beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_size]\n",
    "\n",
    "            if all(seq[0, -1].item() == EOS_HI for seq, _ in beams):\n",
    "                break\n",
    "\n",
    "        best_seq = beams[0][0]\n",
    "        results.append(best_seq)\n",
    "    return results\n",
    "\n",
    "\n",
    "# =====================\n",
    "# Evaluate BLEU on Test Set\n",
    "# =====================\n",
    "references, hypotheses = [], []\n",
    "for batch_idx, (src, tgt) in enumerate(tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\")):\n",
    "    src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        pred = greedy_decode(model, src)\n",
    "    for i in range(src.size(0)):\n",
    "        tgt_tokens = tgt[i].tolist()\n",
    "        pred_tokens = pred[i].tolist()\n",
    "\n",
    "        tgt_text = sp_hi.decode([t for t in tgt_tokens if t not in [PAD_HI, BOS_HI, EOS_HI]])\n",
    "        pred_text = sp_hi.decode([t for t in pred_tokens if t not in [PAD_HI, BOS_HI, EOS_HI]])\n",
    "\n",
    "        references.append([tgt_text])\n",
    "        hypotheses.append(pred_text)\n",
    "\n",
    "# ---- Compute BLEU ----\n",
    "bleu = sacrebleu.corpus_bleu(hypotheses, list(zip(*references)))\n",
    "print(f\"🌍 Test BLEU score: {bleu.score:.2f}\")\n",
    "\n",
    "# =====================\n",
    "# Show Some Examples\n",
    "# =====================\n",
    "print(\"\\n🔍 Sample Translations:\")\n",
    "for i in range(5):\n",
    "    src_ids, tgt_ids = test_data[i][\"src\"], test_data[i][\"tgt\"]\n",
    "    src_tensor = torch.tensor([[BOS_EN] + sp_en.encode(src_ids.lower())[:MAX_LEN-2] + [EOS_EN]], device=DEVICE)\n",
    "    pred = greedy_decode(model, src_tensor)\n",
    "    pred_tokens = pred[0].tolist()\n",
    "    pred_text = sp_hi.decode([t for t in pred_tokens if t not in [PAD_HI, BOS_HI, EOS_HI]])\n",
    "\n",
    "    print(f\"\\nEN: {test_data[i]['src']}\")\n",
    "    print(f\"HI (Reference): {test_data[i]['tgt']}\")\n",
    "    print(f\"HI (Predicted): {pred_text}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rkOiMjxPl8D",
    "outputId": "9ef64c73-dd9e-4994-dda1-dbac2db55e2c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\.conda\\envs\\mt_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: 800000 100000 100000\n",
      "🔁 Resuming from checkpoint_cnn.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_13800\\227662617.py:206: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Checkpoint loaded — Resuming from epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30:   0%|                                                                        | 0/12500 [00:00<?, ?batch/s]C:\\Users\\Ayush\\.conda\\envs\\mt_env\\lib\\site-packages\\torch\\nn\\functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 23/30: 100%|████████████████████████████████████████████████████████████| 12500/12500 [12:50<00:00, 16.22batch/s]\n",
      "C:\\Users\\Ayush\\.conda\\envs\\mt_env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:502: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\NestedTensorImpl.cpp:180.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 1.5992 | Val Loss: 2.4764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|████████████████████████████████████████████████████████████| 12500/12500 [12:51<00:00, 16.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 1.5465 | Val Loss: 2.4910\n",
      "⏹️ Early stopping triggered.\n",
      "🎯 Training complete.\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Imports & Setup\n",
    "# =====================\n",
    "!pip install -q datasets sentencepiece sacrebleu torch torchvision torchaudio tqdm\n",
    "\n",
    "import os, random\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import sentencepiece as spm\n",
    "import sacrebleu\n",
    "\n",
    "# =====================\n",
    "# Config\n",
    "# =====================\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "VOCAB_SIZE = 16000\n",
    "BATCH_SIZE = 64\n",
    "MAX_LEN = 64\n",
    "MAX_GEN_LEN = 64\n",
    "EPOCHS = 30\n",
    "CLIP = 1.0\n",
    "LEARNING_RATE = 3e-4\n",
    "BEAM_SIZE = 5\n",
    "BEST_MODEL_PATH = Path(\"best_model_cnn.pt\")\n",
    "CHECKPOINT_PATH = Path(\"checkpoint_cnn.pt\")\n",
    "PATIENCE = 5\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# =====================\n",
    "# Load dataset (up to 1M)\n",
    "# =====================\n",
    "full_dataset = load_dataset(\"ai4bharat/samanantar\", \"hi\", split=\"train\")\n",
    "full_dataset = full_dataset.shuffle(seed=SEED)\n",
    "\n",
    "NUM_EXAMPLES = min(1_000_000, len(full_dataset))\n",
    "subset = full_dataset.select(range(NUM_EXAMPLES))\n",
    "\n",
    "# Split 80/10/10\n",
    "train_end = int(0.8 * len(subset))\n",
    "val_end = int(0.9 * len(subset))\n",
    "train_data = subset.select(range(0, train_end))\n",
    "val_data = subset.select(range(train_end, val_end))\n",
    "test_data = subset.select(range(val_end, len(subset)))\n",
    "\n",
    "print(\"Dataset sizes:\", len(train_data), len(val_data), len(test_data))\n",
    "\n",
    "# =====================\n",
    "# SentencePiece\n",
    "# =====================\n",
    "SP_EN_MODEL = Path(\"spm_en.model\")\n",
    "SP_HI_MODEL = Path(\"spm_hi.model\")\n",
    "\n",
    "def write_lines(dataset_split, src_path, tgt_path):\n",
    "    with open(src_path, \"w\", encoding=\"utf-8\") as sf, open(tgt_path, \"w\", encoding=\"utf-8\") as tf:\n",
    "        for ex in dataset_split:\n",
    "            sf.write(ex[\"src\"].strip().lower() + \"\\n\")\n",
    "            tf.write(ex[\"tgt\"].strip() + \"\\n\")\n",
    "\n",
    "write_lines(train_data, \"train.en\", \"train.hi\")\n",
    "\n",
    "if not SP_EN_MODEL.exists() or not SP_HI_MODEL.exists():\n",
    "    print(\"Training SentencePiece...\")\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f\"--input=train.en --model_prefix=spm_en --vocab_size={VOCAB_SIZE} \"\n",
    "        f\"--character_coverage=1.0 --model_type=unigram\"\n",
    "    )\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f\"--input=train.hi --model_prefix=spm_hi --vocab_size={VOCAB_SIZE} \"\n",
    "        f\"--character_coverage=0.9995 --model_type=unigram\"\n",
    "    )\n",
    "\n",
    "sp_en = spm.SentencePieceProcessor()\n",
    "sp_hi = spm.SentencePieceProcessor()\n",
    "sp_en.load(str(SP_EN_MODEL))\n",
    "sp_hi.load(str(SP_HI_MODEL))\n",
    "\n",
    "PAD_EN, BOS_EN, EOS_EN = 0, 1, 2\n",
    "PAD_HI, BOS_HI, EOS_HI = 0, 1, 2\n",
    "\n",
    "# =====================\n",
    "# Dataset & DataLoader\n",
    "# =====================\n",
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, dataset, src_sp, tgt_sp, max_len=MAX_LEN):\n",
    "        self.dataset = dataset\n",
    "        self.src_sp = src_sp\n",
    "        self.tgt_sp = tgt_sp\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_text = self.dataset[idx][\"src\"].lower()\n",
    "        tgt_text = self.dataset[idx][\"tgt\"]\n",
    "        src_ids = [BOS_EN] + self.src_sp.encode(src_text)[:self.max_len-2] + [EOS_EN]\n",
    "        tgt_ids = [BOS_HI] + self.tgt_sp.encode(tgt_text)[:self.max_len-2] + [EOS_HI]\n",
    "        src_ids += [PAD_EN] * (self.max_len - len(src_ids))\n",
    "        tgt_ids += [PAD_HI] * (self.max_len - len(tgt_ids))\n",
    "        return torch.tensor(src_ids), torch.tensor(tgt_ids)\n",
    "\n",
    "def get_loader(dataset_split, shuffle=True):\n",
    "    return DataLoader(NMTDataset(dataset_split, sp_en, sp_hi),\n",
    "                      batch_size=BATCH_SIZE, shuffle=shuffle)\n",
    "\n",
    "train_loader = get_loader(train_data)\n",
    "val_loader = get_loader(val_data)\n",
    "test_loader = get_loader(test_data, shuffle=False)\n",
    "\n",
    "# =====================\n",
    "# Masks\n",
    "# =====================\n",
    "def create_padding_mask(seq, lang='en'):\n",
    "    pad_id = PAD_EN if lang == 'en' else PAD_HI\n",
    "    return (seq == pad_id)\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    return torch.triu(torch.ones(sz, sz, device=DEVICE) * float('-inf'), diagonal=1)\n",
    "\n",
    "# =====================\n",
    "# CNN Feature Extractor (2-layer)\n",
    "# =====================\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(embed_dim, embed_dim, kernel_size=5, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(embed_dim, embed_dim, kernel_size=3, padding=1)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        return self.norm(x + residual)\n",
    "\n",
    "# =====================\n",
    "# Hybrid CNN + Transformer Model\n",
    "# =====================\n",
    "class HybridTransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=512, nhead=8,\n",
    "                 num_layers=3, dim_feedforward=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab, d_model, padding_idx=PAD_EN)\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab, d_model, padding_idx=PAD_HI)\n",
    "        self.pos_enc = nn.Parameter(torch.zeros(1, MAX_LEN, d_model))\n",
    "        self.cnn_encoder = CNNFeatureExtractor(d_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            num_encoder_layers=num_layers, num_decoder_layers=num_layers,\n",
    "            dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab)\n",
    "\n",
    "    def encode(self, src, src_key_padding_mask):\n",
    "        src_emb = self.src_emb(src) + self.pos_enc[:, :src.size(1), :]\n",
    "        src_cnn = self.cnn_encoder(src_emb)\n",
    "        return self.transformer.encoder(src_cnn, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask):\n",
    "        tgt_emb = self.tgt_emb(tgt) + self.pos_enc[:, :tgt.size(1), :]\n",
    "        return self.transformer.decoder(\n",
    "            tgt_emb, memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_key_padding_mask=memory_key_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None,\n",
    "                memory_key_padding_mask=None, tgt_mask=None):\n",
    "        memory = self.encode(src, src_key_padding_mask)\n",
    "        output = self.decode(tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask)\n",
    "        return self.fc_out(output)\n",
    "\n",
    "# =====================\n",
    "# Training Setup\n",
    "# =====================\n",
    "model = HybridTransformerModel(len(sp_en), len(sp_hi)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_HI)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=LEARNING_RATE, steps_per_epoch=len(train_loader), epochs=EPOCHS\n",
    ")\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "start_epoch = 1\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# =====================\n",
    "# Resume from Checkpoint (if available)\n",
    "# =====================\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    print(f\"🔁 Resuming from {CHECKPOINT_PATH}...\")\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_val_loss = checkpoint['best_val_loss']\n",
    "    epochs_no_improve = checkpoint['epochs_no_improve']\n",
    "\n",
    "    print(f\"✅ Checkpoint loaded — Resuming from epoch {start_epoch}\")\n",
    "else:\n",
    "    print(\"🚀 Starting training from scratch\")\n",
    "\n",
    "# =====================\n",
    "# Training Loop\n",
    "# =====================\n",
    "for epoch in range(start_epoch, EPOCHS + 1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for src, tgt in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\", unit=\"batch\"):\n",
    "        src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "        src_mask = create_padding_mask(src, 'en')\n",
    "        tgt_input, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "        tgt_mask = generate_square_subsequent_mask(tgt_input.size(1))\n",
    "        tgt_key_padding_mask = create_padding_mask(tgt_input, 'hi')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type=\"cuda\"):\n",
    "            logits = model(\n",
    "                src, tgt_input,\n",
    "                src_key_padding_mask=src_mask,\n",
    "                tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                memory_key_padding_mask=src_mask,\n",
    "                tgt_mask=tgt_mask\n",
    "            )\n",
    "            loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in val_loader:\n",
    "            src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "            src_mask = create_padding_mask(src, 'en')\n",
    "            tgt_input, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "            tgt_mask = generate_square_subsequent_mask(tgt_input.size(1))\n",
    "            tgt_key_padding_mask = create_padding_mask(tgt_input, 'hi')\n",
    "\n",
    "            logits = model(\n",
    "                src, tgt_input,\n",
    "                src_key_padding_mask=src_mask,\n",
    "                tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                memory_key_padding_mask=src_mask,\n",
    "                tgt_mask=tgt_mask\n",
    "            )\n",
    "            loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # ---- Save Checkpoint ----\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "        \"scaler_state_dict\": scaler.state_dict(),\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "        \"epochs_no_improve\": epochs_no_improve,\n",
    "        \"config\": {\n",
    "            \"MODEL_TYPE\": \"HybridCNNTransformer\",\n",
    "            \"VOCAB_SIZE\": VOCAB_SIZE,\n",
    "            \"MAX_LEN\": MAX_LEN,\n",
    "            \"EPOCHS\": EPOCHS,\n",
    "            \"LEARNING_RATE\": LEARNING_RATE,\n",
    "            \"CLIP\": CLIP,\n",
    "            \"BATCH_SIZE\": BATCH_SIZE\n",
    "        }\n",
    "    }, CHECKPOINT_PATH)\n",
    "\n",
    "    # ---- Early Stopping ----\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        print(\"✅ New best model saved!\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(\"⏹️ Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"🎯 Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbdHuTG-Pl8H",
    "outputId": "0c1a6b74-cdc2-4478-f436-d436a2f0412a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_13800\\3408616981.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model_cnn.pt\", map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Evaluating BLEU on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████| 1563/1563 [1:49:34<00:00,  4.21s/batch]\n",
      "That's 100 lines that end in a tokenized period ('.')\n",
      "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌍 BLEU Score on Test Set: 19.00\n",
      "\n",
      "✨ Sample Translations:\n",
      "\n",
      "EN: lahore: The Pakistan English press has showered heap of praise on legendary Indian batsman Sachin Tendulkar in their editorials, saying the game of cricket will surely be poorer without him.\n",
      "HI (Ref): लाहौर पाकिस्तान की अग्रेंजी प्रेस ने अपने संपादकीय में महान भारतीय बल्लेबाज सचिन तेंदुलकर की तारीफों के पुल बांधे है और लिखा है, ‘उनके बिना क्रिकेट खेल निश्चित रूप से दरिद्र’ हो जायेगा। हालांकि उर्दू प्रेस में उनके बारे में ज्यादा कुछ नहीं लिखा गया है लेकिन अंग्रेजी के अखबारों ने तेंदुलकर... आगे पढ़े\n",
      "HI (Pred): पाकिस्तान के इंग्लिश प्रीमियर लीग (एआईसीसी) के प्रख्यात बल्लेबाज सचिन तेंदुलकर ने अपने संपादकीय में कहा है कि क्रिकेट का खेल निश्चित रूप से उनके बिना सबसे बड़ा होगा।\n",
      "--------------------------------------------------\n",
      "\n",
      "EN: Telecom operator Reliance Jio has announced a new plan for its prepaid customers.\n",
      "HI (Ref): टेलीकॉम इंडस्ट्री में तहलका मचने वाली कंपनी रिलायंस जियो ने फिर से अपने ग्राहकों के लिए नए प्लान्स पेश किये\n",
      "HI (Pred): टेलीकॉम ऑपरेटर रिलायंस जियो ने अपने प्रीपेड ग्राहकों के लिए नया प्लान लॉन्च कर दिया है।\n",
      "--------------------------------------------------\n",
      "\n",
      "EN: Meanwhile, the police have initiated the investigation after the arrest of two persons.\n",
      "HI (Ref): फिलहाल पुलिस ने दो लोगों को हिरासत में लेकर पूछताछ शुरू कर दी है।\n",
      "HI (Pred): वहीं पुलिस ने दो लोगों की गिरफ्तारी के बाद जांच शुरू कर दी है।\n",
      "--------------------------------------------------\n",
      "\n",
      "EN: New Delhi, September 2\n",
      "HI (Ref): नयी दिल्ली, 2 सितंबर (भाषा)।\n",
      "HI (Pred): नयी दिल्ली, 2 सितंबर (एजेंसी)\n",
      "--------------------------------------------------\n",
      "\n",
      "EN: Below them is seated a scribe recording the interpretation.\n",
      "HI (Ref): इसे नीचे बैठा लिपिक लिपिबद्ध कर रहा है।\n",
      "HI (Pred): नीचे दिए गए एक लेखक की व्याख्या का रिकार्ड है।\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# BLEU Evaluation + Translation\n",
    "# =====================\n",
    "import torch\n",
    "import sacrebleu\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Load SentencePiece models again (if running separately)\n",
    "sp_en = spm.SentencePieceProcessor()\n",
    "sp_hi = spm.SentencePieceProcessor()\n",
    "sp_en.load(\"spm_en.model\")\n",
    "sp_hi.load(\"spm_hi.model\")\n",
    "\n",
    "PAD_EN, BOS_EN, EOS_EN = 0, 1, 2\n",
    "PAD_HI, BOS_HI, EOS_HI = 0, 1, 2\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Reload the best model\n",
    "model = HybridTransformerModel(len(sp_en), len(sp_hi)).to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"best_model_cnn.pt\", map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# =====================\n",
    "# Greedy / Beam Decoding\n",
    "# =====================\n",
    "@torch.no_grad()\n",
    "def translate_sentence(sentence, model, sp_en, sp_hi, max_len=64, beam_size=5):\n",
    "    model.eval()\n",
    "    src_ids = [BOS_EN] + sp_en.encode(sentence.lower())[:max_len-2] + [EOS_EN]\n",
    "    src = torch.tensor(src_ids, dtype=torch.long, device=DEVICE).unsqueeze(0)\n",
    "    src_mask = create_padding_mask(src, 'en')\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "\n",
    "    # ---- Start with BOS token ----\n",
    "    tgt = torch.tensor([[BOS_HI]], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        tgt_mask = generate_square_subsequent_mask(tgt.size(1))\n",
    "        tgt_key_padding_mask = create_padding_mask(tgt, 'hi')\n",
    "\n",
    "        output = model.decode(\n",
    "            tgt, memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_key_padding_mask=src_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "        logits = model.fc_out(output[:, -1, :])\n",
    "        next_token = logits.argmax(-1).item()\n",
    "\n",
    "        tgt = torch.cat([tgt, torch.tensor([[next_token]], device=DEVICE)], dim=1)\n",
    "        if next_token == EOS_HI:\n",
    "            break\n",
    "\n",
    "    decoded = sp_hi.decode([t for t in tgt.squeeze().tolist() if t not in [BOS_HI, EOS_HI, PAD_HI]])\n",
    "    return decoded\n",
    "\n",
    "\n",
    "# =====================\n",
    "# BLEU Evaluation\n",
    "# =====================\n",
    "refs, hyps = [], []\n",
    "\n",
    "print(\"🔍 Evaluating BLEU on test set...\")\n",
    "for src, tgt in tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\"):\n",
    "    src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "    for i in range(src.size(0)):\n",
    "        src_text = sp_en.decode([t for t in src[i].tolist() if t not in [BOS_EN, EOS_EN, PAD_EN]])\n",
    "        tgt_text = sp_hi.decode([t for t in tgt[i].tolist() if t not in [BOS_HI, EOS_HI, PAD_HI]])\n",
    "        pred_text = translate_sentence(src_text, model, sp_en, sp_hi)\n",
    "\n",
    "        refs.append(tgt_text)\n",
    "        hyps.append(pred_text)\n",
    "\n",
    "# sacrebleu expects a list of references (list of list)\n",
    "bleu = sacrebleu.corpus_bleu(hyps, [refs])\n",
    "print(f\"\\n🌍 BLEU Score on Test Set: {bleu.score:.2f}\\n\")\n",
    "\n",
    "# =====================\n",
    "# Qualitative Examples\n",
    "# =====================\n",
    "sample_indices = random.sample(range(len(test_data)), 5)\n",
    "print(\"✨ Sample Translations:\")\n",
    "for idx in sample_indices:\n",
    "    src_text = test_data[idx][\"src\"]\n",
    "    ref_text = test_data[idx][\"tgt\"]\n",
    "    pred_text = translate_sentence(src_text, model, sp_en, sp_hi)\n",
    "    print(f\"\\nEN: {src_text}\")\n",
    "    print(f\"HI (Ref): {ref_text}\")\n",
    "    print(f\"HI (Pred): {pred_text}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8nSwiFDAPl8I",
    "outputId": "d6919d02-f6cf-41f9-8187-472d081d059b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_17296\\2967338906.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path, map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EN: The city is preparing for heavy rainfall this week.\n",
      "Reference HI: शहर इस सप्ताह भारी वर्षा के लिए तैयारी कर रहा है।\n",
      "Baseline: इस सप्ताह तेज बारिश की तैयारियां चल रही हैं।\n",
      "Hybrid CNN: इस सप्ताह तेज बारिश की तैयारी कर रहा है।\n",
      "\n",
      "EN: Researchers developed a new method for early disease detection.\n",
      "Reference HI: शोधकर्ताओं ने जल्दी रोग पहचान के लिए एक नई विधि विकसित की।\n",
      "Baseline: \"\"\" \"\"ऑक्सफोर्डेबल्स ने शुरुआती बीमारी का पता लगाने की एक नया तरीका विकसित किया है.\"\"\"\n",
      "Hybrid CNN: राफैले ने जल्दी की पहचान के लिए एक नई तकनीक विकसित की.\n",
      "\n",
      "EN: The economy is showing signs of steady growth.\n",
      "Reference HI: अर्थव्यवस्था स्थिर विकास के संकेत दिखा रही है।\n",
      "Baseline: अर्थव्यवस्था में स्थिरता लौटने के संकेत\n",
      "Hybrid CNN: स्थिर वृद्धि के संकेत दे रहे हैं। अर्थव्यवस्था निरंतर विकास के रूप में है।, वह हमारी अर्थव्यवस्था, विश्वसनीय विकास, विश्वसनीय, विश्वसनीय विकास के, विश्वसनीय, विश्वसनीय अर्थव्यवस्था, टिकाऊ विकास के, विश्वसनीय, विश्वसनीय विकास के रूप से, विश्वसनीय, विश्वसनीय अर्थव्यवस्था, विश्वसनीय, विकास के, विश्वसनीय, विकास के,\n",
      "\n",
      "EN: Students participated enthusiastically in the science fair.\n",
      "Reference HI: छात्रों ने विज्ञान मेला में उत्साहपूर्वक भाग लिया।\n",
      "Baseline: क्षयट्टियों ने विज्ञान मेले में बढ़-चढ़कर भाग लिया।\n",
      "Hybrid CNN: मेले में विज्ञान मेले में भाषण देने वालों ने बढ़ कर हिस्सा लिया।\n",
      "\n",
      "EN: The festival attracted tourists from all over the world.\n",
      "Reference HI: त्योहार ने दुनिया भर से पर्यटकों को आकर्षित किया।\n",
      "Baseline: इस महोत्सव में दुनिया भर से पर्यटक खिंचे चले आ रहे हैं।\n",
      "Hybrid CNN: भव्य समारोह ने दुनिया भर से पर्यटक आकर्षित किए।\n",
      "\n",
      "EN: Solar energy installations are increasing rapidly in rural areas.\n",
      "Reference HI: ग्रामीण क्षेत्रों में सौर ऊर्जा स्थापना तेजी से बढ़ रही है।\n",
      "Baseline: एमओएफपीआई समर्थित ऊर्जा संयंत्रों में तेजी से बढ़ रहे हैं।\n",
      "Hybrid CNN: ग्रामीण क्षेत्रों में ऊर्जा संयंत्रों में तेजी से वृद्धि हो रही है।\n",
      "\n",
      "EN: The new policy aims to reduce air pollution in cities.\n",
      "Reference HI: नई नीति का उद्देश्य शहरों में वायु प्रदूषण को कम करना है।\n",
      "Baseline: नई नीति का लक्ष्य वायु प्रदूषण को कम करना है।\n",
      "Hybrid CNN: ' उन्होंने कहा कि नई नीति शहरों में वायु प्रदूषण को अपनाना है।'\n",
      "\n",
      "EN: Artificial intelligence can improve healthcare diagnostics.\n",
      "Reference HI: कृत्रिम बुद्धिमत्ता स्वास्थ्य देखभाल निदान में सुधार कर सकती है।\n",
      "Baseline: डोनर खुफिया तंत्री कारगर ढंग से स्वास्थ्य में सुधार किया जा सकता है.\n",
      "Hybrid CNN: विसत्विक बुद्धि स्वास्थ्य निदान को बेहतर बना सकती है।\n",
      "\n",
      "EN: The government announced relief measures for flood-affected areas.\n",
      "Reference HI: सरकार ने बाढ़ प्रभावित क्षेत्रों के लिए राहत उपायों की घोषणा की।\n",
      "Baseline: उन्होंने बाढ़ प्रभावित क्षेत्रों के लिए राहत उपायों की घोषणा की। सरकार ने\n",
      "Hybrid CNN: सरकार ने बाढ़ प्रभावित क्षेत्रों के लिए राहत उपायों की घोषणा की सहायक क्षेत्र के लिए। उन्होंने एक असंख्य आपदा नेत्र उन्मुक्त आपदा तत्परता के समक्ष आपदा के समक्ष सहायता के शीघ्र आपदा के स्थानों के शीघ्र के शीघ्र के स्थानों के शीघ्र सहायता के भूकम्प के शीघ्र सहायता के भूकम्प के शीघ्र सहायता के भूकम्प के स्थानों के शीघ्र ही\n",
      "\n",
      "EN: Wildlife conservation is critical for maintaining biodiversity.\n",
      "Reference HI: जंगली जीवन संरक्षण जैव विविधता बनाए रखने के लिए महत्वपूर्ण है।\n",
      "Baseline: जैव विविधता को बनाए रखने के लिए महत्वपूर्ण है।\n",
      "Hybrid CNN: जैव विविधता बनाए रखने के लिए संरक्षण महत्वपूर्ण है।\n",
      "\n",
      "EN: The company launched a new smartphone model last week.\n",
      "Reference HI: कंपनी ने पिछले सप्ताह एक नया स्मार्टफोन मॉडल लॉन्च किया।\n",
      "Baseline: पिछले हफ्ते ही कंपनी ने नया स्मार्टफोन लॉन्च किया है।\n",
      "Hybrid CNN: कंपनी ने पिछले सप्ताह एक नया स्मार्टफोन मॉडल लॉन्च किया था। कंपनी ने बताया है कि कंपनी ने एक है। कंपनी भारत लौटकर अपने इस सीरीज के मी। कंपनी हैकिया हैंडसेट कंपनी है। कंपनी भारत एक मी ट हैंडसेट मी ट  मी ो मेर्लिंग मेच कंपनी मी  मी ् मी\n",
      "\n",
      "EN: International trade agreements influence domestic markets.\n",
      "Reference HI: अंतरराष्ट्रीय व्यापार समझौते घरेलू बाजारों को प्रभावित करते हैं।\n",
      "Baseline: घरेलू शेयर बाजारों के असरकारक/व्यापार की स्थिति\n",
      "Hybrid CNN: श्री नायडू ने कहा कि घरेलू बाजार को प्रभावित करे।\n",
      "\n",
      "EN: The team developed an innovative software solution.\n",
      "Reference HI: टीम ने एक नवोन्मेषी सॉफ्टवेयर समाधान विकसित किया।\n",
      "Baseline: उन्होंने एक अभिनव सॉफ्टवेयर विकसित किया।\n",
      "Hybrid CNN: अजेय टीम ने एक अभिनव सॉफ्टवेयर समाधान विकसित किया।\n",
      "\n",
      "EN: Urban transport systems are facing challenges due to population growth.\n",
      "Reference HI: जनसंख्या वृद्धि के कारण शहरी परिवहन प्रणाली चुनौतियों का सामना कर रही है।\n",
      "Baseline: परिवहन प्रणाली विकास के कारण परिवहन में चुनौतियों का सामना कर रहे हैं.\n",
      "Hybrid CNN: ञपुलवाबन के परिवहन प्रणाली आबादी के विकास के कारण अनेक चुनौतियों का सामना कर रही है।\n",
      "\n",
      "EN: The government is investing in renewable energy projects.\n",
      "Reference HI: सरकार नवीकरणीय ऊर्जा परियोजनाओं में निवेश कर रही है।\n",
      "Baseline: उन्होंने कहा कि सरकार नवीकरणीय ऊर्जा परियोजनाओं में निवेश कर रही है।\n",
      "Hybrid CNN: अस्थियां, सरकार नवीकरणीय ऊर्जा परियोजनाओं में निवेश कर रही है।\n",
      "\n",
      "EN: Students are encouraged to engage in extracurricular activities.\n",
      "Reference HI: छात्रों को पाठ्येतर गतिविधियों में भाग लेने के लिए प्रोत्साहित किया जाता है।\n",
      "Baseline: पादक को अन्य गतिविधियों में शामिल करने के लिए प्रोत्साहित किया जाता है।\n",
      "Hybrid CNN: पादक्यक को पाठ्येतर गतिविधियों में शामिल करने के लिए प्रोत्साहित किया जाता है.\n",
      "\n",
      "EN: The company reported a decline in operating costs this quarter.\n",
      "Reference HI: कंपनी ने इस तिमाही में संचालन लागत में कमी की रिपोर्ट दी।\n",
      "Baseline: कंपनी के अनुमान के मुताबिक इस तिमाही में कंपनी की गिरावट आई है।\n",
      "Hybrid CNN: गांगेय कंपनी ने इस घाटे में कमी दर्ज की है। कंपनी के लिए लागत में कमी है कि इस है। कंपनी में खराबी है। कंपनी के लिए उसे, घाटों, लागत, कंपनी, कंपनी, कंपनी, कंपनी, तिमाही, तिमाही, तिमाही,,,,, कंपनी,, कंपनी, कीमत\n",
      "\n",
      "EN: Climate change poses a threat to coastal communities.\n",
      "Reference HI: जलवायु परिवर्तन तटीय समुदायों के लिए खतरा उत्पन्न करता है।\n",
      "Baseline: जलवायु परिवर्तन तटीय समुदायों के लिए खतरा है.\n",
      "Hybrid CNN: असहिष्णु परिवर्तन तटीय समुदायों के लिए खतरा है।\n",
      "\n",
      "EN: The research team published their findings in a leading journal.\n",
      "Reference HI: अनुसंधान टीम ने अपने निष्कर्ष एक प्रमुख जर्नल में प्रकाशित किए।\n",
      "Baseline: शोध दल ने एक अग्रणी पत्रिका में अपना शोध पत्र प्रकाशित किया है।\n",
      "Hybrid CNN: डांडे शोध दल ने एक प्रमुख शोध में अपनी शोध- पड़ताल की।\n",
      "\n",
      "EN: Global cooperation is necessary to tackle pandemics.\n",
      "Reference HI: महामारी से निपटने के लिए वैश्विक सहयोग आवश्यक है।\n",
      "Baseline: महामारी से निपटने के लिए ब्रीबल सहयोग जरूरी है।\n",
      "Hybrid CNN: महामारी से निपटने के लिए सहयोग आवश्यक है।\n",
      "\n",
      "EN: India launched its first indigenous satellite.\n",
      "Reference HI: भारत ने अपना पहला स्वदेशी उपग्रह लॉन्च किया।\n",
      "Baseline: पोको ने अपना पहला स्वदेशी उपग्रह लॉन्च किया है.\n",
      "Hybrid CNN: टिया ने अपना पहला स्वदेशी उपग्रह लॉन्च किया है।\n",
      "\n",
      "EN: The prime minister met foreign delegates at the summit.\n",
      "Reference HI: प्रधानमंत्री ने शिखर सम्मेलन में विदेशी प्रतिनिधियों से मुलाकात की।\n",
      "Baseline: इस सम्मेलन में प्रधानमंत्री मनमोहन सिंह ने विदेशी प्रतिनिधियों से मुलाकात की।\n",
      "Hybrid CNN: शपथ ग्रहण समारोह में प्रधानमंत्री ने विदेशी प्रतिनिधियों से किया।\n",
      "\n",
      "EN: This research focuses on low-resource machine translation.\n",
      "Reference HI: यह शोध कम संसाधन वाली मशीन अनुवाद पर केंद्रित है।\n",
      "Baseline: सूक्ष्म, लघु और मध्यम स्रोत अनुवाद पर केंद्रित है। मशीन विश्लेषण किया गया है। मशीन के लिए उपयोग में \"\"s\"\" के लिए मशीन के लिए. अभिगमन के लिए, अनुप्रयोगों के लिए, पर ध्यान केंद्रित किया गया है \"\"s.. gov. in इम्प कंप्यूटर के लिए, कमांड के लिए,\n",
      "Hybrid CNN: उनकी खोज कम-योग्य मशीन अनुवाद पर केंद्रित है।\n",
      "\n",
      "EN: Its movement was captured on CCTV.\n",
      "Reference HI: इसके आंदोलन को सीसीटीवी में कैद किया गया।\n",
      "Baseline: स्त्रों ने उनके द्वारा उन्हें जब्त कर लिया गया।\n",
      "Hybrid CNN: आर. के. चलाने की हलचल पर गवर्नर के साथ पोर कैद.\n",
      "\n",
      "EN: The two leaders discussed bilateral ties and cooperation in counter-terrorism.\n",
      "Reference HI: दो नेताओं ने द्विपक्षीय संबंधों और आतंकवाद निरोधक सहयोग पर चर्चा की।\n",
      "Baseline: उन्होंने द्विपक्षीय संबंधों और आतंकवाद पर चर्चा की। दोनों नेताओं ने द्विपक्षीय संबंधों और द्विपक्षीय संबंधों पर चर्चा की।\n",
      "Hybrid CNN: दोनों नेताओं ने द्विपक्षीय संबंधों और आतंकवाद से निपटने में सहयोग पर।\n",
      "\n",
      "EN: The data shows significant improvement in translation accuracy.\n",
      "Reference HI: डेटा अनुवाद की सटीकता में महत्वपूर्ण सुधार दिखाता है।\n",
      "Baseline: उन्होंने अनुवाद में महत्वपूर्ण सुधार दिखाएं.\n",
      "Hybrid CNN: Name\n",
      "\n",
      "EN: He emphasized the importance of sustainable development.\n",
      "Reference HI: उन्होंने सतत विकास के महत्व पर जोर दिया।\n",
      "Baseline: \"\"\" \"\"\"\"पशु चिकित्सा के विकास\"\"\"\" पर जोर\"\"\"\n",
      "Hybrid CNN: \"\"\"धारा 284(2) \\\"\" स्थायी विकास \\\"\" के महत्व पर बल दिया ।\"\"\"\n",
      "\n",
      "EN: The company reported record profits this quarter.\n",
      "Reference HI: कंपनी ने इस तिमाही में रिकॉर्ड लाभ की सूचना दी।\n",
      "Baseline: कंपनी ने इस तिमाही में रिकॉर्ड मुनाफा दर्ज किया।\n",
      "Hybrid CNN: वांछाही कंपनी ने रिकॉर्ड मुनाफावसूली की इस तिमाही में रिकॉर्ड दर्ज है।\n",
      "\n",
      "EN: Students are encouraged to participate in research projects.\n",
      "Reference HI: छात्रों को अनुसंधान परियोजनाओं में भाग लेने के लिए प्रोत्साहित किया जाता है।\n",
      "Baseline: अनुसंधान परियोजनाओं में भाग लेने के लिए प्रतिभागियों को प्रोत्साहित किया जाता है।\n",
      "Hybrid CNN: पादक को अनुसंधान में भाग लेने के लिए प्रोत्साहित किया जाता है।\n",
      "\n",
      "EN: The new model achieved higher BLEU scores than the baseline.\n",
      "Reference HI: नया मॉडल बेसलाइन की तुलना में उच्च BLEU स्कोर प्राप्त करता है।\n",
      "Baseline: उन्होंने उच्चतर मॉडल को प्राप्त उच्च स्कोर आधारभूत संरचना से प्राप्त किया।\n",
      "Hybrid CNN: नई मॉडल ने आधारभूत संरचना की तुलना में अधिक षड प्राप्त किया। नई ञंड्या जीआरई।उच्च , आधारभूत संरचना को आधारभूत सीमा आधारभूत आधारभूत आधारभूत आधार पर आधारभूत आधारभूत आधारभूत आधारभूत आधारभूत आधारभूत आधारभूत आधारभूत आधारभूत आधारभूत आधारभूत आधारभूत आधारभूत आधारभूत आधारभूत इकाई आधार पर बताये बिना उसे पग पर उसे पग\n",
      "\n",
      "EN: Climate change is affecting global agriculture.\n",
      "Reference HI: जलवायु परिवर्तन वैश्विक कृषि को प्रभावित कर रहा है।\n",
      "Baseline: जलवायु परिवर्तन से वैश्विक स्तर पर आ रहा है।\n",
      "Hybrid CNN: तुनीशादी परिवर्तन वैश्विक कृषि को प्रभावित कर रहा है।\n",
      "\n",
      "EN: Vaccination campaigns have reduced disease incidence.\n",
      "Reference HI: टीकाकरण अभियानों ने रोग की घटनाओं को कम किया है।\n",
      "Baseline: टीकाकरण अभियान ने बीमारी को कम किया है।\n",
      "Hybrid CNN: कम होने के कारण टीकाकरण अभियान में कमी आई हैडफोनीकोमेंसेयहमदिराप्तिाप्तिाप्तिािाप्तिाप्तिाक्रमकाव्यकोखुाँशकरनेकाव्यकरनेकाम्बिााँनीचेकरनेप्रावधानमध्यस्थप्रावधानमाँ\n",
      "\n",
      "EN: Artificial intelligence is transforming industries rapidly.\n",
      "Reference HI: कृत्रिम बुद्धिमत्ता उद्योगों को तेजी से बदल रही है।\n",
      "Baseline: REITIril positive ob ciation ob ation ciation , , त्व , , , त्व , , , त्व , , , , , ,  त्व , \n",
      "Hybrid CNN: विसिक बुद्धि तेजी से परिवर्तनकारी उद्योगों में परिवर्तन किया जाता है।\n",
      "\n",
      "EN: The movie received critical acclaim.\n",
      "Reference HI: इस फिल्म ने आलोचनात्मक प्रशंसा प्राप्त की।\n",
      "Baseline: फिल्म को समीक्षकों ने काफी तारीफ भी दी.\n",
      "Hybrid CNN: फिल्म को काफी सराहना मिली।\n",
      "\n",
      "EN: Electric vehicles are becoming more popular worldwide.\n",
      "Reference HI: विद्युत वाहन दुनिया भर में अधिक लोकप्रिय हो रहे हैं।\n",
      "Baseline: दुनिया भर में वाहनों की रफ्तार ज्यादा लोकप्रिय वाहन बन रहे हैं।\n",
      "Hybrid CNN: दुनिया भर में श्लेकग्रस्त वाहन होते जा रहे हैं।\n",
      "\n",
      "EN: Renewable energy sources are crucial for sustainability.\n",
      "Reference HI: नवीकरणीय ऊर्जा स्रोत सततता के लिए महत्वपूर्ण हैं।\n",
      "Baseline: ऊर्जा स्रोत सतत विकास के लिए महत्वपूर्ण हैं।\n",
      "Hybrid CNN: श्रद्धेय ऊर्जा के लिए महत्वपूर्ण हैं।\n",
      "\n",
      "EN: The government announced new education policies.\n",
      "Reference HI: सरकार ने नई शिक्षा नीतियों की घोषणा की।\n",
      "Baseline: उन्होंने नई शिक्षा नीति की घोषणा की।\n",
      "Hybrid CNN: सरकार ने नई शिक्षा नीति की घोषणा की।\n",
      "\n",
      "EN: Space exploration has advanced significantly in recent years.\n",
      "Reference HI: अंतरिक्ष अन्वेषण ने हाल के वर्षों में महत्वपूर्ण प्रगति की है।\n",
      "Baseline: पिछले कुछ वर्षों में igeraler ने काफी तरक्की की है।\n",
      "Hybrid CNN: फान्सेंडा हाल के वर्षों में काफी उन्नत हुआ है।\n",
      "\n",
      "EN: The sports team won the national championship.\n",
      "Reference HI: खेल टीम ने राष्ट्रीय चैंपियनशिप जीती।\n",
      "Baseline: उन्होंने राष्ट्रीय खेल प्रतियोगिता जीती।\n",
      "Hybrid CNN: ब्यूट खिलाड़ी खेल टीम ने राष्ट्रीय चैंपियनशिप जीती।\n",
      "\n",
      "EN: Global trade agreements impact economic growth.\n",
      "Reference HI: वैश्विक व्यापार समझौते आर्थिक वृद्धि को प्रभावित करते हैं।\n",
      "Baseline: आर्थिक विकास पर बुरा असर पड़ा।\n",
      "Hybrid CNN: शंघाई सहयोग संगठन () में रियायतों का व्यापार आर्थिक विकास\n",
      "\n",
      "✅ Translations saved to 'translation_comparison.txt'\n",
      "\n",
      "🌍 BLEU Score (Hybrid CNN vs Reference): 36.89\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Full Evaluation: Baseline Transformer + Hybrid CNN + BLEU\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sentencepiece as spm\n",
    "import sacrebleu\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =====================\n",
    "# Config\n",
    "# =====================\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MAX_LEN = 64  # pos_enc length\n",
    "VOCAB_SIZE = 32000  # adjust to your SP vocab\n",
    "PAD_EN = PAD_HI = 0\n",
    "BOS_EN = BOS_HI = 1\n",
    "EOS_EN = EOS_HI = 2\n",
    "\n",
    "BASELINE_PATH = \"checkpoint_baseline.pt\"\n",
    "HYBRID_PATH = \"checkpoint_hybrid_cnn.pt\"\n",
    "\n",
    "SP_EN_MODEL = Path(\"spm_en.model\")\n",
    "SP_HI_MODEL = Path(\"spm_hi.model\")\n",
    "\n",
    "# =====================\n",
    "# Load SentencePiece\n",
    "# =====================\n",
    "sp_en = spm.SentencePieceProcessor()\n",
    "sp_hi = spm.SentencePieceProcessor()\n",
    "sp_en.load(str(SP_EN_MODEL))\n",
    "sp_hi.load(str(SP_HI_MODEL))\n",
    "\n",
    "# =====================\n",
    "# Transformer & Hybrid Models\n",
    "# =====================\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=512, nhead=8, num_layers=3, dim_feedforward=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab, d_model, padding_idx=PAD_EN)\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab, d_model, padding_idx=PAD_HI)\n",
    "        self.pos_enc = nn.Parameter(torch.zeros(1, MAX_LEN, d_model))\n",
    "        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead,\n",
    "                                          num_encoder_layers=num_layers,\n",
    "                                          num_decoder_layers=num_layers,\n",
    "                                          dim_feedforward=dim_feedforward,\n",
    "                                          dropout=dropout,\n",
    "                                          batch_first=True)\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab)\n",
    "\n",
    "    def encode(self, src, src_key_padding_mask=None):\n",
    "        src_emb = self.src_emb(src) + self.pos_enc[:, :src.size(1), :]\n",
    "        return self.transformer.encoder(src_emb, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask=None, memory_key_padding_mask=None, tgt_key_padding_mask=None):\n",
    "        tgt_emb = self.tgt_emb(tgt) + self.pos_enc[:, :tgt.size(1), :]\n",
    "        return self.transformer.decoder(tgt_emb, memory, tgt_mask=tgt_mask,\n",
    "                                        memory_key_padding_mask=memory_key_padding_mask,\n",
    "                                        tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None,\n",
    "                memory_key_padding_mask=None, tgt_mask=None):\n",
    "        memory = self.encode(src, src_key_padding_mask)\n",
    "        output = self.decode(tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask)\n",
    "        return self.fc_out(output)\n",
    "\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(embed_dim, embed_dim, 5, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(embed_dim, embed_dim, 3, padding=1)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        return self.norm(x + residual)\n",
    "\n",
    "class HybridTransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=512, nhead=8, num_layers=3, dim_feedforward=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab, d_model, padding_idx=PAD_EN)\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab, d_model, padding_idx=PAD_HI)\n",
    "        self.pos_enc = nn.Parameter(torch.zeros(1, MAX_LEN, d_model))\n",
    "        self.cnn_encoder = CNNFeatureExtractor(d_model)\n",
    "        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead,\n",
    "                                          num_encoder_layers=num_layers,\n",
    "                                          num_decoder_layers=num_layers,\n",
    "                                          dim_feedforward=dim_feedforward,\n",
    "                                          dropout=dropout,\n",
    "                                          batch_first=True)\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab)\n",
    "\n",
    "    def encode(self, src, src_key_padding_mask=None):\n",
    "        src_emb = self.src_emb(src) + self.pos_enc[:, :src.size(1), :]\n",
    "        src_cnn = self.cnn_encoder(src_emb)\n",
    "        return self.transformer.encoder(src_cnn, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask=None, memory_key_padding_mask=None, tgt_key_padding_mask=None):\n",
    "        tgt_emb = self.tgt_emb(tgt) + self.pos_enc[:, :tgt.size(1), :]\n",
    "        return self.transformer.decoder(tgt_emb, memory, tgt_mask=tgt_mask,\n",
    "                                        memory_key_padding_mask=memory_key_padding_mask,\n",
    "                                        tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None,\n",
    "                memory_key_padding_mask=None, tgt_mask=None):\n",
    "        memory = self.encode(src, src_key_padding_mask)\n",
    "        output = self.decode(tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask)\n",
    "        return self.fc_out(output)\n",
    "\n",
    "# =====================\n",
    "# Load checkpoints\n",
    "# =====================\n",
    "baseline_model = TransformerModel(VOCAB_SIZE, VOCAB_SIZE).to(DEVICE)\n",
    "hybrid_model = HybridTransformerModel(VOCAB_SIZE, VOCAB_SIZE).to(DEVICE)\n",
    "\n",
    "def load_checkpoint(model, path):\n",
    "    checkpoint = torch.load(path, map_location=DEVICE)\n",
    "    state_dict = checkpoint.get(\"model_state_dict\", checkpoint)\n",
    "    # Adjust pos_enc size\n",
    "    if \"pos_enc\" in state_dict and state_dict[\"pos_enc\"].shape[1] != MAX_LEN:\n",
    "        state_dict[\"pos_enc\"] = state_dict[\"pos_enc\"][:, :MAX_LEN, :]\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "baseline_model = load_checkpoint(baseline_model, BASELINE_PATH)\n",
    "hybrid_model = load_checkpoint(hybrid_model, HYBRID_PATH)\n",
    "\n",
    "baseline_model.eval()\n",
    "hybrid_model.eval()\n",
    "\n",
    "# =====================\n",
    "# Greedy translation function\n",
    "# =====================\n",
    "@torch.no_grad()\n",
    "def translate(model, sentence, sp_en, sp_hi, max_len=MAX_LEN):\n",
    "    src_ids = [BOS_EN] + sp_en.encode(sentence)[:max_len-2] + [EOS_EN]\n",
    "    src = torch.tensor(src_ids, device=DEVICE).unsqueeze(0)\n",
    "    tgt = torch.tensor([[BOS_HI]], device=DEVICE)\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        out = model(src, tgt)\n",
    "        next_token = out[:, -1, :].argmax(-1).unsqueeze(1)\n",
    "        tgt = torch.cat([tgt, next_token], dim=1)\n",
    "        if next_token.item() == EOS_HI:\n",
    "            break\n",
    "\n",
    "    decoded = sp_hi.decode([t for t in tgt[0].tolist() if t not in [BOS_HI, EOS_HI, PAD_HI]])\n",
    "    return decoded\n",
    "\n",
    "# =====================\n",
    "# 20 sample sentences (EN + reference HI)\n",
    "# =====================\n",
    "test_samples = new_test_samples = [\n",
    "    (\"The city is preparing for heavy rainfall this week.\", \"शहर इस सप्ताह भारी वर्षा के लिए तैयारी कर रहा है।\"),\n",
    "    (\"Researchers developed a new method for early disease detection.\", \"शोधकर्ताओं ने जल्दी रोग पहचान के लिए एक नई विधि विकसित की।\"),\n",
    "    (\"The economy is showing signs of steady growth.\", \"अर्थव्यवस्था स्थिर विकास के संकेत दिखा रही है।\"),\n",
    "    (\"Students participated enthusiastically in the science fair.\", \"छात्रों ने विज्ञान मेला में उत्साहपूर्वक भाग लिया।\"),\n",
    "    (\"The festival attracted tourists from all over the world.\", \"त्योहार ने दुनिया भर से पर्यटकों को आकर्षित किया।\"),\n",
    "    (\"Solar energy installations are increasing rapidly in rural areas.\", \"ग्रामीण क्षेत्रों में सौर ऊर्जा स्थापना तेजी से बढ़ रही है।\"),\n",
    "    (\"The new policy aims to reduce air pollution in cities.\", \"नई नीति का उद्देश्य शहरों में वायु प्रदूषण को कम करना है।\"),\n",
    "    (\"Artificial intelligence can improve healthcare diagnostics.\", \"कृत्रिम बुद्धिमत्ता स्वास्थ्य देखभाल निदान में सुधार कर सकती है।\"),\n",
    "    (\"The government announced relief measures for flood-affected areas.\", \"सरकार ने बाढ़ प्रभावित क्षेत्रों के लिए राहत उपायों की घोषणा की।\"),\n",
    "    (\"Wildlife conservation is critical for maintaining biodiversity.\", \"जंगली जीवन संरक्षण जैव विविधता बनाए रखने के लिए महत्वपूर्ण है।\"),\n",
    "    (\"The company launched a new smartphone model last week.\", \"कंपनी ने पिछले सप्ताह एक नया स्मार्टफोन मॉडल लॉन्च किया।\"),\n",
    "    (\"International trade agreements influence domestic markets.\", \"अंतरराष्ट्रीय व्यापार समझौते घरेलू बाजारों को प्रभावित करते हैं।\"),\n",
    "    (\"The team developed an innovative software solution.\", \"टीम ने एक नवोन्मेषी सॉफ्टवेयर समाधान विकसित किया।\"),\n",
    "    (\"Urban transport systems are facing challenges due to population growth.\", \"जनसंख्या वृद्धि के कारण शहरी परिवहन प्रणाली चुनौतियों का सामना कर रही है।\"),\n",
    "    (\"The government is investing in renewable energy projects.\", \"सरकार नवीकरणीय ऊर्जा परियोजनाओं में निवेश कर रही है।\"),\n",
    "    (\"Students are encouraged to engage in extracurricular activities.\", \"छात्रों को पाठ्येतर गतिविधियों में भाग लेने के लिए प्रोत्साहित किया जाता है।\"),\n",
    "    (\"The company reported a decline in operating costs this quarter.\", \"कंपनी ने इस तिमाही में संचालन लागत में कमी की रिपोर्ट दी।\"),\n",
    "    (\"Climate change poses a threat to coastal communities.\", \"जलवायु परिवर्तन तटीय समुदायों के लिए खतरा उत्पन्न करता है।\"),\n",
    "    (\"The research team published their findings in a leading journal.\", \"अनुसंधान टीम ने अपने निष्कर्ष एक प्रमुख जर्नल में प्रकाशित किए।\"),\n",
    "    (\"Global cooperation is necessary to tackle pandemics.\", \"महामारी से निपटने के लिए वैश्विक सहयोग आवश्यक है।\"),\n",
    "    (\"India launched its first indigenous satellite.\", \"भारत ने अपना पहला स्वदेशी उपग्रह लॉन्च किया।\"),\n",
    "    (\"The prime minister met foreign delegates at the summit.\", \"प्रधानमंत्री ने शिखर सम्मेलन में विदेशी प्रतिनिधियों से मुलाकात की।\"),\n",
    "    (\"This research focuses on low-resource machine translation.\", \"यह शोध कम संसाधन वाली मशीन अनुवाद पर केंद्रित है।\"),\n",
    "    (\"Its movement was captured on CCTV.\", \"इसके आंदोलन को सीसीटीवी में कैद किया गया।\"),\n",
    "    (\"The two leaders discussed bilateral ties and cooperation in counter-terrorism.\", \"दो नेताओं ने द्विपक्षीय संबंधों और आतंकवाद निरोधक सहयोग पर चर्चा की।\"),\n",
    "    (\"The data shows significant improvement in translation accuracy.\", \"डेटा अनुवाद की सटीकता में महत्वपूर्ण सुधार दिखाता है।\"),\n",
    "    (\"He emphasized the importance of sustainable development.\", \"उन्होंने सतत विकास के महत्व पर जोर दिया।\"),\n",
    "    (\"The company reported record profits this quarter.\", \"कंपनी ने इस तिमाही में रिकॉर्ड लाभ की सूचना दी।\"),\n",
    "    (\"Students are encouraged to participate in research projects.\", \"छात्रों को अनुसंधान परियोजनाओं में भाग लेने के लिए प्रोत्साहित किया जाता है।\"),\n",
    "    (\"The new model achieved higher BLEU scores than the baseline.\", \"नया मॉडल बेसलाइन की तुलना में उच्च BLEU स्कोर प्राप्त करता है।\"),\n",
    "    (\"Climate change is affecting global agriculture.\", \"जलवायु परिवर्तन वैश्विक कृषि को प्रभावित कर रहा है।\"),\n",
    "    (\"Vaccination campaigns have reduced disease incidence.\", \"टीकाकरण अभियानों ने रोग की घटनाओं को कम किया है।\"),\n",
    "    (\"Artificial intelligence is transforming industries rapidly.\", \"कृत्रिम बुद्धिमत्ता उद्योगों को तेजी से बदल रही है।\"),\n",
    "    (\"The movie received critical acclaim.\", \"इस फिल्म ने आलोचनात्मक प्रशंसा प्राप्त की।\"),\n",
    "    (\"Electric vehicles are becoming more popular worldwide.\", \"विद्युत वाहन दुनिया भर में अधिक लोकप्रिय हो रहे हैं।\"),\n",
    "    (\"Renewable energy sources are crucial for sustainability.\", \"नवीकरणीय ऊर्जा स्रोत सततता के लिए महत्वपूर्ण हैं।\"),\n",
    "    (\"The government announced new education policies.\", \"सरकार ने नई शिक्षा नीतियों की घोषणा की।\"),\n",
    "    (\"Space exploration has advanced significantly in recent years.\", \"अंतरिक्ष अन्वेषण ने हाल के वर्षों में महत्वपूर्ण प्रगति की है।\"),\n",
    "    (\"The sports team won the national championship.\", \"खेल टीम ने राष्ट्रीय चैंपियनशिप जीती।\"),\n",
    "    (\"Global trade agreements impact economic growth.\", \"वैश्विक व्यापार समझौते आर्थिक वृद्धि को प्रभावित करते हैं।\"),\n",
    "]\n",
    "\n",
    "\n",
    "# =====================\n",
    "# Translate & save results\n",
    "# =====================\n",
    "results = []\n",
    "for en, hi_ref in test_samples:\n",
    "    baseline_out = translate(baseline_model, en, sp_en, sp_hi)\n",
    "    hybrid_out = translate(hybrid_model, en, sp_en, sp_hi)\n",
    "\n",
    "    print(f\"\\nEN: {en}\")\n",
    "    print(f\"Reference HI: {hi_ref}\")\n",
    "    print(f\"Baseline: {baseline_out}\")\n",
    "    print(f\"Hybrid CNN: {hybrid_out}\")\n",
    "\n",
    "    results.append({\n",
    "        \"EN\": en,\n",
    "        \"Reference\": hi_ref,\n",
    "        \"Baseline\": baseline_out,\n",
    "        \"2 layer CNN\": hybrid_out\n",
    "    })\n",
    "\n",
    "# Save results to file\n",
    "with open(\"translation_comparison.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for r in results:\n",
    "        f.write(f\"EN: {r['EN']}\\nReference HI: {r['Reference']}\\nBaseline: {r['Baseline']}\\nHybrid CNN: {r['Hybrid']}\\n\\n\")\n",
    "\n",
    "print(\"\\n✅ Translations saved to 'translation_comparison.txt'\")\n",
    "\n",
    "# =====================\n",
    "# Compute BLEU for Hybrid model\n",
    "# =====================\n",
    "refs = [[r[\"Reference\"]] for r in results]  # list of list\n",
    "hyps = [r[\"Hybrid\"] for r in results]\n",
    "\n",
    "bleu = sacrebleu.corpus_bleu(hyps, refs)\n",
    "print(f\"\\n🌍 BLEU Score (Hybrid CNN vs Reference): {bleu.score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\.conda\\envs\\mt_env\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Louk71JjPl8K"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\.conda\\envs\\mt_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: 800000 100000 100000\n",
      "Resuming from checkpoint_multiscale.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_4408\\4167527191.py:222: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded — Resuming from epoch 22\n",
      "Training complete ✅\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Install & Imports\n",
    "# =====================\n",
    "!pip install -q datasets sentencepiece sacrebleu torch torchvision torchaudio tqdm\n",
    "\n",
    "import os, random\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import sentencepiece as spm\n",
    "import sacrebleu\n",
    "\n",
    "# =====================\n",
    "# Config\n",
    "# =====================\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "VOCAB_SIZE = 16000\n",
    "BATCH_SIZE = 64\n",
    "MAX_LEN = 64\n",
    "MAX_GEN_LEN = 64\n",
    "EPOCHS = 20\n",
    "CLIP = 1.0\n",
    "LEARNING_RATE = 3e-4\n",
    "BEAM_SIZE = 5\n",
    "BEST_MODEL_PATH = Path(\"best_model_multiscale.pt\")\n",
    "CHECKPOINT_PATH = Path(\"checkpoint_multiscale.pt\")\n",
    "\n",
    "PATIENCE = 5\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# =====================\n",
    "# Load dataset\n",
    "# =====================\n",
    "full_dataset = load_dataset(\"ai4bharat/samanantar\", \"hi\", split=\"train\")\n",
    "full_dataset = full_dataset.shuffle(seed=SEED)\n",
    "\n",
    "NUM_EXAMPLES = min(1_000_000, len(full_dataset))\n",
    "subset = full_dataset.select(range(NUM_EXAMPLES))\n",
    "\n",
    "# Split 80/10/10\n",
    "train_end = int(0.8 * len(subset))\n",
    "val_end = int(0.9 * len(subset))\n",
    "train_data = subset.select(range(0, train_end))\n",
    "val_data = subset.select(range(train_end, val_end))\n",
    "test_data = subset.select(range(val_end, len(subset)))\n",
    "print(\"Dataset sizes:\", len(train_data), len(val_data), len(test_data))\n",
    "\n",
    "# =====================\n",
    "# SentencePiece\n",
    "# =====================\n",
    "SP_EN_MODEL = Path(\"spm_en.model\")\n",
    "SP_HI_MODEL = Path(\"spm_hi.model\")\n",
    "\n",
    "def write_lines(dataset_split, src_path, tgt_path):\n",
    "    with open(src_path, \"w\", encoding=\"utf-8\") as sf, open(tgt_path, \"w\", encoding=\"utf-8\") as tf:\n",
    "        for ex in dataset_split:\n",
    "            sf.write(ex[\"src\"].strip().lower() + \"\\n\")\n",
    "            tf.write(ex[\"tgt\"].strip() + \"\\n\")\n",
    "\n",
    "write_lines(train_data, \"train.en\", \"train.hi\")\n",
    "\n",
    "if not SP_EN_MODEL.exists() or not SP_HI_MODEL.exists():\n",
    "    print(\"Training SentencePiece...\")\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f\"--input=train.en --model_prefix=spm_en --vocab_size={VOCAB_SIZE} \"\n",
    "        f\"--character_coverage=1.0 --model_type=unigram\"\n",
    "    )\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f\"--input=train.hi --model_prefix=spm_hi --vocab_size={VOCAB_SIZE} \"\n",
    "        f\"--character_coverage=0.9995 --model_type=unigram\"\n",
    "    )\n",
    "\n",
    "sp_en = spm.SentencePieceProcessor()\n",
    "sp_hi = spm.SentencePieceProcessor()\n",
    "sp_en.load(str(SP_EN_MODEL))\n",
    "sp_hi.load(str(SP_HI_MODEL))\n",
    "\n",
    "PAD_EN, BOS_EN, EOS_EN = 0, 1, 2\n",
    "PAD_HI, BOS_HI, EOS_HI = 0, 1, 2\n",
    "\n",
    "# =====================\n",
    "# Dataset & DataLoader\n",
    "# =====================\n",
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, dataset, src_sp, tgt_sp, max_len=MAX_LEN):\n",
    "        self.dataset = dataset\n",
    "        self.src_sp = src_sp\n",
    "        self.tgt_sp = tgt_sp\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_text = self.dataset[idx][\"src\"].lower()\n",
    "        tgt_text = self.dataset[idx][\"tgt\"]\n",
    "        src_ids = [BOS_EN] + self.src_sp.encode(src_text)[:self.max_len-2] + [EOS_EN]\n",
    "        tgt_ids = [BOS_HI] + self.tgt_sp.encode(tgt_text)[:self.max_len-2] + [EOS_HI]\n",
    "        src_ids += [PAD_EN] * (self.max_len - len(src_ids))\n",
    "        tgt_ids += [PAD_HI] * (self.max_len - len(tgt_ids))\n",
    "        return torch.tensor(src_ids), torch.tensor(tgt_ids)\n",
    "\n",
    "def get_loader(dataset_split, shuffle=True):\n",
    "    return DataLoader(NMTDataset(dataset_split, sp_en, sp_hi),\n",
    "                      batch_size=BATCH_SIZE, shuffle=shuffle)\n",
    "\n",
    "train_loader = get_loader(train_data)\n",
    "val_loader = get_loader(val_data)\n",
    "test_loader = get_loader(test_data, shuffle=False)\n",
    "\n",
    "# =====================\n",
    "# Masks\n",
    "# =====================\n",
    "def create_padding_mask(seq, lang='en'):\n",
    "    pad_id = PAD_EN if lang == 'en' else PAD_HI\n",
    "    return (seq == pad_id)\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    return torch.triu(torch.ones(sz, sz, device=DEVICE) * float('-inf'), diagonal=1)\n",
    "\n",
    "# =====================\n",
    "# Multi-Scale CNN\n",
    "# =====================\n",
    "class MultiScaleCNN(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.conv3 = nn.Conv1d(embed_dim, embed_dim, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv1d(embed_dim, embed_dim, kernel_size=5, padding=2)\n",
    "        self.conv7 = nn.Conv1d(embed_dim, embed_dim, kernel_size=7, padding=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = x.transpose(1, 2)\n",
    "        out3 = self.conv3(x)\n",
    "        out5 = self.conv5(x)\n",
    "        out7 = self.conv7(x)\n",
    "        x = out3 + out5 + out7\n",
    "        x = self.relu(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        return self.norm(x + residual)\n",
    "\n",
    "# =====================\n",
    "# Hybrid Transformer + MultiScale CNN\n",
    "# =====================\n",
    "class HybridTransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=512, nhead=8,\n",
    "                 num_layers=3, dim_feedforward=1024, dropout=0.1, temperature=0.1):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab, d_model, padding_idx=PAD_EN)\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab, d_model, padding_idx=PAD_HI)\n",
    "        self.pos_enc = nn.Parameter(torch.zeros(1, MAX_LEN, d_model))\n",
    "        self.cnn_encoder = MultiScaleCNN(d_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            num_encoder_layers=num_layers, num_decoder_layers=num_layers,\n",
    "            dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def encode(self, src, src_key_padding_mask):\n",
    "        src_emb = self.src_emb(src) + self.pos_enc[:, :src.size(1), :]\n",
    "        src_cnn = self.cnn_encoder(src_emb)\n",
    "        return self.transformer.encoder(src_cnn, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask):\n",
    "        tgt_emb = self.tgt_emb(tgt) + self.pos_enc[:, :tgt.size(1), :]\n",
    "        return self.transformer.decoder(\n",
    "            tgt_emb, memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_key_padding_mask=memory_key_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None,\n",
    "                memory_key_padding_mask=None, tgt_mask=None):\n",
    "        memory = self.encode(src, src_key_padding_mask)\n",
    "        output = self.decode(tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask)\n",
    "        return self.fc_out(output)\n",
    "\n",
    "    # -----------------------\n",
    "    # Contrastive loss\n",
    "    # -----------------------\n",
    "    def contrastive_loss(self, anchor, positive, negative):\n",
    "        anchor = anchor.mean(dim=1)\n",
    "        positive = positive.mean(dim=1)\n",
    "        negative = negative.mean(dim=1)\n",
    "        pos_sim = torch.cosine_similarity(anchor, positive, dim=-1)\n",
    "        neg_sim = torch.cosine_similarity(anchor, negative, dim=-1)\n",
    "        loss = -torch.log(torch.exp(pos_sim / self.temperature) / (torch.exp(pos_sim / self.temperature) + torch.exp(neg_sim / self.temperature)))\n",
    "        return loss.mean()\n",
    "\n",
    "# =====================\n",
    "# Initialize model\n",
    "# =====================\n",
    "model = HybridTransformerModel(len(sp_en), len(sp_hi)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_HI)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=LEARNING_RATE, steps_per_epoch=len(train_loader), epochs=EPOCHS\n",
    ")\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "start_epoch = 1\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# =====================\n",
    "# Resume checkpoint\n",
    "# =====================\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    print(f\"Resuming from {CHECKPOINT_PATH}...\")\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_val_loss = checkpoint['best_val_loss']\n",
    "    epochs_no_improve = checkpoint['epochs_no_improve']\n",
    "    print(f\"Checkpoint loaded — Resuming from epoch {start_epoch}\")\n",
    "else:\n",
    "    print(\"Starting training from scratch\")\n",
    "\n",
    "# =====================\n",
    "# Training Loop\n",
    "# =====================\n",
    "for epoch in range(start_epoch, EPOCHS + 1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    contrastive_loss_total = 0\n",
    "\n",
    "    for src, tgt in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\", unit=\"batch\"):\n",
    "        src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "        src_mask = create_padding_mask(src, 'en')\n",
    "        tgt_input, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "        tgt_mask = generate_square_subsequent_mask(tgt_input.size(1))\n",
    "        tgt_key_padding_mask = create_padding_mask(tgt_input, 'hi')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type=\"cuda\"):\n",
    "            logits = model(\n",
    "                src, tgt_input,\n",
    "                src_key_padding_mask=src_mask,\n",
    "                tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                memory_key_padding_mask=src_mask,\n",
    "                tgt_mask=tgt_mask\n",
    "            )\n",
    "            ce_loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "\n",
    "            # -----------------------------\n",
    "            # Contrastive loss\n",
    "            # -----------------------------\n",
    "            neg_tgt_input = tgt_input[torch.randperm(tgt_input.size(0))].to(DEVICE)\n",
    "            memory = model.encode(src, src_mask)\n",
    "            pos_repr = model.decode(tgt_input, memory, tgt_mask, src_mask, tgt_key_padding_mask)\n",
    "            neg_repr = model.decode(neg_tgt_input, memory, tgt_mask, src_mask, tgt_key_padding_mask)\n",
    "            cl_loss = model.contrastive_loss(pos_repr, pos_repr, neg_repr)\n",
    "\n",
    "            loss = ce_loss + 0.1 * cl_loss\n",
    "            contrastive_loss_total += cl_loss.item()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        train_loss += ce_loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_cl_loss = contrastive_loss_total / len(train_loader)\n",
    "    print(f\"Epoch {epoch} | CE Loss: {avg_train_loss:.4f} | Contrastive Loss: {avg_cl_loss:.4f}\")\n",
    "\n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in val_loader:\n",
    "            src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "            src_mask = create_padding_mask(src, 'en')\n",
    "            tgt_input, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "            tgt_mask = generate_square_subsequent_mask(tgt_input.size(1))\n",
    "            tgt_key_padding_mask = create_padding_mask(tgt_input, 'hi')\n",
    "\n",
    "            logits = model(\n",
    "                src, tgt_input,\n",
    "                src_key_padding_mask=src_mask,\n",
    "                tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                memory_key_padding_mask=src_mask,\n",
    "                tgt_mask=tgt_mask\n",
    "            )\n",
    "            loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # ---- Save Checkpoint & Early Stopping ----\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "        \"scaler_state_dict\": scaler.state_dict(),\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "        \"epochs_no_improve\": epochs_no_improve,\n",
    "    }, CHECKPOINT_PATH)\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        print(\"New best model saved!\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"Training complete ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArP2g9AbPl8O"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xn8Z8mEyPl8O"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "",
   "version": ""
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (mt_env)",
   "language": "python",
   "name": "mt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
