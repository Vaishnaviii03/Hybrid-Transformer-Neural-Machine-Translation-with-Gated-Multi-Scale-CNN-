{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFn4MYfePl73",
    "outputId": "64055ed6-0939-424c-da19-4c42224f14c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\.conda\\envs\\mt_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: 800000 100000 100000\n",
      "üîÑ Resuming from checkpoint: checkpoint_baseline.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_28892\\798033649.py:183: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded scaler state from checkpoint.\n",
      "Resumed from epoch 26, best val loss = 2.4229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30:   0%|                                                                        | 0/12500 [00:00<?, ?batch/s]C:\\Users\\Ayush\\.conda\\envs\\mt_env\\lib\\site-packages\\torch\\nn\\functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 27/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12500/12500 [13:56<00:00, 14.94batch/s]\n",
      "C:\\Users\\Ayush\\.conda\\envs\\mt_env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:502: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\NestedTensorImpl.cpp:180.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 1.5976 | Val Loss: 2.4865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12500/12500 [13:56<00:00, 14.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 1.5685 | Val Loss: 2.4935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12500/12500 [13:54<00:00, 14.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 1.5502 | Val Loss: 2.4999\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "üéØ Training complete.\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Imports & Setup\n",
    "# =====================\n",
    "!pip install -q datasets sentencepiece sacrebleu torch torchvision torchaudio tqdm\n",
    "\n",
    "import os, random\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import sentencepiece as spm\n",
    "import sacrebleu\n",
    "\n",
    "# =====================\n",
    "# Config\n",
    "# =====================\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "VOCAB_SIZE = 16000\n",
    "BATCH_SIZE = 64\n",
    "MAX_LEN = 64\n",
    "MAX_GEN_LEN = 64\n",
    "EPOCHS = 30\n",
    "CLIP = 1.0\n",
    "LEARNING_RATE = 3e-4\n",
    "BEAM_SIZE = 5\n",
    "BEST_MODEL_PATH = Path(\"best_model_baseline.pt\")\n",
    "CHECKPOINT_PATH = Path(\"checkpoint_baseline.pt\")\n",
    "PATIENCE = 5  # early stopping patience\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# =====================\n",
    "# Load dataset (up to 1M)\n",
    "# =====================\n",
    "full_dataset = load_dataset(\"ai4bharat/samanantar\", \"hi\", split=\"train\")\n",
    "full_dataset = full_dataset.shuffle(seed=SEED)\n",
    "\n",
    "NUM_EXAMPLES = min(1_000_000, len(full_dataset))\n",
    "subset = full_dataset.select(range(NUM_EXAMPLES))\n",
    "\n",
    "# Split 80% train, 10% val, 10% test\n",
    "train_end = int(0.8 * len(subset))\n",
    "val_end = int(0.9 * len(subset))\n",
    "train_data = subset.select(range(0, train_end))\n",
    "val_data = subset.select(range(train_end, val_end))\n",
    "test_data = subset.select(range(val_end, len(subset)))\n",
    "\n",
    "print(\"Dataset sizes:\", len(train_data), len(val_data), len(test_data))\n",
    "\n",
    "# =====================\n",
    "# SentencePiece\n",
    "# =====================\n",
    "SP_EN_MODEL = Path(\"spm_en.model\")\n",
    "SP_HI_MODEL = Path(\"spm_hi.model\")\n",
    "\n",
    "def write_lines(dataset_split, src_path, tgt_path):\n",
    "    with open(src_path, \"w\", encoding=\"utf-8\") as sf, open(tgt_path, \"w\", encoding=\"utf-8\") as tf:\n",
    "        for ex in dataset_split:\n",
    "            sf.write(ex[\"src\"].strip().lower() + \"\\n\")\n",
    "            tf.write(ex[\"tgt\"].strip() + \"\\n\")\n",
    "\n",
    "write_lines(train_data, \"train.en\", \"train.hi\")\n",
    "\n",
    "if not SP_EN_MODEL.exists() or not SP_HI_MODEL.exists():\n",
    "    print(\"Training SentencePiece...\")\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f\"--input=train.en --model_prefix=spm_en --vocab_size={VOCAB_SIZE} \"\n",
    "        f\"--character_coverage=1.0 --model_type=unigram\"\n",
    "    )\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f\"--input=train.hi --model_prefix=spm_hi --vocab_size={VOCAB_SIZE} \"\n",
    "        f\"--character_coverage=0.9995 --model_type=unigram\"\n",
    "    )\n",
    "\n",
    "sp_en = spm.SentencePieceProcessor()\n",
    "sp_hi = spm.SentencePieceProcessor()\n",
    "sp_en.load(str(SP_EN_MODEL))\n",
    "sp_hi.load(str(SP_HI_MODEL))\n",
    "\n",
    "PAD_EN, BOS_EN, EOS_EN = 0, 1, 2\n",
    "PAD_HI, BOS_HI, EOS_HI = 0, 1, 2\n",
    "\n",
    "# =====================\n",
    "# Dataset & DataLoader\n",
    "# =====================\n",
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, dataset, src_sp, tgt_sp, max_len=MAX_LEN):\n",
    "        self.dataset = dataset\n",
    "        self.src_sp = src_sp\n",
    "        self.tgt_sp = tgt_sp\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_text = self.dataset[idx][\"src\"].lower()\n",
    "        tgt_text = self.dataset[idx][\"tgt\"]\n",
    "        src_ids = [BOS_EN] + self.src_sp.encode(src_text)[:self.max_len-2] + [EOS_EN]\n",
    "        tgt_ids = [BOS_HI] + self.tgt_sp.encode(tgt_text)[:self.max_len-2] + [EOS_HI]\n",
    "        src_ids += [PAD_EN] * (self.max_len - len(src_ids))\n",
    "        tgt_ids += [PAD_HI] * (self.max_len - len(tgt_ids))\n",
    "        return torch.tensor(src_ids), torch.tensor(tgt_ids)\n",
    "\n",
    "def get_loader(dataset_split, shuffle=True):\n",
    "    return DataLoader(NMTDataset(dataset_split, sp_en, sp_hi),\n",
    "                      batch_size=BATCH_SIZE, shuffle=shuffle)\n",
    "\n",
    "train_loader = get_loader(train_data)\n",
    "val_loader = get_loader(val_data)\n",
    "test_loader = get_loader(test_data, shuffle=False)\n",
    "\n",
    "# =====================\n",
    "# Masks\n",
    "# =====================\n",
    "def create_padding_mask(seq, lang='en'):\n",
    "    pad_id = PAD_EN if lang == 'en' else PAD_HI\n",
    "    return (seq == pad_id)\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    return torch.triu(torch.ones(sz, sz, device=DEVICE) * float('-inf'), diagonal=1)\n",
    "\n",
    "# =====================\n",
    "# Transformer Model\n",
    "# =====================\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=512, nhead=8,\n",
    "                 num_layers=3, dim_feedforward=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab, d_model, padding_idx=PAD_EN)\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab, d_model, padding_idx=PAD_HI)\n",
    "        self.pos_enc = nn.Parameter(torch.zeros(1, MAX_LEN, d_model))\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            num_encoder_layers=num_layers, num_decoder_layers=num_layers,\n",
    "            dim_feedforward=dim_feedforward, dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab)\n",
    "\n",
    "    def encode(self, src, src_key_padding_mask):\n",
    "        src_emb = self.src_emb(src) + self.pos_enc[:, :src.size(1), :]\n",
    "        return self.transformer.encoder(src_emb, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask):\n",
    "        tgt_emb = self.tgt_emb(tgt) + self.pos_enc[:, :tgt.size(1), :]\n",
    "        return self.transformer.decoder(\n",
    "            tgt_emb, memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_key_padding_mask=memory_key_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None,\n",
    "                memory_key_padding_mask=None, tgt_mask=None):\n",
    "        memory = self.encode(src, src_key_padding_mask)\n",
    "        output = self.decode(tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask)\n",
    "        return self.fc_out(output)\n",
    "\n",
    "# =====================\n",
    "# Training Setup\n",
    "# =====================\n",
    "model = TransformerModel(len(sp_en), len(sp_hi)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_HI)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=LEARNING_RATE, steps_per_epoch=len(train_loader), epochs=EPOCHS\n",
    ")\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "# ---- Resume if checkpoint exists ----\n",
    "start_epoch = 1\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    print(f\"üîÑ Resuming from checkpoint: {CHECKPOINT_PATH}\")\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "    # Handle optional scaler\n",
    "    if \"scaler_state_dict\" in checkpoint:\n",
    "        scaler.load_state_dict(checkpoint[\"scaler_state_dict\"])\n",
    "        print(\"‚úÖ Loaded scaler state from checkpoint.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No scaler state found in checkpoint ‚Äî continuing without it.\")\n",
    "    start_epoch = checkpoint.get(\"epoch\", 0) + 1\n",
    "    best_val_loss = checkpoint.get(\"best_val_loss\", float(\"inf\"))\n",
    "    epochs_no_improve = checkpoint.get(\"epochs_no_improve\", 0)\n",
    "    print(f\"Resumed from epoch {start_epoch-1}, best val loss = {best_val_loss:.4f}\")\n",
    "\n",
    "# =====================\n",
    "# Training Loop\n",
    "# =====================\n",
    "for epoch in range(start_epoch, EPOCHS + 1):\n",
    "    # ---- Train ----\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for src, tgt in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\", unit=\"batch\"):\n",
    "        src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "        src_mask = create_padding_mask(src, 'en')\n",
    "        tgt_input, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "        tgt_mask = generate_square_subsequent_mask(tgt_input.size(1))\n",
    "        tgt_key_padding_mask = create_padding_mask(tgt_input, 'hi')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type=\"cuda\"):\n",
    "            logits = model(\n",
    "                src, tgt_input,\n",
    "                src_key_padding_mask=src_mask,\n",
    "                tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                memory_key_padding_mask=src_mask,\n",
    "                tgt_mask=tgt_mask\n",
    "            )\n",
    "            loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in val_loader:\n",
    "            src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "            src_mask = create_padding_mask(src, 'en')\n",
    "            tgt_input, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "            tgt_mask = generate_square_subsequent_mask(tgt_input.size(1))\n",
    "            tgt_key_padding_mask = create_padding_mask(tgt_input, 'hi')\n",
    "\n",
    "            logits = model(\n",
    "                src, tgt_input,\n",
    "                src_key_padding_mask=src_mask,\n",
    "                tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                memory_key_padding_mask=src_mask,\n",
    "                tgt_mask=tgt_mask\n",
    "            )\n",
    "            loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # ---- Save Checkpoint ----\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "        \"scaler_state_dict\": scaler.state_dict(),\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "        \"epochs_no_improve\": epochs_no_improve,\n",
    "    }, CHECKPOINT_PATH)\n",
    "\n",
    "    # ---- Early Stopping ----\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        print(\"‚úÖ New best model saved!\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(\"‚èπÔ∏è Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"üéØ Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmTpXAxePl7_",
    "outputId": "c99d3aa8-7a7c-46d6-fbe6-e6ccf3fb6589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Full checkpoint saved as 'checkpoint_baseline.pt'\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Save Full Checkpoint\n",
    "# =====================\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'scheduler_state_dict': scheduler.state_dict(),\n",
    "    'best_val_loss': best_val_loss,\n",
    "    'config': {\n",
    "        'VOCAB_SIZE': VOCAB_SIZE,\n",
    "        'MAX_LEN': MAX_LEN,\n",
    "        'EPOCHS': EPOCHS,\n",
    "        'LEARNING_RATE': LEARNING_RATE,\n",
    "        'CLIP': CLIP,\n",
    "        'BATCH_SIZE': BATCH_SIZE\n",
    "    }\n",
    "}, \"checkpoint_baseline.pt\")\n",
    "\n",
    "print(\"‚úÖ Full checkpoint saved as 'checkpoint_baseline.pt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZ-pZJCEPl8A",
    "outputId": "3abad2c1-7877-436b-dbe3-cd45635c305c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Config saved to config.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "config = {\n",
    "    \"VOCAB_SIZE\": VOCAB_SIZE,\n",
    "    \"MAX_LEN\": MAX_LEN,\n",
    "    \"EPOCHS\": EPOCHS,\n",
    "    \"LEARNING_RATE\": LEARNING_RATE,\n",
    "    \"CLIP\": CLIP,\n",
    "    \"BATCH_SIZE\": BATCH_SIZE,\n",
    "    \"DEVICE\": DEVICE\n",
    "}\n",
    "\n",
    "with open(\"config.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "print(\"‚úÖ Config saved to config.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bT0fKEzjPl8B",
    "outputId": "6321463a-0aab-42c3-b33b-c4a202d7ea1e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_28892\\2853380784.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded best model for evaluation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [09:34<00:00,  2.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç Test BLEU score: 8.58\n",
      "\n",
      "üîç Sample Translations:\n",
      "\n",
      "EN: Its movement was captured on CCTV.\n",
      "HI (Reference): ‡§â‡§®‡§ï‡•Ä ‡§Ø‡§π ‡§π‡§∞‡§ï‡§§ ‡§∏‡•Ä‡§∏‡•Ä‡§ü‡•Ä‡§µ‡•Ä ‡§Æ‡•á‡§Ç ‡§ï‡•à‡§¶ ‡§π‡•ã ‡§ó‡§à‡•§\n",
      "HI (Predicted): ‡§Ø‡§π ‡§∏‡•Ä‡§∏‡•Ä‡§ü‡•Ä‡§µ‡•Ä ‡§Æ‡•á‡§Ç ‡§ï‡•à‡§¶ ‡§π‡•ã ‡§ó‡§Ø‡§æ‡•§\n",
      "--------------------------------------------------\n",
      "\n",
      "EN: \"The two leaders \"\"discussed bilateral ties, including development partnership and cooperation in counter-terrorism and international fora,\"\" he said in the tweet.\"\n",
      "HI (Reference): ‡§ü‡•ç‡§µ‡•Ä‡§ü ‡§Æ‡•á‡§Ç ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§ï‡§π‡§æ ‡§ï‡§ø ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§®‡•á ‚Äò‚Äò‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§∏‡§æ‡§ù‡•á‡§¶‡§æ‡§∞‡•Ä ‡§î‡§∞ ‡§Ü‡§§‡§Ç‡§ï‡§µ‡§æ‡§¶ ‡§ï‡•á ‡§ñ‡§ø‡§≤‡§æ‡§´ ‡§§‡§•‡§æ ‡§Ö‡§Ç‡§§‡§∞‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§Æ‡§Ç‡§ö‡•ã‡§Ç ‡§™‡§∞ ‡§∏‡§π‡§Ø‡•ã‡§ó ‡§∏‡§Æ‡•á‡§§ ‡§¶‡•ç‡§µ‡§ø‡§™‡§ï‡•ç‡§∑‡•Ä‡§Ø ‡§∏‡§Ç‡§¨‡§Ç‡§ß‡•ã‡§Ç‚Äô‚Äô ‡§™‡§∞ ‡§ö‡§∞‡•ç‡§ö‡§æ ‡§ï‡•Ä‡•§\n",
      "HI (Predicted): ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§ü‡•ç‡§µ‡•Ä‡§ü ‡§ï‡§ø‡§Ø‡§æ, ‚Äò‚Äò‡§¶‡•ã‡§®‡•ã‡§Ç ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§®‡•á ‡§¶‡•ç‡§µ‡§ø‡§™‡§ï‡•ç‡§∑‡•Ä‡§Ø ‡§∏‡§Ç‡§¨‡§Ç‡§ß‡•ã‡§Ç ‡§ï‡•ã ‡§§‡•ã‡§°‡§º‡§æ, ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§∏‡§æ‡§ù‡•á‡§¶‡§æ‡§∞‡•Ä ‡§î‡§∞ ‡§Ü‡§§‡§Ç‡§ï‡§µ‡§æ‡§¶ ‡§µ‡§ø‡§∞‡•ã‡§ß‡•Ä ‡§î‡§∞ ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§∞‡§æ‡§∑‡•ç‚Äç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§Æ‡§Ç‡§ö‡•ã‡§Ç ‡§™‡§∞ ‡§∏‡§π‡§Ø‡•ã‡§ó ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§π‡•à‡§Ç‡•§\n",
      "--------------------------------------------------\n",
      "\n",
      "EN: These are Allahabad Bank, United Bank of India, Corporation Bank, IDBI Bank, Uco Bank, Bank of India, Central Bank of India, Indian Overseas Bank, Oriental Bank of Commerce, Dena Bank and Bank of Maharashtra.\n",
      "HI (Reference): ‡§¶‡•á‡§®‡§æ ‡§¨‡•à‡§Ç‡§ï, ‡§á‡§≤‡§æ‡§π‡§æ‡§¨‡§æ‡§¶ ‡§¨‡•à‡§Ç‡§ï, ‡§Ø‡•Ç‡§®‡§æ‡§á‡§ü‡•á‡§° ‡§¨‡•à‡§Ç‡§ï ‡§ë‡§´ ‡§á‡§Ç‡§°‡§ø‡§Ø‡§æ, ‡§ï‡•â‡§∞‡§™‡•ã‡§∞‡•á‡§∂‡§® ‡§¨‡•à‡§Ç‡§ï, ‡§Ü‡§à‡§°‡•Ä‡§¨‡•Ä‡§Ü‡§à ‡§¨‡•à‡§Ç‡§ï, ‡§Ø‡•Ç‡§ï‡•ã ‡§¨‡•à‡§Ç‡§ï, ‡§¨‡•à‡§Ç‡§ï ‡§ë‡§´ ‡§á‡§Ç‡§°‡§ø‡§Ø‡§æ, ‡§∏‡•á‡§Ç‡§ü‡•ç‡§∞‡§≤ ‡§¨‡•à‡§Ç‡§ï ‡§ë‡§´ ‡§á‡§Ç‡§°‡§ø‡§Ø‡§æ, ‡§á‡§Ç‡§°‡§ø‡§Ø‡§® ‡§ì‡§µ‡§∞‡§∏‡•Ä‡§ú ‡§¨‡•à‡§Ç‡§ï, ‡§ì‡§∞‡§ø‡§è‡§Ç‡§ü‡§≤ ‡§¨‡•à‡§Ç‡§ï ‡§ë‡§´ ‡§ï‡•â‡§Æ‡§∞‡•ç‡§∏ ‡§î‡§∞ ‡§¨‡•à‡§Ç‡§ï ‡§ë‡§´ ‡§Æ‡§π‡§æ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•§\n",
      "HI (Predicted): ‡§Ø‡•á ‡§π‡•à‡§Ç- ‡§¨‡•à‡§Ç‡§ï ‡§ë‡§´ ‡§á‡§Ç‡§°‡§ø‡§Ø‡§æ, ‡§ì‡§∞‡§ø‡§è‡§Ç‡§ü‡§≤ ‡§¨‡•à‡§Ç‡§ï ‡§ë‡§´ ‡§ï‡•â‡§Æ‡§∞‡•ç‡§∏, ‡§¨‡•à‡§Ç‡§ï ‡§ë‡§´ ‡§á‡§Ç‡§°‡§ø‡§Ø‡§æ, ‡§Ü‡§à‡§°‡•Ä‡§¨‡•Ä‡§Ü‡§à ‡§¨‡•à‡§Ç‡§ï, ‡§Ø‡•Ç‡§ï‡•ã ‡§¨‡•à‡§Ç‡§ï, ‡§∏‡•á‡§Ç‡§ü‡•ç‡§∞‡§≤ ‡§¨‡•à‡§Ç‡§ï ‡§ë‡§´ ‡§á‡§Ç‡§°‡§ø‡§Ø‡§æ, ‡§á‡§Ç‡§°‡§ø‡§Ø‡§® ‡§ì‡§µ‡§∞‡§∏‡•Ä‡§ú ‡§¨‡•à‡§Ç‡§ï, ‡§ì‡§∞‡§ø‡§Ø‡§Ç‡§ü‡§≤ ‡§¨‡•à‡§Ç‡§ï ‡§ë‡§´ ‡§ï‡•â‡§Æ‡§∞‡•ç‡§∏, ‡§¶‡•á‡§®‡§æ ‡§¨‡•à‡§Ç‡§ï ‡§ë‡§´ ‡§Æ‡§π‡§æ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•§\n",
      "--------------------------------------------------\n",
      "\n",
      "EN: Those who remember Allah standing, sitting, and lying on their sides, and reflect on the creation of the heavens and the earth [and say], Our Lord, You have not created this in vain! Immaculate are You! Save us from the punishment of the Fire.\n",
      "HI (Reference): ‡§ú‡•ã ‡§≤‡•ã‡§ó ‡§â‡§†‡§§‡•á ‡§¨‡•à‡§†‡§§‡•á ‡§ï‡§∞‡§µ‡§ü ‡§≤‡•á‡§§‡•á (‡§Ö‡§≤‡§ó‡§∞‡§ú‡§º ‡§π‡§∞ ‡§π‡§æ‡§≤ ‡§Æ‡•á‡§Ç) ‡§ñ‡§º‡•Å‡§¶‡§æ ‡§ï‡§æ ‡§ú‡§º‡§ø‡§ï‡•ç‡§∞ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§Ü‡§∏‡§Æ‡§æ‡§®‡•ã‡§Ç ‡§î‡§∞ ‡§ú‡§º‡§Æ‡•Ä‡§® ‡§ï‡•Ä ‡§¨‡§®‡§æ‡§µ‡§ü ‡§Æ‡•á‡§Ç ‡§ó‡§º‡•å‡§∞ ‡§µ ‡§´‡§º‡§ø‡§ï‡•ç‡§∞ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ (‡§¨‡•á‡§∏‡§æ‡§ñ‡•ç‡§§‡§æ) ‡§ï‡§π ‡§â‡§†‡§§‡•á ‡§π‡•à‡§Ç ‡§ï‡§ø ‡§ñ‡§º‡•Å‡§¶‡§æ‡§µ‡§®‡•ç‡§¶‡§æ ‡§§‡•Ç‡§®‡•á ‡§á‡§∏‡§ï‡•ã ‡§¨‡•á‡§ï‡§æ‡§∞ ‡§™‡•à‡§¶‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§ø‡§Ø‡§æ ‡§§‡•Ç (‡§´‡•á‡§≤‡•á ‡§Ö‡§¨‡§∏ ‡§∏‡•á) ‡§™‡§æ‡§ï ‡§µ ‡§™‡§æ‡§ï‡•Ä‡§ú‡§º‡§æ ‡§π‡•à ‡§¨‡§∏ ‡§π‡§Æ‡§ï‡•ã ‡§¶‡•ã‡§ú‡§º‡§ï ‡§ï‡•á ‡§Ö‡§ú‡§º‡§æ‡§¨ ‡§∏‡•á ‡§¨‡§ö‡§æ\n",
      "HI (Predicted): ‡§ú‡•ã ‡§≤‡•ã‡§ó ‡§Ö‡§≤‡•ç‡§≤‡§æ‡§π ‡§ï‡•Ä ‡§ì‡§∞ ‡§ñ‡§°‡§º‡•á ‡§π‡•Å‡§è ‡§¨‡•à‡§†‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§Ö‡§™‡§®‡•á ‡§ï‡§ø‡§®‡§æ‡§∞‡•ã‡§Ç ‡§™‡§∞ ‡§ù‡•Ç‡§† ‡§¨‡•ã‡§≤‡§§‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§Ü‡§ï‡§æ‡§∂‡•ã‡§Ç ‡§î‡§∞ ‡§ß‡§∞‡§§‡•Ä ‡§ï‡•Ä ‡§∏‡§Ç‡§∞‡§ö‡§®‡§æ ‡§™‡§∞ ‡§™‡•ç‡§∞‡§§‡§ø‡§¨‡§ø‡§Ç‡§¨‡§ø‡§§ ‡§π‡•ã‡§§‡•á ‡§π‡•à‡§Ç, ‡§î‡§∞ ‡§§‡•Å‡§Æ ‡§π‡§Æ‡§æ‡§∞‡§æ ‡§∞‡§¨ ‡§π‡§Æ‡§®‡•á ‡§á‡§∏ ‡§µ‡•ç‡§Ø‡§∞‡•ç‡§•‡§§‡§æ ‡§ï‡•ã ‡§™‡•à‡§¶‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§ø‡§Ø‡§æ‡•§ ‡§§‡•Å‡§Æ ‡§§‡•ã ‡§π‡§Æ ‡§™‡§∞ ‡§Ü‡§ó ‡§ï‡•Ä ‡§Ø‡§æ‡§§‡§®‡§æ ‡§∏‡•á ‡§¨‡§ö ‡§ó‡§è\n",
      "--------------------------------------------------\n",
      "\n",
      "EN: I am not scared of them.\n",
      "HI (Reference): ‡§Æ‡•à‡§Ç ‡§â‡§®‡§ï‡•Ä ‡§ß‡§Æ‡§ï‡§ø‡§Ø‡•ã‡§Ç ‡§∏‡•á ‡§°‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§π‡•Ç‡§Ç‡•§\n",
      "HI (Predicted): ‡§Æ‡•à‡§Ç ‡§â‡§®‡§∏‡•á ‡§°‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç‡•§\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# ‚úÖ Evaluation on Test Set\n",
    "# =====================\n",
    "from torch.nn.functional import log_softmax\n",
    "import math\n",
    "\n",
    "# ---- Load best model ----\n",
    "model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "print(\"‚úÖ Loaded best model for evaluation.\")\n",
    "\n",
    "# =====================\n",
    "# Greedy Decoding\n",
    "# =====================\n",
    "def greedy_decode(model, src, max_len=MAX_GEN_LEN):\n",
    "    model.eval()\n",
    "    src_mask = create_padding_mask(src, 'en')\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.full((src.size(0), 1), BOS_HI, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    for i in range(max_len - 1):\n",
    "        tgt_mask = generate_square_subsequent_mask(ys.size(1))\n",
    "        tgt_key_padding_mask = create_padding_mask(ys, 'hi')\n",
    "\n",
    "        out = model.decode(\n",
    "            ys, memory, tgt_mask=tgt_mask,\n",
    "            memory_key_padding_mask=src_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "        out = model.fc_out(out[:, -1, :])\n",
    "        next_word = out.argmax(dim=-1, keepdim=True)\n",
    "        ys = torch.cat([ys, next_word], dim=1)\n",
    "\n",
    "        # Stop if EOS is reached for all\n",
    "        if torch.all(next_word.squeeze() == EOS_HI):\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# =====================\n",
    "# Beam Search Decoding\n",
    "# =====================\n",
    "def beam_search_decode(model, src, beam_size=BEAM_SIZE, max_len=MAX_GEN_LEN):\n",
    "    model.eval()\n",
    "    src_mask = create_padding_mask(src, 'en')\n",
    "    memory = model.encode(src, src_mask)\n",
    "\n",
    "    batch_size = src.size(0)\n",
    "    results = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        beams = [(torch.tensor([[BOS_HI]], device=DEVICE), 0.0)]\n",
    "        for _ in range(max_len - 1):\n",
    "            new_beams = []\n",
    "            for seq, score in beams:\n",
    "                if seq[0, -1].item() == EOS_HI:\n",
    "                    new_beams.append((seq, score))\n",
    "                    continue\n",
    "\n",
    "                tgt_mask = generate_square_subsequent_mask(seq.size(1))\n",
    "                tgt_key_padding_mask = create_padding_mask(seq, 'hi')\n",
    "                out = model.decode(\n",
    "                    seq, memory[i:i+1],\n",
    "                    tgt_mask=tgt_mask,\n",
    "                    memory_key_padding_mask=src_mask[i:i+1],\n",
    "                    tgt_key_padding_mask=tgt_key_padding_mask\n",
    "                )\n",
    "                logits = model.fc_out(out[:, -1, :])\n",
    "                log_probs = log_softmax(logits, dim=-1)\n",
    "                topk_log_probs, topk_indices = torch.topk(log_probs, beam_size)\n",
    "\n",
    "                for k in range(beam_size):\n",
    "                    next_seq = torch.cat([seq, topk_indices[:, k].unsqueeze(1)], dim=1)\n",
    "                    new_beams.append((next_seq, score + topk_log_probs[0, k].item()))\n",
    "\n",
    "            beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_size]\n",
    "\n",
    "            if all(seq[0, -1].item() == EOS_HI for seq, _ in beams):\n",
    "                break\n",
    "\n",
    "        best_seq = beams[0][0]\n",
    "        results.append(best_seq)\n",
    "    return results\n",
    "\n",
    "\n",
    "# =====================\n",
    "# Evaluate BLEU on Test Set\n",
    "# =====================\n",
    "references, hypotheses = [], []\n",
    "for batch_idx, (src, tgt) in enumerate(tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\")):\n",
    "    src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        pred = greedy_decode(model, src)\n",
    "    for i in range(src.size(0)):\n",
    "        tgt_tokens = tgt[i].tolist()\n",
    "        pred_tokens = pred[i].tolist()\n",
    "\n",
    "        tgt_text = sp_hi.decode([t for t in tgt_tokens if t not in [PAD_HI, BOS_HI, EOS_HI]])\n",
    "        pred_text = sp_hi.decode([t for t in pred_tokens if t not in [PAD_HI, BOS_HI, EOS_HI]])\n",
    "\n",
    "        references.append([tgt_text])\n",
    "        hypotheses.append(pred_text)\n",
    "\n",
    "# ---- Compute BLEU ----\n",
    "bleu = sacrebleu.corpus_bleu(hypotheses, list(zip(*references)))\n",
    "print(f\"üåç Test BLEU score: {bleu.score:.2f}\")\n",
    "\n",
    "# =====================\n",
    "# Show Some Examples\n",
    "# =====================\n",
    "print(\"\\nüîç Sample Translations:\")\n",
    "for i in range(5):\n",
    "    src_ids, tgt_ids = test_data[i][\"src\"], test_data[i][\"tgt\"]\n",
    "    src_tensor = torch.tensor([[BOS_EN] + sp_en.encode(src_ids.lower())[:MAX_LEN-2] + [EOS_EN]], device=DEVICE)\n",
    "    pred = greedy_decode(model, src_tensor)\n",
    "    pred_tokens = pred[0].tolist()\n",
    "    pred_text = sp_hi.decode([t for t in pred_tokens if t not in [PAD_HI, BOS_HI, EOS_HI]])\n",
    "\n",
    "    print(f\"\\nEN: {test_data[i]['src']}\")\n",
    "    print(f\"HI (Reference): {test_data[i]['tgt']}\")\n",
    "    print(f\"HI (Predicted): {pred_text}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rkOiMjxPl8D",
    "outputId": "9ef64c73-dd9e-4994-dda1-dbac2db55e2c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\.conda\\envs\\mt_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: 800000 100000 100000\n",
      "üîÅ Resuming from checkpoint_cnn.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_13800\\227662617.py:206: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Checkpoint loaded ‚Äî Resuming from epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30:   0%|                                                                        | 0/12500 [00:00<?, ?batch/s]C:\\Users\\Ayush\\.conda\\envs\\mt_env\\lib\\site-packages\\torch\\nn\\functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch 23/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12500/12500 [12:50<00:00, 16.22batch/s]\n",
      "C:\\Users\\Ayush\\.conda\\envs\\mt_env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:502: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\NestedTensorImpl.cpp:180.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 1.5992 | Val Loss: 2.4764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12500/12500 [12:51<00:00, 16.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 1.5465 | Val Loss: 2.4910\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "üéØ Training complete.\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Imports & Setup\n",
    "# =====================\n",
    "!pip install -q datasets sentencepiece sacrebleu torch torchvision torchaudio tqdm\n",
    "\n",
    "import os, random\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import sentencepiece as spm\n",
    "import sacrebleu\n",
    "\n",
    "# =====================\n",
    "# Config\n",
    "# =====================\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "VOCAB_SIZE = 16000\n",
    "BATCH_SIZE = 64\n",
    "MAX_LEN = 64\n",
    "MAX_GEN_LEN = 64\n",
    "EPOCHS = 30\n",
    "CLIP = 1.0\n",
    "LEARNING_RATE = 3e-4\n",
    "BEAM_SIZE = 5\n",
    "BEST_MODEL_PATH = Path(\"best_model_cnn.pt\")\n",
    "CHECKPOINT_PATH = Path(\"checkpoint_cnn.pt\")\n",
    "PATIENCE = 5\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# =====================\n",
    "# Load dataset (up to 1M)\n",
    "# =====================\n",
    "full_dataset = load_dataset(\"ai4bharat/samanantar\", \"hi\", split=\"train\")\n",
    "full_dataset = full_dataset.shuffle(seed=SEED)\n",
    "\n",
    "NUM_EXAMPLES = min(1_000_000, len(full_dataset))\n",
    "subset = full_dataset.select(range(NUM_EXAMPLES))\n",
    "\n",
    "# Split 80/10/10\n",
    "train_end = int(0.8 * len(subset))\n",
    "val_end = int(0.9 * len(subset))\n",
    "train_data = subset.select(range(0, train_end))\n",
    "val_data = subset.select(range(train_end, val_end))\n",
    "test_data = subset.select(range(val_end, len(subset)))\n",
    "\n",
    "print(\"Dataset sizes:\", len(train_data), len(val_data), len(test_data))\n",
    "\n",
    "# =====================\n",
    "# SentencePiece\n",
    "# =====================\n",
    "SP_EN_MODEL = Path(\"spm_en.model\")\n",
    "SP_HI_MODEL = Path(\"spm_hi.model\")\n",
    "\n",
    "def write_lines(dataset_split, src_path, tgt_path):\n",
    "    with open(src_path, \"w\", encoding=\"utf-8\") as sf, open(tgt_path, \"w\", encoding=\"utf-8\") as tf:\n",
    "        for ex in dataset_split:\n",
    "            sf.write(ex[\"src\"].strip().lower() + \"\\n\")\n",
    "            tf.write(ex[\"tgt\"].strip() + \"\\n\")\n",
    "\n",
    "write_lines(train_data, \"train.en\", \"train.hi\")\n",
    "\n",
    "if not SP_EN_MODEL.exists() or not SP_HI_MODEL.exists():\n",
    "    print(\"Training SentencePiece...\")\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f\"--input=train.en --model_prefix=spm_en --vocab_size={VOCAB_SIZE} \"\n",
    "        f\"--character_coverage=1.0 --model_type=unigram\"\n",
    "    )\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f\"--input=train.hi --model_prefix=spm_hi --vocab_size={VOCAB_SIZE} \"\n",
    "        f\"--character_coverage=0.9995 --model_type=unigram\"\n",
    "    )\n",
    "\n",
    "sp_en = spm.SentencePieceProcessor()\n",
    "sp_hi = spm.SentencePieceProcessor()\n",
    "sp_en.load(str(SP_EN_MODEL))\n",
    "sp_hi.load(str(SP_HI_MODEL))\n",
    "\n",
    "PAD_EN, BOS_EN, EOS_EN = 0, 1, 2\n",
    "PAD_HI, BOS_HI, EOS_HI = 0, 1, 2\n",
    "\n",
    "# =====================\n",
    "# Dataset & DataLoader\n",
    "# =====================\n",
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, dataset, src_sp, tgt_sp, max_len=MAX_LEN):\n",
    "        self.dataset = dataset\n",
    "        self.src_sp = src_sp\n",
    "        self.tgt_sp = tgt_sp\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_text = self.dataset[idx][\"src\"].lower()\n",
    "        tgt_text = self.dataset[idx][\"tgt\"]\n",
    "        src_ids = [BOS_EN] + self.src_sp.encode(src_text)[:self.max_len-2] + [EOS_EN]\n",
    "        tgt_ids = [BOS_HI] + self.tgt_sp.encode(tgt_text)[:self.max_len-2] + [EOS_HI]\n",
    "        src_ids += [PAD_EN] * (self.max_len - len(src_ids))\n",
    "        tgt_ids += [PAD_HI] * (self.max_len - len(tgt_ids))\n",
    "        return torch.tensor(src_ids), torch.tensor(tgt_ids)\n",
    "\n",
    "def get_loader(dataset_split, shuffle=True):\n",
    "    return DataLoader(NMTDataset(dataset_split, sp_en, sp_hi),\n",
    "                      batch_size=BATCH_SIZE, shuffle=shuffle)\n",
    "\n",
    "train_loader = get_loader(train_data)\n",
    "val_loader = get_loader(val_data)\n",
    "test_loader = get_loader(test_data, shuffle=False)\n",
    "\n",
    "# =====================\n",
    "# Masks\n",
    "# =====================\n",
    "def create_padding_mask(seq, lang='en'):\n",
    "    pad_id = PAD_EN if lang == 'en' else PAD_HI\n",
    "    return (seq == pad_id)\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    return torch.triu(torch.ones(sz, sz, device=DEVICE) * float('-inf'), diagonal=1)\n",
    "\n",
    "# =====================\n",
    "# CNN Feature Extractor (2-layer)\n",
    "# =====================\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(embed_dim, embed_dim, kernel_size=5, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(embed_dim, embed_dim, kernel_size=3, padding=1)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        return self.norm(x + residual)\n",
    "\n",
    "# =====================\n",
    "# Hybrid CNN + Transformer Model\n",
    "# =====================\n",
    "class HybridTransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=512, nhead=8,\n",
    "                 num_layers=3, dim_feedforward=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab, d_model, padding_idx=PAD_EN)\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab, d_model, padding_idx=PAD_HI)\n",
    "        self.pos_enc = nn.Parameter(torch.zeros(1, MAX_LEN, d_model))\n",
    "        self.cnn_encoder = CNNFeatureExtractor(d_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            num_encoder_layers=num_layers, num_decoder_layers=num_layers,\n",
    "            dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab)\n",
    "\n",
    "    def encode(self, src, src_key_padding_mask):\n",
    "        src_emb = self.src_emb(src) + self.pos_enc[:, :src.size(1), :]\n",
    "        src_cnn = self.cnn_encoder(src_emb)\n",
    "        return self.transformer.encoder(src_cnn, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask):\n",
    "        tgt_emb = self.tgt_emb(tgt) + self.pos_enc[:, :tgt.size(1), :]\n",
    "        return self.transformer.decoder(\n",
    "            tgt_emb, memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_key_padding_mask=memory_key_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None,\n",
    "                memory_key_padding_mask=None, tgt_mask=None):\n",
    "        memory = self.encode(src, src_key_padding_mask)\n",
    "        output = self.decode(tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask)\n",
    "        return self.fc_out(output)\n",
    "\n",
    "# =====================\n",
    "# Training Setup\n",
    "# =====================\n",
    "model = HybridTransformerModel(len(sp_en), len(sp_hi)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_HI)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=LEARNING_RATE, steps_per_epoch=len(train_loader), epochs=EPOCHS\n",
    ")\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "start_epoch = 1\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# =====================\n",
    "# Resume from Checkpoint (if available)\n",
    "# =====================\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    print(f\"üîÅ Resuming from {CHECKPOINT_PATH}...\")\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_val_loss = checkpoint['best_val_loss']\n",
    "    epochs_no_improve = checkpoint['epochs_no_improve']\n",
    "\n",
    "    print(f\"‚úÖ Checkpoint loaded ‚Äî Resuming from epoch {start_epoch}\")\n",
    "else:\n",
    "    print(\"üöÄ Starting training from scratch\")\n",
    "\n",
    "# =====================\n",
    "# Training Loop\n",
    "# =====================\n",
    "for epoch in range(start_epoch, EPOCHS + 1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for src, tgt in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\", unit=\"batch\"):\n",
    "        src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "        src_mask = create_padding_mask(src, 'en')\n",
    "        tgt_input, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "        tgt_mask = generate_square_subsequent_mask(tgt_input.size(1))\n",
    "        tgt_key_padding_mask = create_padding_mask(tgt_input, 'hi')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type=\"cuda\"):\n",
    "            logits = model(\n",
    "                src, tgt_input,\n",
    "                src_key_padding_mask=src_mask,\n",
    "                tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                memory_key_padding_mask=src_mask,\n",
    "                tgt_mask=tgt_mask\n",
    "            )\n",
    "            loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in val_loader:\n",
    "            src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "            src_mask = create_padding_mask(src, 'en')\n",
    "            tgt_input, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "            tgt_mask = generate_square_subsequent_mask(tgt_input.size(1))\n",
    "            tgt_key_padding_mask = create_padding_mask(tgt_input, 'hi')\n",
    "\n",
    "            logits = model(\n",
    "                src, tgt_input,\n",
    "                src_key_padding_mask=src_mask,\n",
    "                tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                memory_key_padding_mask=src_mask,\n",
    "                tgt_mask=tgt_mask\n",
    "            )\n",
    "            loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # ---- Save Checkpoint ----\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "        \"scaler_state_dict\": scaler.state_dict(),\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "        \"epochs_no_improve\": epochs_no_improve,\n",
    "        \"config\": {\n",
    "            \"MODEL_TYPE\": \"HybridCNNTransformer\",\n",
    "            \"VOCAB_SIZE\": VOCAB_SIZE,\n",
    "            \"MAX_LEN\": MAX_LEN,\n",
    "            \"EPOCHS\": EPOCHS,\n",
    "            \"LEARNING_RATE\": LEARNING_RATE,\n",
    "            \"CLIP\": CLIP,\n",
    "            \"BATCH_SIZE\": BATCH_SIZE\n",
    "        }\n",
    "    }, CHECKPOINT_PATH)\n",
    "\n",
    "    # ---- Early Stopping ----\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        print(\"‚úÖ New best model saved!\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(\"‚èπÔ∏è Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"üéØ Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbdHuTG-Pl8H",
    "outputId": "0c1a6b74-cdc2-4478-f436-d436a2f0412a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_13800\\3408616981.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model_cnn.pt\", map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating BLEU on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1563/1563 [1:49:34<00:00,  4.21s/batch]\n",
      "That's 100 lines that end in a tokenized period ('.')\n",
      "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåç BLEU Score on Test Set: 19.00\n",
      "\n",
      "‚ú® Sample Translations:\n",
      "\n",
      "EN: lahore: The Pakistan English press has showered heap of praise on legendary Indian batsman Sachin Tendulkar in their editorials, saying the game of cricket will surely be poorer without him.\n",
      "HI (Ref): ‡§≤‡§æ‡§π‡•å‡§∞ ‡§™‡§æ‡§ï‡§ø‡§∏‡•ç‡§§‡§æ‡§® ‡§ï‡•Ä ‡§Ö‡§ó‡•ç‡§∞‡•á‡§Ç‡§ú‡•Ä ‡§™‡•ç‡§∞‡•á‡§∏ ‡§®‡•á ‡§Ö‡§™‡§®‡•á ‡§∏‡§Ç‡§™‡§æ‡§¶‡§ï‡•Ä‡§Ø ‡§Æ‡•á‡§Ç ‡§Æ‡§π‡§æ‡§® ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§¨‡§≤‡•ç‡§≤‡•á‡§¨‡§æ‡§ú ‡§∏‡§ö‡§ø‡§® ‡§§‡•á‡§Ç‡§¶‡•Å‡§≤‡§ï‡§∞ ‡§ï‡•Ä ‡§§‡§æ‡§∞‡•Ä‡§´‡•ã‡§Ç ‡§ï‡•á ‡§™‡•Å‡§≤ ‡§¨‡§æ‡§Ç‡§ß‡•á ‡§π‡•à ‡§î‡§∞ ‡§≤‡§ø‡§ñ‡§æ ‡§π‡•à, ‚Äò‡§â‡§®‡§ï‡•á ‡§¨‡§ø‡§®‡§æ ‡§ï‡•ç‡§∞‡§ø‡§ï‡•á‡§ü ‡§ñ‡•á‡§≤ ‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§¶‡§∞‡§ø‡§¶‡•ç‡§∞‚Äô ‡§π‡•ã ‡§ú‡§æ‡§Ø‡•á‡§ó‡§æ‡•§ ‡§π‡§æ‡§≤‡§æ‡§Ç‡§ï‡§ø ‡§â‡§∞‡•ç‡§¶‡•Ç ‡§™‡•ç‡§∞‡•á‡§∏ ‡§Æ‡•á‡§Ç ‡§â‡§®‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§ú‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§ï‡•Å‡§õ ‡§®‡§π‡•Ä‡§Ç ‡§≤‡§ø‡§ñ‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à ‡§≤‡•á‡§ï‡§ø‡§® ‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä ‡§ï‡•á ‡§Ö‡§ñ‡§¨‡§æ‡§∞‡•ã‡§Ç ‡§®‡•á ‡§§‡•á‡§Ç‡§¶‡•Å‡§≤‡§ï‡§∞... ‡§Ü‡§ó‡•á ‡§™‡•ù‡•á\n",
      "HI (Pred): ‡§™‡§æ‡§ï‡§ø‡§∏‡•ç‡§§‡§æ‡§® ‡§ï‡•á ‡§á‡§Ç‡§ó‡•ç‡§≤‡§ø‡§∂ ‡§™‡•ç‡§∞‡•Ä‡§Æ‡§ø‡§Ø‡§∞ ‡§≤‡•Ä‡§ó (‡§è‡§Ü‡§à‡§∏‡•Ä‡§∏‡•Ä) ‡§ï‡•á ‡§™‡•ç‡§∞‡§ñ‡•ç‡§Ø‡§æ‡§§ ‡§¨‡§≤‡•ç‡§≤‡•á‡§¨‡§æ‡§ú ‡§∏‡§ö‡§ø‡§® ‡§§‡•á‡§Ç‡§¶‡•Å‡§≤‡§ï‡§∞ ‡§®‡•á ‡§Ö‡§™‡§®‡•á ‡§∏‡§Ç‡§™‡§æ‡§¶‡§ï‡•Ä‡§Ø ‡§Æ‡•á‡§Ç ‡§ï‡§π‡§æ ‡§π‡•à ‡§ï‡§ø ‡§ï‡•ç‡§∞‡§ø‡§ï‡•á‡§ü ‡§ï‡§æ ‡§ñ‡•á‡§≤ ‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§â‡§®‡§ï‡•á ‡§¨‡§ø‡§®‡§æ ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡§æ ‡§π‡•ã‡§ó‡§æ‡•§\n",
      "--------------------------------------------------\n",
      "\n",
      "EN: Telecom operator Reliance Jio has announced a new plan for its prepaid customers.\n",
      "HI (Ref): ‡§ü‡•á‡§≤‡•Ä‡§ï‡•â‡§Æ ‡§á‡§Ç‡§°‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä ‡§Æ‡•á‡§Ç ‡§§‡§π‡§≤‡§ï‡§æ ‡§Æ‡§ö‡§®‡•á ‡§µ‡§æ‡§≤‡•Ä ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§∞‡§ø‡§≤‡§æ‡§Ø‡§Ç‡§∏ ‡§ú‡§ø‡§Ø‡•ã ‡§®‡•á ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§Ö‡§™‡§®‡•á ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§è ‡§™‡•ç‡§≤‡§æ‡§®‡•ç‡§∏ ‡§™‡•á‡§∂ ‡§ï‡§ø‡§Ø‡•á\n",
      "HI (Pred): ‡§ü‡•á‡§≤‡•Ä‡§ï‡•â‡§Æ ‡§ë‡§™‡§∞‡•á‡§ü‡§∞ ‡§∞‡§ø‡§≤‡§æ‡§Ø‡§Ç‡§∏ ‡§ú‡§ø‡§Ø‡•ã ‡§®‡•á ‡§Ö‡§™‡§®‡•á ‡§™‡•ç‡§∞‡•Ä‡§™‡•á‡§° ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§Ø‡§æ ‡§™‡•ç‡§≤‡§æ‡§® ‡§≤‡•â‡§®‡•ç‡§ö ‡§ï‡§∞ ‡§¶‡§ø‡§Ø‡§æ ‡§π‡•à‡•§\n",
      "--------------------------------------------------\n",
      "\n",
      "EN: Meanwhile, the police have initiated the investigation after the arrest of two persons.\n",
      "HI (Ref): ‡§´‡§ø‡§≤‡§π‡§æ‡§≤ ‡§™‡•Å‡§≤‡§ø‡§∏ ‡§®‡•á ‡§¶‡•ã ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•ã ‡§π‡§ø‡§∞‡§æ‡§∏‡§§ ‡§Æ‡•á‡§Ç ‡§≤‡•á‡§ï‡§∞ ‡§™‡•Ç‡§õ‡§§‡§æ‡§õ ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞ ‡§¶‡•Ä ‡§π‡•à‡•§\n",
      "HI (Pred): ‡§µ‡§π‡•Ä‡§Ç ‡§™‡•Å‡§≤‡§ø‡§∏ ‡§®‡•á ‡§¶‡•ã ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•Ä ‡§ó‡§ø‡§∞‡§´‡•ç‡§§‡§æ‡§∞‡•Ä ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§ú‡§æ‡§Ç‡§ö ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞ ‡§¶‡•Ä ‡§π‡•à‡•§\n",
      "--------------------------------------------------\n",
      "\n",
      "EN: New Delhi, September 2\n",
      "HI (Ref): ‡§®‡§Ø‡•Ä ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä, 2 ‡§∏‡§ø‡§§‡§Ç‡§¨‡§∞ (‡§≠‡§æ‡§∑‡§æ)‡•§\n",
      "HI (Pred): ‡§®‡§Ø‡•Ä ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä, 2 ‡§∏‡§ø‡§§‡§Ç‡§¨‡§∞ (‡§è‡§ú‡•á‡§Ç‡§∏‡•Ä)\n",
      "--------------------------------------------------\n",
      "\n",
      "EN: Below them is seated a scribe recording the interpretation.\n",
      "HI (Ref): ‡§á‡§∏‡•á ‡§®‡•Ä‡§ö‡•á ‡§¨‡•à‡§†‡§æ ‡§≤‡§ø‡§™‡§ø‡§ï ‡§≤‡§ø‡§™‡§ø‡§¨‡§¶‡•ç‡§ß ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à‡•§\n",
      "HI (Pred): ‡§®‡•Ä‡§ö‡•á ‡§¶‡§ø‡§è ‡§ó‡§è ‡§è‡§ï ‡§≤‡•á‡§ñ‡§ï ‡§ï‡•Ä ‡§µ‡•ç‡§Ø‡§æ‡§ñ‡•ç‡§Ø‡§æ ‡§ï‡§æ ‡§∞‡§ø‡§ï‡§æ‡§∞‡•ç‡§° ‡§π‡•à‡•§\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# BLEU Evaluation + Translation\n",
    "# =====================\n",
    "import torch\n",
    "import sacrebleu\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Load SentencePiece models again (if running separately)\n",
    "sp_en = spm.SentencePieceProcessor()\n",
    "sp_hi = spm.SentencePieceProcessor()\n",
    "sp_en.load(\"spm_en.model\")\n",
    "sp_hi.load(\"spm_hi.model\")\n",
    "\n",
    "PAD_EN, BOS_EN, EOS_EN = 0, 1, 2\n",
    "PAD_HI, BOS_HI, EOS_HI = 0, 1, 2\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Reload the best model\n",
    "model = HybridTransformerModel(len(sp_en), len(sp_hi)).to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"best_model_cnn.pt\", map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# =====================\n",
    "# Greedy / Beam Decoding\n",
    "# =====================\n",
    "@torch.no_grad()\n",
    "def translate_sentence(sentence, model, sp_en, sp_hi, max_len=64, beam_size=5):\n",
    "    model.eval()\n",
    "    src_ids = [BOS_EN] + sp_en.encode(sentence.lower())[:max_len-2] + [EOS_EN]\n",
    "    src = torch.tensor(src_ids, dtype=torch.long, device=DEVICE).unsqueeze(0)\n",
    "    src_mask = create_padding_mask(src, 'en')\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "\n",
    "    # ---- Start with BOS token ----\n",
    "    tgt = torch.tensor([[BOS_HI]], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        tgt_mask = generate_square_subsequent_mask(tgt.size(1))\n",
    "        tgt_key_padding_mask = create_padding_mask(tgt, 'hi')\n",
    "\n",
    "        output = model.decode(\n",
    "            tgt, memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_key_padding_mask=src_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "        logits = model.fc_out(output[:, -1, :])\n",
    "        next_token = logits.argmax(-1).item()\n",
    "\n",
    "        tgt = torch.cat([tgt, torch.tensor([[next_token]], device=DEVICE)], dim=1)\n",
    "        if next_token == EOS_HI:\n",
    "            break\n",
    "\n",
    "    decoded = sp_hi.decode([t for t in tgt.squeeze().tolist() if t not in [BOS_HI, EOS_HI, PAD_HI]])\n",
    "    return decoded\n",
    "\n",
    "\n",
    "# =====================\n",
    "# BLEU Evaluation\n",
    "# =====================\n",
    "refs, hyps = [], []\n",
    "\n",
    "print(\"üîç Evaluating BLEU on test set...\")\n",
    "for src, tgt in tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\"):\n",
    "    src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "    for i in range(src.size(0)):\n",
    "        src_text = sp_en.decode([t for t in src[i].tolist() if t not in [BOS_EN, EOS_EN, PAD_EN]])\n",
    "        tgt_text = sp_hi.decode([t for t in tgt[i].tolist() if t not in [BOS_HI, EOS_HI, PAD_HI]])\n",
    "        pred_text = translate_sentence(src_text, model, sp_en, sp_hi)\n",
    "\n",
    "        refs.append(tgt_text)\n",
    "        hyps.append(pred_text)\n",
    "\n",
    "# sacrebleu expects a list of references (list of list)\n",
    "bleu = sacrebleu.corpus_bleu(hyps, [refs])\n",
    "print(f\"\\nüåç BLEU Score on Test Set: {bleu.score:.2f}\\n\")\n",
    "\n",
    "# =====================\n",
    "# Qualitative Examples\n",
    "# =====================\n",
    "sample_indices = random.sample(range(len(test_data)), 5)\n",
    "print(\"‚ú® Sample Translations:\")\n",
    "for idx in sample_indices:\n",
    "    src_text = test_data[idx][\"src\"]\n",
    "    ref_text = test_data[idx][\"tgt\"]\n",
    "    pred_text = translate_sentence(src_text, model, sp_en, sp_hi)\n",
    "    print(f\"\\nEN: {src_text}\")\n",
    "    print(f\"HI (Ref): {ref_text}\")\n",
    "    print(f\"HI (Pred): {pred_text}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8nSwiFDAPl8I",
    "outputId": "d6919d02-f6cf-41f9-8187-472d081d059b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_17296\\2967338906.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path, map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EN: The city is preparing for heavy rainfall this week.\n",
      "Reference HI: ‡§∂‡§π‡§∞ ‡§á‡§∏ ‡§∏‡§™‡•ç‡§§‡§æ‡§π ‡§≠‡§æ‡§∞‡•Ä ‡§µ‡§∞‡•ç‡§∑‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•à‡§Ø‡§æ‡§∞‡•Ä ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à‡•§\n",
      "Baseline: ‡§á‡§∏ ‡§∏‡§™‡•ç‡§§‡§æ‡§π ‡§§‡•á‡§ú ‡§¨‡§æ‡§∞‡§ø‡§∂ ‡§ï‡•Ä ‡§§‡•à‡§Ø‡§æ‡§∞‡§ø‡§Ø‡§æ‡§Ç ‡§ö‡§≤ ‡§∞‡§π‡•Ä ‡§π‡•à‡§Ç‡•§\n",
      "Hybrid CNN: ‡§á‡§∏ ‡§∏‡§™‡•ç‡§§‡§æ‡§π ‡§§‡•á‡§ú ‡§¨‡§æ‡§∞‡§ø‡§∂ ‡§ï‡•Ä ‡§§‡•à‡§Ø‡§æ‡§∞‡•Ä ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à‡•§\n",
      "\n",
      "EN: Researchers developed a new method for early disease detection.\n",
      "Reference HI: ‡§∂‡•ã‡§ß‡§ï‡§∞‡•ç‡§§‡§æ‡§ì‡§Ç ‡§®‡•á ‡§ú‡§≤‡•ç‡§¶‡•Ä ‡§∞‡•ã‡§ó ‡§™‡§π‡§ö‡§æ‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§®‡§à ‡§µ‡§ø‡§ß‡§ø ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§ï‡•Ä‡•§\n",
      "Baseline: \"\"\" \"\"‡§ë‡§ï‡•ç‡§∏‡§´‡•ã‡§∞‡•ç‡§°‡•á‡§¨‡§≤‡•ç‡§∏ ‡§®‡•á ‡§∂‡•Å‡§∞‡•Å‡§Ü‡§§‡•Ä ‡§¨‡•Ä‡§Æ‡§æ‡§∞‡•Ä ‡§ï‡§æ ‡§™‡§§‡§æ ‡§≤‡§ó‡§æ‡§®‡•á ‡§ï‡•Ä ‡§è‡§ï ‡§®‡§Ø‡§æ ‡§§‡§∞‡•Ä‡§ï‡§æ ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à.\"\"\"\n",
      "Hybrid CNN: ‡§∞‡§æ‡§´‡•à‡§≤‡•á ‡§®‡•á ‡§ú‡§≤‡•ç‡§¶‡•Ä ‡§ï‡•Ä ‡§™‡§π‡§ö‡§æ‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§®‡§à ‡§§‡§ï‡§®‡•Ä‡§ï ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§ï‡•Ä.\n",
      "\n",
      "EN: The economy is showing signs of steady growth.\n",
      "Reference HI: ‡§Ö‡§∞‡•ç‡§•‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ ‡§∏‡•ç‡§•‡§ø‡§∞ ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ï‡•á ‡§∏‡§Ç‡§ï‡•á‡§§ ‡§¶‡§ø‡§ñ‡§æ ‡§∞‡§π‡•Ä ‡§π‡•à‡•§\n",
      "Baseline: ‡§Ö‡§∞‡•ç‡§•‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ ‡§Æ‡•á‡§Ç ‡§∏‡•ç‡§•‡§ø‡§∞‡§§‡§æ ‡§≤‡•å‡§ü‡§®‡•á ‡§ï‡•á ‡§∏‡§Ç‡§ï‡•á‡§§\n",
      "Hybrid CNN: ‡§∏‡•ç‡§•‡§ø‡§∞ ‡§µ‡•É‡§¶‡•ç‡§ß‡§ø ‡§ï‡•á ‡§∏‡§Ç‡§ï‡•á‡§§ ‡§¶‡•á ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§ ‡§Ö‡§∞‡•ç‡§•‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ ‡§®‡§ø‡§∞‡§Ç‡§§‡§∞ ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§π‡•à‡•§, ‡§µ‡§π ‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§Ö‡§∞‡•ç‡§•‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ, ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø ‡§µ‡§ø‡§ï‡§æ‡§∏, ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø, ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ï‡•á, ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø, ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø ‡§Ö‡§∞‡•ç‡§•‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ, ‡§ü‡§ø‡§ï‡§æ‡§ä ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ï‡•á, ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø, ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§∏‡•á, ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø, ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø ‡§Ö‡§∞‡•ç‡§•‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ, ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø, ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ï‡•á, ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø, ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ï‡•á,\n",
      "\n",
      "EN: Students participated enthusiastically in the science fair.\n",
      "Reference HI: ‡§õ‡§æ‡§§‡•ç‡§∞‡•ã‡§Ç ‡§®‡•á ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§® ‡§Æ‡•á‡§≤‡§æ ‡§Æ‡•á‡§Ç ‡§â‡§§‡•ç‡§∏‡§æ‡§π‡§™‡•Ç‡§∞‡•ç‡§µ‡§ï ‡§≠‡§æ‡§ó ‡§≤‡§ø‡§Ø‡§æ‡•§\n",
      "Baseline: ‡§ï‡•ç‡§∑‡§Ø‡§ü‡•ç‡§ü‡§ø‡§Ø‡•ã‡§Ç ‡§®‡•á ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§® ‡§Æ‡•á‡§≤‡•á ‡§Æ‡•á‡§Ç ‡§¨‡§¢‡§º-‡§ö‡§¢‡§º‡§ï‡§∞ ‡§≠‡§æ‡§ó ‡§≤‡§ø‡§Ø‡§æ‡•§\n",
      "Hybrid CNN: ‡§Æ‡•á‡§≤‡•á ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§® ‡§Æ‡•á‡§≤‡•á ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§∑‡§£ ‡§¶‡•á‡§®‡•á ‡§µ‡§æ‡§≤‡•ã‡§Ç ‡§®‡•á ‡§¨‡§¢‡§º ‡§ï‡§∞ ‡§π‡§ø‡§∏‡•ç‡§∏‡§æ ‡§≤‡§ø‡§Ø‡§æ‡•§\n",
      "\n",
      "EN: The festival attracted tourists from all over the world.\n",
      "Reference HI: ‡§§‡•ç‡§Ø‡•ã‡§π‡§æ‡§∞ ‡§®‡•á ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§≠‡§∞ ‡§∏‡•á ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï‡•ã‡§Ç ‡§ï‡•ã ‡§Ü‡§ï‡§∞‡•ç‡§∑‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ‡•§\n",
      "Baseline: ‡§á‡§∏ ‡§Æ‡§π‡•ã‡§§‡•ç‡§∏‡§µ ‡§Æ‡•á‡§Ç ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§≠‡§∞ ‡§∏‡•á ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§ñ‡§ø‡§Ç‡§ö‡•á ‡§ö‡§≤‡•á ‡§Ü ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§\n",
      "Hybrid CNN: ‡§≠‡§µ‡•ç‡§Ø ‡§∏‡§Æ‡§æ‡§∞‡•ã‡§π ‡§®‡•á ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§≠‡§∞ ‡§∏‡•á ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§Ü‡§ï‡§∞‡•ç‡§∑‡§ø‡§§ ‡§ï‡§ø‡§è‡•§\n",
      "\n",
      "EN: Solar energy installations are increasing rapidly in rural areas.\n",
      "Reference HI: ‡§ó‡•ç‡§∞‡§æ‡§Æ‡•Ä‡§£ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡•å‡§∞ ‡§ä‡§∞‡•ç‡§ú‡§æ ‡§∏‡•ç‡§•‡§æ‡§™‡§®‡§æ ‡§§‡•á‡§ú‡•Ä ‡§∏‡•á ‡§¨‡§¢‡§º ‡§∞‡§π‡•Ä ‡§π‡•à‡•§\n",
      "Baseline: ‡§è‡§Æ‡§ì‡§è‡§´‡§™‡•Ä‡§Ü‡§à ‡§∏‡§Æ‡§∞‡•ç‡§•‡§ø‡§§ ‡§ä‡§∞‡•ç‡§ú‡§æ ‡§∏‡§Ç‡§Ø‡§Ç‡§§‡•ç‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§§‡•á‡§ú‡•Ä ‡§∏‡•á ‡§¨‡§¢‡§º ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§\n",
      "Hybrid CNN: ‡§ó‡•ç‡§∞‡§æ‡§Æ‡•Ä‡§£ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§ä‡§∞‡•ç‡§ú‡§æ ‡§∏‡§Ç‡§Ø‡§Ç‡§§‡•ç‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§§‡•á‡§ú‡•Ä ‡§∏‡•á ‡§µ‡•É‡§¶‡•ç‡§ß‡§ø ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à‡•§\n",
      "\n",
      "EN: The new policy aims to reduce air pollution in cities.\n",
      "Reference HI: ‡§®‡§à ‡§®‡•Ä‡§§‡§ø ‡§ï‡§æ ‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø ‡§∂‡§π‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§µ‡§æ‡§Ø‡•Å ‡§™‡•ç‡§∞‡§¶‡•Ç‡§∑‡§£ ‡§ï‡•ã ‡§ï‡§Æ ‡§ï‡§∞‡§®‡§æ ‡§π‡•à‡•§\n",
      "Baseline: ‡§®‡§à ‡§®‡•Ä‡§§‡§ø ‡§ï‡§æ ‡§≤‡§ï‡•ç‡§∑‡•ç‡§Ø ‡§µ‡§æ‡§Ø‡•Å ‡§™‡•ç‡§∞‡§¶‡•Ç‡§∑‡§£ ‡§ï‡•ã ‡§ï‡§Æ ‡§ï‡§∞‡§®‡§æ ‡§π‡•à‡•§\n",
      "Hybrid CNN: ' ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§ï‡§π‡§æ ‡§ï‡§ø ‡§®‡§à ‡§®‡•Ä‡§§‡§ø ‡§∂‡§π‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§µ‡§æ‡§Ø‡•Å ‡§™‡•ç‡§∞‡§¶‡•Ç‡§∑‡§£ ‡§ï‡•ã ‡§Ö‡§™‡§®‡§æ‡§®‡§æ ‡§π‡•à‡•§'\n",
      "\n",
      "EN: Artificial intelligence can improve healthcare diagnostics.\n",
      "Reference HI: ‡§ï‡•É‡§§‡•ç‡§∞‡§ø‡§Æ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§§‡•ç‡§§‡§æ ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§¶‡•á‡§ñ‡§≠‡§æ‡§≤ ‡§®‡§ø‡§¶‡§æ‡§® ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à‡•§\n",
      "Baseline: ‡§°‡•ã‡§®‡§∞ ‡§ñ‡•Å‡§´‡§ø‡§Ø‡§æ ‡§§‡§Ç‡§§‡•ç‡§∞‡•Ä ‡§ï‡§æ‡§∞‡§ó‡§∞ ‡§¢‡§Ç‡§ó ‡§∏‡•á ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à.\n",
      "Hybrid CNN: ‡§µ‡§ø‡§∏‡§§‡•ç‡§µ‡§ø‡§ï ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§®‡§ø‡§¶‡§æ‡§® ‡§ï‡•ã ‡§¨‡•á‡§π‡§§‡§∞ ‡§¨‡§®‡§æ ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à‡•§\n",
      "\n",
      "EN: The government announced relief measures for flood-affected areas.\n",
      "Reference HI: ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§®‡•á ‡§¨‡§æ‡§¢‡§º ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§ø‡§§ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∞‡§æ‡§π‡§§ ‡§â‡§™‡§æ‡§Ø‡•ã‡§Ç ‡§ï‡•Ä ‡§ò‡•ã‡§∑‡§£‡§æ ‡§ï‡•Ä‡•§\n",
      "Baseline: ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¨‡§æ‡§¢‡§º ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§ø‡§§ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∞‡§æ‡§π‡§§ ‡§â‡§™‡§æ‡§Ø‡•ã‡§Ç ‡§ï‡•Ä ‡§ò‡•ã‡§∑‡§£‡§æ ‡§ï‡•Ä‡•§ ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§®‡•á\n",
      "Hybrid CNN: ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§®‡•á ‡§¨‡§æ‡§¢‡§º ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§ø‡§§ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∞‡§æ‡§π‡§§ ‡§â‡§™‡§æ‡§Ø‡•ã‡§Ç ‡§ï‡•Ä ‡§ò‡•ã‡§∑‡§£‡§æ ‡§ï‡•Ä ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞ ‡§ï‡•á ‡§≤‡§ø‡§è‡•§ ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§è‡§ï ‡§Ö‡§∏‡§Ç‡§ñ‡•ç‡§Ø ‡§Ü‡§™‡§¶‡§æ ‡§®‡•á‡§§‡•ç‡§∞ ‡§â‡§®‡•ç‡§Æ‡•Å‡§ï‡•ç‡§§ ‡§Ü‡§™‡§¶‡§æ ‡§§‡§§‡•ç‡§™‡§∞‡§§‡§æ ‡§ï‡•á ‡§∏‡§Æ‡§ï‡•ç‡§∑ ‡§Ü‡§™‡§¶‡§æ ‡§ï‡•á ‡§∏‡§Æ‡§ï‡•ç‡§∑ ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§ï‡•á ‡§∂‡•Ä‡§ò‡•ç‡§∞ ‡§Ü‡§™‡§¶‡§æ ‡§ï‡•á ‡§∏‡•ç‡§•‡§æ‡§®‡•ã‡§Ç ‡§ï‡•á ‡§∂‡•Ä‡§ò‡•ç‡§∞ ‡§ï‡•á ‡§∂‡•Ä‡§ò‡•ç‡§∞ ‡§ï‡•á ‡§∏‡•ç‡§•‡§æ‡§®‡•ã‡§Ç ‡§ï‡•á ‡§∂‡•Ä‡§ò‡•ç‡§∞ ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§ï‡•á ‡§≠‡•Ç‡§ï‡§Æ‡•ç‡§™ ‡§ï‡•á ‡§∂‡•Ä‡§ò‡•ç‡§∞ ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§ï‡•á ‡§≠‡•Ç‡§ï‡§Æ‡•ç‡§™ ‡§ï‡•á ‡§∂‡•Ä‡§ò‡•ç‡§∞ ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§ï‡•á ‡§≠‡•Ç‡§ï‡§Æ‡•ç‡§™ ‡§ï‡•á ‡§∏‡•ç‡§•‡§æ‡§®‡•ã‡§Ç ‡§ï‡•á ‡§∂‡•Ä‡§ò‡•ç‡§∞ ‡§π‡•Ä\n",
      "\n",
      "EN: Wildlife conservation is critical for maintaining biodiversity.\n",
      "Reference HI: ‡§ú‡§Ç‡§ó‡§≤‡•Ä ‡§ú‡•Ä‡§µ‡§® ‡§∏‡§Ç‡§∞‡§ï‡•ç‡§∑‡§£ ‡§ú‡•à‡§µ ‡§µ‡§ø‡§µ‡§ø‡§ß‡§§‡§æ ‡§¨‡§®‡§æ‡§è ‡§∞‡§ñ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à‡•§\n",
      "Baseline: ‡§ú‡•à‡§µ ‡§µ‡§ø‡§µ‡§ø‡§ß‡§§‡§æ ‡§ï‡•ã ‡§¨‡§®‡§æ‡§è ‡§∞‡§ñ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à‡•§\n",
      "Hybrid CNN: ‡§ú‡•à‡§µ ‡§µ‡§ø‡§µ‡§ø‡§ß‡§§‡§æ ‡§¨‡§®‡§æ‡§è ‡§∞‡§ñ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§Ç‡§∞‡§ï‡•ç‡§∑‡§£ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à‡•§\n",
      "\n",
      "EN: The company launched a new smartphone model last week.\n",
      "Reference HI: ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§®‡•á ‡§™‡§ø‡§õ‡§≤‡•á ‡§∏‡§™‡•ç‡§§‡§æ‡§π ‡§è‡§ï ‡§®‡§Ø‡§æ ‡§∏‡•ç‡§Æ‡§æ‡§∞‡•ç‡§ü‡§´‡•ã‡§® ‡§Æ‡•â‡§°‡§≤ ‡§≤‡•â‡§®‡•ç‡§ö ‡§ï‡§ø‡§Ø‡§æ‡•§\n",
      "Baseline: ‡§™‡§ø‡§õ‡§≤‡•á ‡§π‡§´‡•ç‡§§‡•á ‡§π‡•Ä ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§®‡•á ‡§®‡§Ø‡§æ ‡§∏‡•ç‡§Æ‡§æ‡§∞‡•ç‡§ü‡§´‡•ã‡§® ‡§≤‡•â‡§®‡•ç‡§ö ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à‡•§\n",
      "Hybrid CNN: ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§®‡•á ‡§™‡§ø‡§õ‡§≤‡•á ‡§∏‡§™‡•ç‡§§‡§æ‡§π ‡§è‡§ï ‡§®‡§Ø‡§æ ‡§∏‡•ç‡§Æ‡§æ‡§∞‡•ç‡§ü‡§´‡•ã‡§® ‡§Æ‡•â‡§°‡§≤ ‡§≤‡•â‡§®‡•ç‡§ö ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ‡•§ ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§®‡•á ‡§¨‡§§‡§æ‡§Ø‡§æ ‡§π‡•à ‡§ï‡§ø ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§®‡•á ‡§è‡§ï ‡§π‡•à‡•§ ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§≠‡§æ‡§∞‡§§ ‡§≤‡•å‡§ü‡§ï‡§∞ ‡§Ö‡§™‡§®‡•á ‡§á‡§∏ ‡§∏‡•Ä‡§∞‡•Ä‡§ú ‡§ï‡•á ‡§Æ‡•Ä‡•§ ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§π‡•à‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à‡§Ç‡§°‡§∏‡•á‡§ü ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§π‡•à‡•§ ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§≠‡§æ‡§∞‡§§ ‡§è‡§ï ‡§Æ‡•Ä ‡§ü ‡§π‡•à‡§Ç‡§°‡§∏‡•á‡§ü ‡§Æ‡•Ä ‡§ü  ‡§Æ‡•Ä ‡•ã ‡§Æ‡•á‡§∞‡•ç‡§≤‡§ø‡§Ç‡§ó ‡§Æ‡•á‡§ö ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§Æ‡•Ä  ‡§Æ‡•Ä ‡•ç ‡§Æ‡•Ä\n",
      "\n",
      "EN: International trade agreements influence domestic markets.\n",
      "Reference HI: ‡§Ö‡§Ç‡§§‡§∞‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§µ‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞ ‡§∏‡§Æ‡§ù‡•å‡§§‡•á ‡§ò‡§∞‡•á‡§≤‡•Ç ‡§¨‡§æ‡§ú‡§æ‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§ø‡§§ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§\n",
      "Baseline: ‡§ò‡§∞‡•á‡§≤‡•Ç ‡§∂‡•á‡§Ø‡§∞ ‡§¨‡§æ‡§ú‡§æ‡§∞‡•ã‡§Ç ‡§ï‡•á ‡§Ö‡§∏‡§∞‡§ï‡§æ‡§∞‡§ï/‡§µ‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞ ‡§ï‡•Ä ‡§∏‡•ç‡§•‡§ø‡§§‡§ø\n",
      "Hybrid CNN: ‡§∂‡•ç‡§∞‡•Ä ‡§®‡§æ‡§Ø‡§°‡•Ç ‡§®‡•á ‡§ï‡§π‡§æ ‡§ï‡§ø ‡§ò‡§∞‡•á‡§≤‡•Ç ‡§¨‡§æ‡§ú‡§æ‡§∞ ‡§ï‡•ã ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§ø‡§§ ‡§ï‡§∞‡•á‡•§\n",
      "\n",
      "EN: The team developed an innovative software solution.\n",
      "Reference HI: ‡§ü‡•Ä‡§Æ ‡§®‡•á ‡§è‡§ï ‡§®‡§µ‡•ã‡§®‡•ç‡§Æ‡•á‡§∑‡•Ä ‡§∏‡•â‡§´‡•ç‡§ü‡§µ‡•á‡§Ø‡§∞ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ‡•§\n",
      "Baseline: ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§è‡§ï ‡§Ö‡§≠‡§ø‡§®‡§µ ‡§∏‡•â‡§´‡•ç‡§ü‡§µ‡•á‡§Ø‡§∞ ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ‡•§\n",
      "Hybrid CNN: ‡§Ö‡§ú‡•á‡§Ø ‡§ü‡•Ä‡§Æ ‡§®‡•á ‡§è‡§ï ‡§Ö‡§≠‡§ø‡§®‡§µ ‡§∏‡•â‡§´‡•ç‡§ü‡§µ‡•á‡§Ø‡§∞ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ‡•§\n",
      "\n",
      "EN: Urban transport systems are facing challenges due to population growth.\n",
      "Reference HI: ‡§ú‡§®‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ ‡§µ‡•É‡§¶‡•ç‡§ß‡§ø ‡§ï‡•á ‡§ï‡§æ‡§∞‡§£ ‡§∂‡§π‡§∞‡•Ä ‡§™‡§∞‡§ø‡§µ‡§π‡§® ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§ö‡•Å‡§®‡•å‡§§‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡§æ ‡§∏‡§æ‡§Æ‡§®‡§æ ‡§ï‡§∞ ‡§∞‡§π‡•Ä ‡§π‡•à‡•§\n",
      "Baseline: ‡§™‡§∞‡§ø‡§µ‡§π‡§® ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ï‡•á ‡§ï‡§æ‡§∞‡§£ ‡§™‡§∞‡§ø‡§µ‡§π‡§® ‡§Æ‡•á‡§Ç ‡§ö‡•Å‡§®‡•å‡§§‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡§æ ‡§∏‡§æ‡§Æ‡§®‡§æ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç.\n",
      "Hybrid CNN: ‡§û‡§™‡•Å‡§≤‡§µ‡§æ‡§¨‡§® ‡§ï‡•á ‡§™‡§∞‡§ø‡§µ‡§π‡§® ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§Ü‡§¨‡§æ‡§¶‡•Ä ‡§ï‡•á ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ï‡•á ‡§ï‡§æ‡§∞‡§£ ‡§Ö‡§®‡•á‡§ï ‡§ö‡•Å‡§®‡•å‡§§‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡§æ ‡§∏‡§æ‡§Æ‡§®‡§æ ‡§ï‡§∞ ‡§∞‡§π‡•Ä ‡§π‡•à‡•§\n",
      "\n",
      "EN: The government is investing in renewable energy projects.\n",
      "Reference HI: ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§®‡§µ‡•Ä‡§ï‡§∞‡§£‡•Ä‡§Ø ‡§ä‡§∞‡•ç‡§ú‡§æ ‡§™‡§∞‡§ø‡§Ø‡•ã‡§ú‡§®‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§®‡§ø‡§µ‡•á‡§∂ ‡§ï‡§∞ ‡§∞‡§π‡•Ä ‡§π‡•à‡•§\n",
      "Baseline: ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§ï‡§π‡§æ ‡§ï‡§ø ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§®‡§µ‡•Ä‡§ï‡§∞‡§£‡•Ä‡§Ø ‡§ä‡§∞‡•ç‡§ú‡§æ ‡§™‡§∞‡§ø‡§Ø‡•ã‡§ú‡§®‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§®‡§ø‡§µ‡•á‡§∂ ‡§ï‡§∞ ‡§∞‡§π‡•Ä ‡§π‡•à‡•§\n",
      "Hybrid CNN: ‡§Ö‡§∏‡•ç‡§•‡§ø‡§Ø‡§æ‡§Ç, ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§®‡§µ‡•Ä‡§ï‡§∞‡§£‡•Ä‡§Ø ‡§ä‡§∞‡•ç‡§ú‡§æ ‡§™‡§∞‡§ø‡§Ø‡•ã‡§ú‡§®‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§®‡§ø‡§µ‡•á‡§∂ ‡§ï‡§∞ ‡§∞‡§π‡•Ä ‡§π‡•à‡•§\n",
      "\n",
      "EN: Students are encouraged to engage in extracurricular activities.\n",
      "Reference HI: ‡§õ‡§æ‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§™‡§æ‡§†‡•ç‡§Ø‡•á‡§§‡§∞ ‡§ó‡§§‡§ø‡§µ‡§ø‡§ß‡§ø‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§ó ‡§≤‡•á‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•ç‡§∞‡•ã‡§§‡•ç‡§∏‡§æ‡§π‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§\n",
      "Baseline: ‡§™‡§æ‡§¶‡§ï ‡§ï‡•ã ‡§Ö‡§®‡•ç‡§Ø ‡§ó‡§§‡§ø‡§µ‡§ø‡§ß‡§ø‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•ç‡§∞‡•ã‡§§‡•ç‡§∏‡§æ‡§π‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§\n",
      "Hybrid CNN: ‡§™‡§æ‡§¶‡§ï‡•ç‡§Ø‡§ï ‡§ï‡•ã ‡§™‡§æ‡§†‡•ç‡§Ø‡•á‡§§‡§∞ ‡§ó‡§§‡§ø‡§µ‡§ø‡§ß‡§ø‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•ç‡§∞‡•ã‡§§‡•ç‡§∏‡§æ‡§π‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à.\n",
      "\n",
      "EN: The company reported a decline in operating costs this quarter.\n",
      "Reference HI: ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§®‡•á ‡§á‡§∏ ‡§§‡§ø‡§Æ‡§æ‡§π‡•Ä ‡§Æ‡•á‡§Ç ‡§∏‡§Ç‡§ö‡§æ‡§≤‡§® ‡§≤‡§æ‡§ó‡§§ ‡§Æ‡•á‡§Ç ‡§ï‡§Æ‡•Ä ‡§ï‡•Ä ‡§∞‡§ø‡§™‡•ã‡§∞‡•ç‡§ü ‡§¶‡•Ä‡•§\n",
      "Baseline: ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§ï‡•á ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§® ‡§ï‡•á ‡§Æ‡•Å‡§§‡§æ‡§¨‡§ø‡§ï ‡§á‡§∏ ‡§§‡§ø‡§Æ‡§æ‡§π‡•Ä ‡§Æ‡•á‡§Ç ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§ï‡•Ä ‡§ó‡§ø‡§∞‡§æ‡§µ‡§ü ‡§Ü‡§à ‡§π‡•à‡•§\n",
      "Hybrid CNN: ‡§ó‡§æ‡§Ç‡§ó‡•á‡§Ø ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§®‡•á ‡§á‡§∏ ‡§ò‡§æ‡§ü‡•á ‡§Æ‡•á‡§Ç ‡§ï‡§Æ‡•Ä ‡§¶‡§∞‡•ç‡§ú ‡§ï‡•Ä ‡§π‡•à‡•§ ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§≤‡§æ‡§ó‡§§ ‡§Æ‡•á‡§Ç ‡§ï‡§Æ‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§á‡§∏ ‡§π‡•à‡•§ ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§Æ‡•á‡§Ç ‡§ñ‡§∞‡§æ‡§¨‡•Ä ‡§π‡•à‡•§ ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§∏‡•á, ‡§ò‡§æ‡§ü‡•ã‡§Ç, ‡§≤‡§æ‡§ó‡§§, ‡§ï‡§Ç‡§™‡§®‡•Ä, ‡§ï‡§Ç‡§™‡§®‡•Ä, ‡§ï‡§Ç‡§™‡§®‡•Ä, ‡§ï‡§Ç‡§™‡§®‡•Ä, ‡§§‡§ø‡§Æ‡§æ‡§π‡•Ä, ‡§§‡§ø‡§Æ‡§æ‡§π‡•Ä, ‡§§‡§ø‡§Æ‡§æ‡§π‡•Ä,,,,, ‡§ï‡§Ç‡§™‡§®‡•Ä,, ‡§ï‡§Ç‡§™‡§®‡•Ä, ‡§ï‡•Ä‡§Æ‡§§\n",
      "\n",
      "EN: Climate change poses a threat to coastal communities.\n",
      "Reference HI: ‡§ú‡§≤‡§µ‡§æ‡§Ø‡•Å ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® ‡§§‡§ü‡•Ä‡§Ø ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ñ‡§§‡§∞‡§æ ‡§â‡§§‡•ç‡§™‡§®‡•ç‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§\n",
      "Baseline: ‡§ú‡§≤‡§µ‡§æ‡§Ø‡•Å ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® ‡§§‡§ü‡•Ä‡§Ø ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ñ‡§§‡§∞‡§æ ‡§π‡•à.\n",
      "Hybrid CNN: ‡§Ö‡§∏‡§π‡§ø‡§∑‡•ç‡§£‡•Å ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® ‡§§‡§ü‡•Ä‡§Ø ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ñ‡§§‡§∞‡§æ ‡§π‡•à‡•§\n",
      "\n",
      "EN: The research team published their findings in a leading journal.\n",
      "Reference HI: ‡§Ö‡§®‡•Å‡§∏‡§Ç‡§ß‡§æ‡§® ‡§ü‡•Ä‡§Æ ‡§®‡•á ‡§Ö‡§™‡§®‡•á ‡§®‡§ø‡§∑‡•ç‡§ï‡§∞‡•ç‡§∑ ‡§è‡§ï ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§ú‡§∞‡•ç‡§®‡§≤ ‡§Æ‡•á‡§Ç ‡§™‡•ç‡§∞‡§ï‡§æ‡§∂‡§ø‡§§ ‡§ï‡§ø‡§è‡•§\n",
      "Baseline: ‡§∂‡•ã‡§ß ‡§¶‡§≤ ‡§®‡•á ‡§è‡§ï ‡§Ö‡§ó‡•ç‡§∞‡§£‡•Ä ‡§™‡§§‡•ç‡§∞‡§ø‡§ï‡§æ ‡§Æ‡•á‡§Ç ‡§Ö‡§™‡§®‡§æ ‡§∂‡•ã‡§ß ‡§™‡§§‡•ç‡§∞ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∂‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à‡•§\n",
      "Hybrid CNN: ‡§°‡§æ‡§Ç‡§°‡•á ‡§∂‡•ã‡§ß ‡§¶‡§≤ ‡§®‡•á ‡§è‡§ï ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§∂‡•ã‡§ß ‡§Æ‡•á‡§Ç ‡§Ö‡§™‡§®‡•Ä ‡§∂‡•ã‡§ß- ‡§™‡§°‡§º‡§§‡§æ‡§≤ ‡§ï‡•Ä‡•§\n",
      "\n",
      "EN: Global cooperation is necessary to tackle pandemics.\n",
      "Reference HI: ‡§Æ‡§π‡§æ‡§Æ‡§æ‡§∞‡•Ä ‡§∏‡•á ‡§®‡§ø‡§™‡§ü‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡•à‡§∂‡•ç‡§µ‡§ø‡§ï ‡§∏‡§π‡§Ø‡•ã‡§ó ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§π‡•à‡•§\n",
      "Baseline: ‡§Æ‡§π‡§æ‡§Æ‡§æ‡§∞‡•Ä ‡§∏‡•á ‡§®‡§ø‡§™‡§ü‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¨‡•ç‡§∞‡•Ä‡§¨‡§≤ ‡§∏‡§π‡§Ø‡•ã‡§ó ‡§ú‡§∞‡•Ç‡§∞‡•Ä ‡§π‡•à‡•§\n",
      "Hybrid CNN: ‡§Æ‡§π‡§æ‡§Æ‡§æ‡§∞‡•Ä ‡§∏‡•á ‡§®‡§ø‡§™‡§ü‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§π‡§Ø‡•ã‡§ó ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§π‡•à‡•§\n",
      "\n",
      "EN: India launched its first indigenous satellite.\n",
      "Reference HI: ‡§≠‡§æ‡§∞‡§§ ‡§®‡•á ‡§Ö‡§™‡§®‡§æ ‡§™‡§π‡§≤‡§æ ‡§∏‡•ç‡§µ‡§¶‡•á‡§∂‡•Ä ‡§â‡§™‡§ó‡•ç‡§∞‡§π ‡§≤‡•â‡§®‡•ç‡§ö ‡§ï‡§ø‡§Ø‡§æ‡•§\n",
      "Baseline: ‡§™‡•ã‡§ï‡•ã ‡§®‡•á ‡§Ö‡§™‡§®‡§æ ‡§™‡§π‡§≤‡§æ ‡§∏‡•ç‡§µ‡§¶‡•á‡§∂‡•Ä ‡§â‡§™‡§ó‡•ç‡§∞‡§π ‡§≤‡•â‡§®‡•ç‡§ö ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à.\n",
      "Hybrid CNN: ‡§ü‡§ø‡§Ø‡§æ ‡§®‡•á ‡§Ö‡§™‡§®‡§æ ‡§™‡§π‡§≤‡§æ ‡§∏‡•ç‡§µ‡§¶‡•á‡§∂‡•Ä ‡§â‡§™‡§ó‡•ç‡§∞‡§π ‡§≤‡•â‡§®‡•ç‡§ö ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à‡•§\n",
      "\n",
      "EN: The prime minister met foreign delegates at the summit.\n",
      "Reference HI: ‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä ‡§®‡•á ‡§∂‡§ø‡§ñ‡§∞ ‡§∏‡§Æ‡•ç‡§Æ‡•á‡§≤‡§® ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§¶‡•á‡§∂‡•Ä ‡§™‡•ç‡§∞‡§§‡§ø‡§®‡§ø‡§ß‡§ø‡§Ø‡•ã‡§Ç ‡§∏‡•á ‡§Æ‡•Å‡§≤‡§æ‡§ï‡§æ‡§§ ‡§ï‡•Ä‡•§\n",
      "Baseline: ‡§á‡§∏ ‡§∏‡§Æ‡•ç‡§Æ‡•á‡§≤‡§® ‡§Æ‡•á‡§Ç ‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä ‡§Æ‡§®‡§Æ‡•ã‡§π‡§® ‡§∏‡§ø‡§Ç‡§π ‡§®‡•á ‡§µ‡§ø‡§¶‡•á‡§∂‡•Ä ‡§™‡•ç‡§∞‡§§‡§ø‡§®‡§ø‡§ß‡§ø‡§Ø‡•ã‡§Ç ‡§∏‡•á ‡§Æ‡•Å‡§≤‡§æ‡§ï‡§æ‡§§ ‡§ï‡•Ä‡•§\n",
      "Hybrid CNN: ‡§∂‡§™‡§• ‡§ó‡•ç‡§∞‡§π‡§£ ‡§∏‡§Æ‡§æ‡§∞‡•ã‡§π ‡§Æ‡•á‡§Ç ‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä ‡§®‡•á ‡§µ‡§ø‡§¶‡•á‡§∂‡•Ä ‡§™‡•ç‡§∞‡§§‡§ø‡§®‡§ø‡§ß‡§ø‡§Ø‡•ã‡§Ç ‡§∏‡•á ‡§ï‡§ø‡§Ø‡§æ‡•§\n",
      "\n",
      "EN: This research focuses on low-resource machine translation.\n",
      "Reference HI: ‡§Ø‡§π ‡§∂‡•ã‡§ß ‡§ï‡§Æ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§µ‡§æ‡§≤‡•Ä ‡§Æ‡§∂‡•Ä‡§® ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§™‡§∞ ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞‡§ø‡§§ ‡§π‡•à‡•§\n",
      "Baseline: ‡§∏‡•Ç‡§ï‡•ç‡§∑‡•ç‡§Æ, ‡§≤‡§ò‡•Å ‡§î‡§∞ ‡§Æ‡§ß‡•ç‡§Ø‡§Æ ‡§∏‡•ç‡§∞‡•ã‡§§ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§™‡§∞ ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞‡§ø‡§§ ‡§π‡•à‡•§ ‡§Æ‡§∂‡•Ä‡§® ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§ ‡§Æ‡§∂‡•Ä‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§™‡§Ø‡•ã‡§ó ‡§Æ‡•á‡§Ç \"\"s\"\" ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡§∂‡•Ä‡§® ‡§ï‡•á ‡§≤‡§ø‡§è. ‡§Ö‡§≠‡§ø‡§ó‡§Æ‡§® ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§™‡§∞ ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à \"\"s.. gov. in ‡§á‡§Æ‡•ç‡§™ ‡§ï‡§Ç‡§™‡•ç‡§Ø‡•Ç‡§ü‡§∞ ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§ï‡§Æ‡§æ‡§Ç‡§° ‡§ï‡•á ‡§≤‡§ø‡§è,\n",
      "Hybrid CNN: ‡§â‡§®‡§ï‡•Ä ‡§ñ‡•ã‡§ú ‡§ï‡§Æ-‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§Æ‡§∂‡•Ä‡§® ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§™‡§∞ ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞‡§ø‡§§ ‡§π‡•à‡•§\n",
      "\n",
      "EN: Its movement was captured on CCTV.\n",
      "Reference HI: ‡§á‡§∏‡§ï‡•á ‡§Ü‡§Ç‡§¶‡•ã‡§≤‡§® ‡§ï‡•ã ‡§∏‡•Ä‡§∏‡•Ä‡§ü‡•Ä‡§µ‡•Ä ‡§Æ‡•á‡§Ç ‡§ï‡•à‡§¶ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ‡•§\n",
      "Baseline: ‡§∏‡•ç‡§§‡•ç‡§∞‡•ã‡§Ç ‡§®‡•á ‡§â‡§®‡§ï‡•á ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§â‡§®‡•ç‡§π‡•á‡§Ç ‡§ú‡§¨‡•ç‡§§ ‡§ï‡§∞ ‡§≤‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ‡•§\n",
      "Hybrid CNN: ‡§Ü‡§∞. ‡§ï‡•á. ‡§ö‡§≤‡§æ‡§®‡•á ‡§ï‡•Ä ‡§π‡§≤‡§ö‡§≤ ‡§™‡§∞ ‡§ó‡§µ‡§∞‡•ç‡§®‡§∞ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§™‡•ã‡§∞ ‡§ï‡•à‡§¶.\n",
      "\n",
      "EN: The two leaders discussed bilateral ties and cooperation in counter-terrorism.\n",
      "Reference HI: ‡§¶‡•ã ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§®‡•á ‡§¶‡•ç‡§µ‡§ø‡§™‡§ï‡•ç‡§∑‡•Ä‡§Ø ‡§∏‡§Ç‡§¨‡§Ç‡§ß‡•ã‡§Ç ‡§î‡§∞ ‡§Ü‡§§‡§Ç‡§ï‡§µ‡§æ‡§¶ ‡§®‡§ø‡§∞‡•ã‡§ß‡§ï ‡§∏‡§π‡§Ø‡•ã‡§ó ‡§™‡§∞ ‡§ö‡§∞‡•ç‡§ö‡§æ ‡§ï‡•Ä‡•§\n",
      "Baseline: ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¶‡•ç‡§µ‡§ø‡§™‡§ï‡•ç‡§∑‡•Ä‡§Ø ‡§∏‡§Ç‡§¨‡§Ç‡§ß‡•ã‡§Ç ‡§î‡§∞ ‡§Ü‡§§‡§Ç‡§ï‡§µ‡§æ‡§¶ ‡§™‡§∞ ‡§ö‡§∞‡•ç‡§ö‡§æ ‡§ï‡•Ä‡•§ ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§®‡•á ‡§¶‡•ç‡§µ‡§ø‡§™‡§ï‡•ç‡§∑‡•Ä‡§Ø ‡§∏‡§Ç‡§¨‡§Ç‡§ß‡•ã‡§Ç ‡§î‡§∞ ‡§¶‡•ç‡§µ‡§ø‡§™‡§ï‡•ç‡§∑‡•Ä‡§Ø ‡§∏‡§Ç‡§¨‡§Ç‡§ß‡•ã‡§Ç ‡§™‡§∞ ‡§ö‡§∞‡•ç‡§ö‡§æ ‡§ï‡•Ä‡•§\n",
      "Hybrid CNN: ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§®‡•á ‡§¶‡•ç‡§µ‡§ø‡§™‡§ï‡•ç‡§∑‡•Ä‡§Ø ‡§∏‡§Ç‡§¨‡§Ç‡§ß‡•ã‡§Ç ‡§î‡§∞ ‡§Ü‡§§‡§Ç‡§ï‡§µ‡§æ‡§¶ ‡§∏‡•á ‡§®‡§ø‡§™‡§ü‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§π‡§Ø‡•ã‡§ó ‡§™‡§∞‡•§\n",
      "\n",
      "EN: The data shows significant improvement in translation accuracy.\n",
      "Reference HI: ‡§°‡•á‡§ü‡§æ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§ï‡•Ä ‡§∏‡§ü‡•Ä‡§ï‡§§‡§æ ‡§Æ‡•á‡§Ç ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§¶‡§ø‡§ñ‡§æ‡§§‡§æ ‡§π‡•à‡•§\n",
      "Baseline: ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§Æ‡•á‡§Ç ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§¶‡§ø‡§ñ‡§æ‡§è‡§Ç.\n",
      "Hybrid CNN: Name\n",
      "\n",
      "EN: He emphasized the importance of sustainable development.\n",
      "Reference HI: ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§∏‡§§‡§§ ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ï‡•á ‡§Æ‡§π‡§§‡•ç‡§µ ‡§™‡§∞ ‡§ú‡•ã‡§∞ ‡§¶‡§ø‡§Ø‡§æ‡•§\n",
      "Baseline: \"\"\" \"\"\"\"‡§™‡§∂‡•Å ‡§ö‡§ø‡§ï‡§ø‡§§‡•ç‡§∏‡§æ ‡§ï‡•á ‡§µ‡§ø‡§ï‡§æ‡§∏\"\"\"\" ‡§™‡§∞ ‡§ú‡•ã‡§∞\"\"\"\n",
      "Hybrid CNN: \"\"\"‡§ß‡§æ‡§∞‡§æ 284(2) \\\"\" ‡§∏‡•ç‡§•‡§æ‡§Ø‡•Ä ‡§µ‡§ø‡§ï‡§æ‡§∏ \\\"\" ‡§ï‡•á ‡§Æ‡§π‡§§‡•ç‡§µ ‡§™‡§∞ ‡§¨‡§≤ ‡§¶‡§ø‡§Ø‡§æ ‡•§\"\"\"\n",
      "\n",
      "EN: The company reported record profits this quarter.\n",
      "Reference HI: ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§®‡•á ‡§á‡§∏ ‡§§‡§ø‡§Æ‡§æ‡§π‡•Ä ‡§Æ‡•á‡§Ç ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§≤‡§æ‡§≠ ‡§ï‡•Ä ‡§∏‡•Ç‡§ö‡§®‡§æ ‡§¶‡•Ä‡•§\n",
      "Baseline: ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§®‡•á ‡§á‡§∏ ‡§§‡§ø‡§Æ‡§æ‡§π‡•Ä ‡§Æ‡•á‡§Ç ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§Æ‡•Å‡§®‡§æ‡§´‡§æ ‡§¶‡§∞‡•ç‡§ú ‡§ï‡§ø‡§Ø‡§æ‡•§\n",
      "Hybrid CNN: ‡§µ‡§æ‡§Ç‡§õ‡§æ‡§π‡•Ä ‡§ï‡§Ç‡§™‡§®‡•Ä ‡§®‡•á ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§Æ‡•Å‡§®‡§æ‡§´‡§æ‡§µ‡§∏‡•Ç‡§≤‡•Ä ‡§ï‡•Ä ‡§á‡§∏ ‡§§‡§ø‡§Æ‡§æ‡§π‡•Ä ‡§Æ‡•á‡§Ç ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§¶‡§∞‡•ç‡§ú ‡§π‡•à‡•§\n",
      "\n",
      "EN: Students are encouraged to participate in research projects.\n",
      "Reference HI: ‡§õ‡§æ‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§Ö‡§®‡•Å‡§∏‡§Ç‡§ß‡§æ‡§® ‡§™‡§∞‡§ø‡§Ø‡•ã‡§ú‡§®‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§ó ‡§≤‡•á‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•ç‡§∞‡•ã‡§§‡•ç‡§∏‡§æ‡§π‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§\n",
      "Baseline: ‡§Ö‡§®‡•Å‡§∏‡§Ç‡§ß‡§æ‡§® ‡§™‡§∞‡§ø‡§Ø‡•ã‡§ú‡§®‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§ó ‡§≤‡•á‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•ç‡§∞‡§§‡§ø‡§≠‡§æ‡§ó‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§™‡•ç‡§∞‡•ã‡§§‡•ç‡§∏‡§æ‡§π‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§\n",
      "Hybrid CNN: ‡§™‡§æ‡§¶‡§ï ‡§ï‡•ã ‡§Ö‡§®‡•Å‡§∏‡§Ç‡§ß‡§æ‡§® ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§ó ‡§≤‡•á‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•ç‡§∞‡•ã‡§§‡•ç‡§∏‡§æ‡§π‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§\n",
      "\n",
      "EN: The new model achieved higher BLEU scores than the baseline.\n",
      "Reference HI: ‡§®‡§Ø‡§æ ‡§Æ‡•â‡§°‡§≤ ‡§¨‡•á‡§∏‡§≤‡§æ‡§á‡§® ‡§ï‡•Ä ‡§§‡•Å‡§≤‡§®‡§æ ‡§Æ‡•á‡§Ç ‡§â‡§ö‡•ç‡§ö BLEU ‡§∏‡•ç‡§ï‡•ã‡§∞ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§\n",
      "Baseline: ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§â‡§ö‡•ç‡§ö‡§§‡§∞ ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§â‡§ö‡•ç‡§ö ‡§∏‡•ç‡§ï‡•ã‡§∞ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§∏‡§Ç‡§∞‡§ö‡§®‡§æ ‡§∏‡•á ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§ø‡§Ø‡§æ‡•§\n",
      "Hybrid CNN: ‡§®‡§à ‡§Æ‡•â‡§°‡§≤ ‡§®‡•á ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§∏‡§Ç‡§∞‡§ö‡§®‡§æ ‡§ï‡•Ä ‡§§‡•Å‡§≤‡§®‡§æ ‡§Æ‡•á‡§Ç ‡§Ö‡§ß‡§ø‡§ï ‡§∑‡§° ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§ø‡§Ø‡§æ‡•§ ‡§®‡§à ‡§û‡§Ç‡§°‡•ç‡§Ø‡§æ ‡§ú‡•Ä‡§Ü‡§∞‡§à‡•§‡§â‡§ö‡•ç‡§ö , ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§∏‡§Ç‡§∞‡§ö‡§®‡§æ ‡§ï‡•ã ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§∏‡•Ä‡§Æ‡§æ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§á‡§ï‡§æ‡§à ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ ‡§¨‡§§‡§æ‡§Ø‡•á ‡§¨‡§ø‡§®‡§æ ‡§â‡§∏‡•á ‡§™‡§ó ‡§™‡§∞ ‡§â‡§∏‡•á ‡§™‡§ó\n",
      "\n",
      "EN: Climate change is affecting global agriculture.\n",
      "Reference HI: ‡§ú‡§≤‡§µ‡§æ‡§Ø‡•Å ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® ‡§µ‡•à‡§∂‡•ç‡§µ‡§ø‡§ï ‡§ï‡•É‡§∑‡§ø ‡§ï‡•ã ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§ø‡§§ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à‡•§\n",
      "Baseline: ‡§ú‡§≤‡§µ‡§æ‡§Ø‡•Å ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® ‡§∏‡•á ‡§µ‡•à‡§∂‡•ç‡§µ‡§ø‡§ï ‡§∏‡•ç‡§§‡§∞ ‡§™‡§∞ ‡§Ü ‡§∞‡§π‡§æ ‡§π‡•à‡•§\n",
      "Hybrid CNN: ‡§§‡•Å‡§®‡•Ä‡§∂‡§æ‡§¶‡•Ä ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® ‡§µ‡•à‡§∂‡•ç‡§µ‡§ø‡§ï ‡§ï‡•É‡§∑‡§ø ‡§ï‡•ã ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§ø‡§§ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à‡•§\n",
      "\n",
      "EN: Vaccination campaigns have reduced disease incidence.\n",
      "Reference HI: ‡§ü‡•Ä‡§ï‡§æ‡§ï‡§∞‡§£ ‡§Ö‡§≠‡§ø‡§Ø‡§æ‡§®‡•ã‡§Ç ‡§®‡•á ‡§∞‡•ã‡§ó ‡§ï‡•Ä ‡§ò‡§ü‡§®‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§ï‡§Æ ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à‡•§\n",
      "Baseline: ‡§ü‡•Ä‡§ï‡§æ‡§ï‡§∞‡§£ ‡§Ö‡§≠‡§ø‡§Ø‡§æ‡§® ‡§®‡•á ‡§¨‡•Ä‡§Æ‡§æ‡§∞‡•Ä ‡§ï‡•ã ‡§ï‡§Æ ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à‡•§\n",
      "Hybrid CNN: ‡§ï‡§Æ ‡§π‡•ã‡§®‡•á ‡§ï‡•á ‡§ï‡§æ‡§∞‡§£ ‡§ü‡•Ä‡§ï‡§æ‡§ï‡§∞‡§£ ‡§Ö‡§≠‡§ø‡§Ø‡§æ‡§® ‡§Æ‡•á‡§Ç ‡§ï‡§Æ‡•Ä ‡§Ü‡§à ‡§π‡•à‡§°‡§´‡•ã‡§®‡•Ä‡§ï‡•ã‡§Æ‡•á‡§Ç‡§∏‡•á‡§Ø‡§π‡§Æ‡§¶‡§ø‡§∞‡§æ‡§™‡•ç‡§§‡§ø‡§æ‡§™‡•ç‡§§‡§ø‡§æ‡§™‡•ç‡§§‡§ø‡§æ‡§ø‡§æ‡§™‡•ç‡§§‡§ø‡§æ‡§™‡•ç‡§§‡§ø‡§æ‡§ï‡•ç‡§∞‡§Æ‡§ï‡§æ‡§µ‡•ç‡§Ø‡§ï‡•ã‡§ñ‡•Å‡§æ‡§Å‡§∂‡§ï‡§∞‡§®‡•á‡§ï‡§æ‡§µ‡•ç‡§Ø‡§ï‡§∞‡§®‡•á‡§ï‡§æ‡§Æ‡•ç‡§¨‡§ø‡§æ‡§æ‡§Å‡§®‡•Ä‡§ö‡•á‡§ï‡§∞‡§®‡•á‡§™‡•ç‡§∞‡§æ‡§µ‡§ß‡§æ‡§®‡§Æ‡§ß‡•ç‡§Ø‡§∏‡•ç‡§•‡§™‡•ç‡§∞‡§æ‡§µ‡§ß‡§æ‡§®‡§Æ‡§æ‡§Å\n",
      "\n",
      "EN: Artificial intelligence is transforming industries rapidly.\n",
      "Reference HI: ‡§ï‡•É‡§§‡•ç‡§∞‡§ø‡§Æ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§§‡•ç‡§§‡§æ ‡§â‡§¶‡•ç‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•ã ‡§§‡•á‡§ú‡•Ä ‡§∏‡•á ‡§¨‡§¶‡§≤ ‡§∞‡§π‡•Ä ‡§π‡•à‡•§\n",
      "Baseline: REITIril positive ob ciation ob ation ciation , , ‡§§‡•ç‡§µ , , , ‡§§‡•ç‡§µ , , , ‡§§‡•ç‡§µ , , , , , ,  ‡§§‡•ç‡§µ , \n",
      "Hybrid CNN: ‡§µ‡§ø‡§∏‡§ø‡§ï ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø ‡§§‡•á‡§ú‡•Ä ‡§∏‡•á ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§®‡§ï‡§æ‡§∞‡•Ä ‡§â‡§¶‡•ç‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§\n",
      "\n",
      "EN: The movie received critical acclaim.\n",
      "Reference HI: ‡§á‡§∏ ‡§´‡§ø‡§≤‡•ç‡§Æ ‡§®‡•á ‡§Ü‡§≤‡•ã‡§ö‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§™‡•ç‡§∞‡§∂‡§Ç‡§∏‡§æ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡•Ä‡•§\n",
      "Baseline: ‡§´‡§ø‡§≤‡•ç‡§Æ ‡§ï‡•ã ‡§∏‡§Æ‡•Ä‡§ï‡•ç‡§∑‡§ï‡•ã‡§Ç ‡§®‡•á ‡§ï‡§æ‡§´‡•Ä ‡§§‡§æ‡§∞‡•Ä‡§´ ‡§≠‡•Ä ‡§¶‡•Ä.\n",
      "Hybrid CNN: ‡§´‡§ø‡§≤‡•ç‡§Æ ‡§ï‡•ã ‡§ï‡§æ‡§´‡•Ä ‡§∏‡§∞‡§æ‡§π‡§®‡§æ ‡§Æ‡§ø‡§≤‡•Ä‡•§\n",
      "\n",
      "EN: Electric vehicles are becoming more popular worldwide.\n",
      "Reference HI: ‡§µ‡§ø‡§¶‡•ç‡§Ø‡•Å‡§§ ‡§µ‡§æ‡§π‡§® ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§≠‡§∞ ‡§Æ‡•á‡§Ç ‡§Ö‡§ß‡§ø‡§ï ‡§≤‡•ã‡§ï‡§™‡•ç‡§∞‡§ø‡§Ø ‡§π‡•ã ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§\n",
      "Baseline: ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§≠‡§∞ ‡§Æ‡•á‡§Ç ‡§µ‡§æ‡§π‡§®‡•ã‡§Ç ‡§ï‡•Ä ‡§∞‡§´‡•ç‡§§‡§æ‡§∞ ‡§ú‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§≤‡•ã‡§ï‡§™‡•ç‡§∞‡§ø‡§Ø ‡§µ‡§æ‡§π‡§® ‡§¨‡§® ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§\n",
      "Hybrid CNN: ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§≠‡§∞ ‡§Æ‡•á‡§Ç ‡§∂‡•ç‡§≤‡•á‡§ï‡§ó‡•ç‡§∞‡§∏‡•ç‡§§ ‡§µ‡§æ‡§π‡§® ‡§π‡•ã‡§§‡•á ‡§ú‡§æ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§\n",
      "\n",
      "EN: Renewable energy sources are crucial for sustainability.\n",
      "Reference HI: ‡§®‡§µ‡•Ä‡§ï‡§∞‡§£‡•Ä‡§Ø ‡§ä‡§∞‡•ç‡§ú‡§æ ‡§∏‡•ç‡§∞‡•ã‡§§ ‡§∏‡§§‡§§‡§§‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à‡§Ç‡•§\n",
      "Baseline: ‡§ä‡§∞‡•ç‡§ú‡§æ ‡§∏‡•ç‡§∞‡•ã‡§§ ‡§∏‡§§‡§§ ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à‡§Ç‡•§\n",
      "Hybrid CNN: ‡§∂‡•ç‡§∞‡§¶‡•ç‡§ß‡•á‡§Ø ‡§ä‡§∞‡•ç‡§ú‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à‡§Ç‡•§\n",
      "\n",
      "EN: The government announced new education policies.\n",
      "Reference HI: ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§®‡•á ‡§®‡§à ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§®‡•Ä‡§§‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•Ä ‡§ò‡•ã‡§∑‡§£‡§æ ‡§ï‡•Ä‡•§\n",
      "Baseline: ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§®‡§à ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§®‡•Ä‡§§‡§ø ‡§ï‡•Ä ‡§ò‡•ã‡§∑‡§£‡§æ ‡§ï‡•Ä‡•§\n",
      "Hybrid CNN: ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§®‡•á ‡§®‡§à ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§®‡•Ä‡§§‡§ø ‡§ï‡•Ä ‡§ò‡•ã‡§∑‡§£‡§æ ‡§ï‡•Ä‡•§\n",
      "\n",
      "EN: Space exploration has advanced significantly in recent years.\n",
      "Reference HI: ‡§Ö‡§Ç‡§§‡§∞‡§ø‡§ï‡•ç‡§∑ ‡§Ö‡§®‡•ç‡§µ‡•á‡§∑‡§£ ‡§®‡•á ‡§π‡§æ‡§≤ ‡§ï‡•á ‡§µ‡§∞‡•ç‡§∑‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§™‡•ç‡§∞‡§ó‡§§‡§ø ‡§ï‡•Ä ‡§π‡•à‡•§\n",
      "Baseline: ‡§™‡§ø‡§õ‡§≤‡•á ‡§ï‡•Å‡§õ ‡§µ‡§∞‡•ç‡§∑‡•ã‡§Ç ‡§Æ‡•á‡§Ç igeraler ‡§®‡•á ‡§ï‡§æ‡§´‡•Ä ‡§§‡§∞‡§ï‡•ç‡§ï‡•Ä ‡§ï‡•Ä ‡§π‡•à‡•§\n",
      "Hybrid CNN: ‡§´‡§æ‡§®‡•ç‡§∏‡•á‡§Ç‡§°‡§æ ‡§π‡§æ‡§≤ ‡§ï‡•á ‡§µ‡§∞‡•ç‡§∑‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§ï‡§æ‡§´‡•Ä ‡§â‡§®‡•ç‡§®‡§§ ‡§π‡•Å‡§Ü ‡§π‡•à‡•§\n",
      "\n",
      "EN: The sports team won the national championship.\n",
      "Reference HI: ‡§ñ‡•á‡§≤ ‡§ü‡•Ä‡§Æ ‡§®‡•á ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§ö‡•à‡§Ç‡§™‡§ø‡§Ø‡§®‡§∂‡§ø‡§™ ‡§ú‡•Ä‡§§‡•Ä‡•§\n",
      "Baseline: ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§ñ‡•á‡§≤ ‡§™‡•ç‡§∞‡§§‡§ø‡§Ø‡•ã‡§ó‡§ø‡§§‡§æ ‡§ú‡•Ä‡§§‡•Ä‡•§\n",
      "Hybrid CNN: ‡§¨‡•ç‡§Ø‡•Ç‡§ü ‡§ñ‡§ø‡§≤‡§æ‡§°‡§º‡•Ä ‡§ñ‡•á‡§≤ ‡§ü‡•Ä‡§Æ ‡§®‡•á ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§ö‡•à‡§Ç‡§™‡§ø‡§Ø‡§®‡§∂‡§ø‡§™ ‡§ú‡•Ä‡§§‡•Ä‡•§\n",
      "\n",
      "EN: Global trade agreements impact economic growth.\n",
      "Reference HI: ‡§µ‡•à‡§∂‡•ç‡§µ‡§ø‡§ï ‡§µ‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞ ‡§∏‡§Æ‡§ù‡•å‡§§‡•á ‡§Ü‡§∞‡•ç‡§•‡§ø‡§ï ‡§µ‡•É‡§¶‡•ç‡§ß‡§ø ‡§ï‡•ã ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§ø‡§§ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§\n",
      "Baseline: ‡§Ü‡§∞‡•ç‡§•‡§ø‡§ï ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§™‡§∞ ‡§¨‡•Å‡§∞‡§æ ‡§Ö‡§∏‡§∞ ‡§™‡§°‡§º‡§æ‡•§\n",
      "Hybrid CNN: ‡§∂‡§Ç‡§ò‡§æ‡§à ‡§∏‡§π‡§Ø‡•ã‡§ó ‡§∏‡§Ç‡§ó‡§†‡§® () ‡§Æ‡•á‡§Ç ‡§∞‡§ø‡§Ø‡§æ‡§Ø‡§§‡•ã‡§Ç ‡§ï‡§æ ‡§µ‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞ ‡§Ü‡§∞‡•ç‡§•‡§ø‡§ï ‡§µ‡§ø‡§ï‡§æ‡§∏\n",
      "\n",
      "‚úÖ Translations saved to 'translation_comparison.txt'\n",
      "\n",
      "üåç BLEU Score (Hybrid CNN vs Reference): 36.89\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Full Evaluation: Baseline Transformer + Hybrid CNN + BLEU\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sentencepiece as spm\n",
    "import sacrebleu\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =====================\n",
    "# Config\n",
    "# =====================\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MAX_LEN = 64  # pos_enc length\n",
    "VOCAB_SIZE = 32000  # adjust to your SP vocab\n",
    "PAD_EN = PAD_HI = 0\n",
    "BOS_EN = BOS_HI = 1\n",
    "EOS_EN = EOS_HI = 2\n",
    "\n",
    "BASELINE_PATH = \"checkpoint_baseline.pt\"\n",
    "HYBRID_PATH = \"checkpoint_hybrid_cnn.pt\"\n",
    "\n",
    "SP_EN_MODEL = Path(\"spm_en.model\")\n",
    "SP_HI_MODEL = Path(\"spm_hi.model\")\n",
    "\n",
    "# =====================\n",
    "# Load SentencePiece\n",
    "# =====================\n",
    "sp_en = spm.SentencePieceProcessor()\n",
    "sp_hi = spm.SentencePieceProcessor()\n",
    "sp_en.load(str(SP_EN_MODEL))\n",
    "sp_hi.load(str(SP_HI_MODEL))\n",
    "\n",
    "# =====================\n",
    "# Transformer & Hybrid Models\n",
    "# =====================\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=512, nhead=8, num_layers=3, dim_feedforward=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab, d_model, padding_idx=PAD_EN)\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab, d_model, padding_idx=PAD_HI)\n",
    "        self.pos_enc = nn.Parameter(torch.zeros(1, MAX_LEN, d_model))\n",
    "        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead,\n",
    "                                          num_encoder_layers=num_layers,\n",
    "                                          num_decoder_layers=num_layers,\n",
    "                                          dim_feedforward=dim_feedforward,\n",
    "                                          dropout=dropout,\n",
    "                                          batch_first=True)\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab)\n",
    "\n",
    "    def encode(self, src, src_key_padding_mask=None):\n",
    "        src_emb = self.src_emb(src) + self.pos_enc[:, :src.size(1), :]\n",
    "        return self.transformer.encoder(src_emb, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask=None, memory_key_padding_mask=None, tgt_key_padding_mask=None):\n",
    "        tgt_emb = self.tgt_emb(tgt) + self.pos_enc[:, :tgt.size(1), :]\n",
    "        return self.transformer.decoder(tgt_emb, memory, tgt_mask=tgt_mask,\n",
    "                                        memory_key_padding_mask=memory_key_padding_mask,\n",
    "                                        tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None,\n",
    "                memory_key_padding_mask=None, tgt_mask=None):\n",
    "        memory = self.encode(src, src_key_padding_mask)\n",
    "        output = self.decode(tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask)\n",
    "        return self.fc_out(output)\n",
    "\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(embed_dim, embed_dim, 5, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(embed_dim, embed_dim, 3, padding=1)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        return self.norm(x + residual)\n",
    "\n",
    "class HybridTransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=512, nhead=8, num_layers=3, dim_feedforward=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab, d_model, padding_idx=PAD_EN)\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab, d_model, padding_idx=PAD_HI)\n",
    "        self.pos_enc = nn.Parameter(torch.zeros(1, MAX_LEN, d_model))\n",
    "        self.cnn_encoder = CNNFeatureExtractor(d_model)\n",
    "        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead,\n",
    "                                          num_encoder_layers=num_layers,\n",
    "                                          num_decoder_layers=num_layers,\n",
    "                                          dim_feedforward=dim_feedforward,\n",
    "                                          dropout=dropout,\n",
    "                                          batch_first=True)\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab)\n",
    "\n",
    "    def encode(self, src, src_key_padding_mask=None):\n",
    "        src_emb = self.src_emb(src) + self.pos_enc[:, :src.size(1), :]\n",
    "        src_cnn = self.cnn_encoder(src_emb)\n",
    "        return self.transformer.encoder(src_cnn, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask=None, memory_key_padding_mask=None, tgt_key_padding_mask=None):\n",
    "        tgt_emb = self.tgt_emb(tgt) + self.pos_enc[:, :tgt.size(1), :]\n",
    "        return self.transformer.decoder(tgt_emb, memory, tgt_mask=tgt_mask,\n",
    "                                        memory_key_padding_mask=memory_key_padding_mask,\n",
    "                                        tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None,\n",
    "                memory_key_padding_mask=None, tgt_mask=None):\n",
    "        memory = self.encode(src, src_key_padding_mask)\n",
    "        output = self.decode(tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask)\n",
    "        return self.fc_out(output)\n",
    "\n",
    "# =====================\n",
    "# Load checkpoints\n",
    "# =====================\n",
    "baseline_model = TransformerModel(VOCAB_SIZE, VOCAB_SIZE).to(DEVICE)\n",
    "hybrid_model = HybridTransformerModel(VOCAB_SIZE, VOCAB_SIZE).to(DEVICE)\n",
    "\n",
    "def load_checkpoint(model, path):\n",
    "    checkpoint = torch.load(path, map_location=DEVICE)\n",
    "    state_dict = checkpoint.get(\"model_state_dict\", checkpoint)\n",
    "    # Adjust pos_enc size\n",
    "    if \"pos_enc\" in state_dict and state_dict[\"pos_enc\"].shape[1] != MAX_LEN:\n",
    "        state_dict[\"pos_enc\"] = state_dict[\"pos_enc\"][:, :MAX_LEN, :]\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "baseline_model = load_checkpoint(baseline_model, BASELINE_PATH)\n",
    "hybrid_model = load_checkpoint(hybrid_model, HYBRID_PATH)\n",
    "\n",
    "baseline_model.eval()\n",
    "hybrid_model.eval()\n",
    "\n",
    "# =====================\n",
    "# Greedy translation function\n",
    "# =====================\n",
    "@torch.no_grad()\n",
    "def translate(model, sentence, sp_en, sp_hi, max_len=MAX_LEN):\n",
    "    src_ids = [BOS_EN] + sp_en.encode(sentence)[:max_len-2] + [EOS_EN]\n",
    "    src = torch.tensor(src_ids, device=DEVICE).unsqueeze(0)\n",
    "    tgt = torch.tensor([[BOS_HI]], device=DEVICE)\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        out = model(src, tgt)\n",
    "        next_token = out[:, -1, :].argmax(-1).unsqueeze(1)\n",
    "        tgt = torch.cat([tgt, next_token], dim=1)\n",
    "        if next_token.item() == EOS_HI:\n",
    "            break\n",
    "\n",
    "    decoded = sp_hi.decode([t for t in tgt[0].tolist() if t not in [BOS_HI, EOS_HI, PAD_HI]])\n",
    "    return decoded\n",
    "\n",
    "# =====================\n",
    "# 20 sample sentences (EN + reference HI)\n",
    "# =====================\n",
    "test_samples = new_test_samples = [\n",
    "    (\"The city is preparing for heavy rainfall this week.\", \"‡§∂‡§π‡§∞ ‡§á‡§∏ ‡§∏‡§™‡•ç‡§§‡§æ‡§π ‡§≠‡§æ‡§∞‡•Ä ‡§µ‡§∞‡•ç‡§∑‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•à‡§Ø‡§æ‡§∞‡•Ä ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à‡•§\"),\n",
    "    (\"Researchers developed a new method for early disease detection.\", \"‡§∂‡•ã‡§ß‡§ï‡§∞‡•ç‡§§‡§æ‡§ì‡§Ç ‡§®‡•á ‡§ú‡§≤‡•ç‡§¶‡•Ä ‡§∞‡•ã‡§ó ‡§™‡§π‡§ö‡§æ‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§®‡§à ‡§µ‡§ø‡§ß‡§ø ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§ï‡•Ä‡•§\"),\n",
    "    (\"The economy is showing signs of steady growth.\", \"‡§Ö‡§∞‡•ç‡§•‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ ‡§∏‡•ç‡§•‡§ø‡§∞ ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ï‡•á ‡§∏‡§Ç‡§ï‡•á‡§§ ‡§¶‡§ø‡§ñ‡§æ ‡§∞‡§π‡•Ä ‡§π‡•à‡•§\"),\n",
    "    (\"Students participated enthusiastically in the science fair.\", \"‡§õ‡§æ‡§§‡•ç‡§∞‡•ã‡§Ç ‡§®‡•á ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§® ‡§Æ‡•á‡§≤‡§æ ‡§Æ‡•á‡§Ç ‡§â‡§§‡•ç‡§∏‡§æ‡§π‡§™‡•Ç‡§∞‡•ç‡§µ‡§ï ‡§≠‡§æ‡§ó ‡§≤‡§ø‡§Ø‡§æ‡•§\"),\n",
    "    (\"The festival attracted tourists from all over the world.\", \"‡§§‡•ç‡§Ø‡•ã‡§π‡§æ‡§∞ ‡§®‡•á ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§≠‡§∞ ‡§∏‡•á ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï‡•ã‡§Ç ‡§ï‡•ã ‡§Ü‡§ï‡§∞‡•ç‡§∑‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ‡•§\"),\n",
    "    (\"Solar energy installations are increasing rapidly in rural areas.\", \"‡§ó‡•ç‡§∞‡§æ‡§Æ‡•Ä‡§£ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡•å‡§∞ ‡§ä‡§∞‡•ç‡§ú‡§æ ‡§∏‡•ç‡§•‡§æ‡§™‡§®‡§æ ‡§§‡•á‡§ú‡•Ä ‡§∏‡•á ‡§¨‡§¢‡§º ‡§∞‡§π‡•Ä ‡§π‡•à‡•§\"),\n",
    "    (\"The new policy aims to reduce air pollution in cities.\", \"‡§®‡§à ‡§®‡•Ä‡§§‡§ø ‡§ï‡§æ ‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø ‡§∂‡§π‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§µ‡§æ‡§Ø‡•Å ‡§™‡•ç‡§∞‡§¶‡•Ç‡§∑‡§£ ‡§ï‡•ã ‡§ï‡§Æ ‡§ï‡§∞‡§®‡§æ ‡§π‡•à‡•§\"),\n",
    "    (\"Artificial intelligence can improve healthcare diagnostics.\", \"‡§ï‡•É‡§§‡•ç‡§∞‡§ø‡§Æ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§§‡•ç‡§§‡§æ ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§¶‡•á‡§ñ‡§≠‡§æ‡§≤ ‡§®‡§ø‡§¶‡§æ‡§® ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à‡•§\"),\n",
    "    (\"The government announced relief measures for flood-affected areas.\", \"‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§®‡•á ‡§¨‡§æ‡§¢‡§º ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§ø‡§§ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∞‡§æ‡§π‡§§ ‡§â‡§™‡§æ‡§Ø‡•ã‡§Ç ‡§ï‡•Ä ‡§ò‡•ã‡§∑‡§£‡§æ ‡§ï‡•Ä‡•§\"),\n",
    "    (\"Wildlife conservation is critical for maintaining biodiversity.\", \"‡§ú‡§Ç‡§ó‡§≤‡•Ä ‡§ú‡•Ä‡§µ‡§® ‡§∏‡§Ç‡§∞‡§ï‡•ç‡§∑‡§£ ‡§ú‡•à‡§µ ‡§µ‡§ø‡§µ‡§ø‡§ß‡§§‡§æ ‡§¨‡§®‡§æ‡§è ‡§∞‡§ñ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à‡•§\"),\n",
    "    (\"The company launched a new smartphone model last week.\", \"‡§ï‡§Ç‡§™‡§®‡•Ä ‡§®‡•á ‡§™‡§ø‡§õ‡§≤‡•á ‡§∏‡§™‡•ç‡§§‡§æ‡§π ‡§è‡§ï ‡§®‡§Ø‡§æ ‡§∏‡•ç‡§Æ‡§æ‡§∞‡•ç‡§ü‡§´‡•ã‡§® ‡§Æ‡•â‡§°‡§≤ ‡§≤‡•â‡§®‡•ç‡§ö ‡§ï‡§ø‡§Ø‡§æ‡•§\"),\n",
    "    (\"International trade agreements influence domestic markets.\", \"‡§Ö‡§Ç‡§§‡§∞‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§µ‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞ ‡§∏‡§Æ‡§ù‡•å‡§§‡•á ‡§ò‡§∞‡•á‡§≤‡•Ç ‡§¨‡§æ‡§ú‡§æ‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§ø‡§§ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§\"),\n",
    "    (\"The team developed an innovative software solution.\", \"‡§ü‡•Ä‡§Æ ‡§®‡•á ‡§è‡§ï ‡§®‡§µ‡•ã‡§®‡•ç‡§Æ‡•á‡§∑‡•Ä ‡§∏‡•â‡§´‡•ç‡§ü‡§µ‡•á‡§Ø‡§∞ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ‡•§\"),\n",
    "    (\"Urban transport systems are facing challenges due to population growth.\", \"‡§ú‡§®‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ ‡§µ‡•É‡§¶‡•ç‡§ß‡§ø ‡§ï‡•á ‡§ï‡§æ‡§∞‡§£ ‡§∂‡§π‡§∞‡•Ä ‡§™‡§∞‡§ø‡§µ‡§π‡§® ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§ö‡•Å‡§®‡•å‡§§‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡§æ ‡§∏‡§æ‡§Æ‡§®‡§æ ‡§ï‡§∞ ‡§∞‡§π‡•Ä ‡§π‡•à‡•§\"),\n",
    "    (\"The government is investing in renewable energy projects.\", \"‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§®‡§µ‡•Ä‡§ï‡§∞‡§£‡•Ä‡§Ø ‡§ä‡§∞‡•ç‡§ú‡§æ ‡§™‡§∞‡§ø‡§Ø‡•ã‡§ú‡§®‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§®‡§ø‡§µ‡•á‡§∂ ‡§ï‡§∞ ‡§∞‡§π‡•Ä ‡§π‡•à‡•§\"),\n",
    "    (\"Students are encouraged to engage in extracurricular activities.\", \"‡§õ‡§æ‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§™‡§æ‡§†‡•ç‡§Ø‡•á‡§§‡§∞ ‡§ó‡§§‡§ø‡§µ‡§ø‡§ß‡§ø‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§ó ‡§≤‡•á‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•ç‡§∞‡•ã‡§§‡•ç‡§∏‡§æ‡§π‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§\"),\n",
    "    (\"The company reported a decline in operating costs this quarter.\", \"‡§ï‡§Ç‡§™‡§®‡•Ä ‡§®‡•á ‡§á‡§∏ ‡§§‡§ø‡§Æ‡§æ‡§π‡•Ä ‡§Æ‡•á‡§Ç ‡§∏‡§Ç‡§ö‡§æ‡§≤‡§® ‡§≤‡§æ‡§ó‡§§ ‡§Æ‡•á‡§Ç ‡§ï‡§Æ‡•Ä ‡§ï‡•Ä ‡§∞‡§ø‡§™‡•ã‡§∞‡•ç‡§ü ‡§¶‡•Ä‡•§\"),\n",
    "    (\"Climate change poses a threat to coastal communities.\", \"‡§ú‡§≤‡§µ‡§æ‡§Ø‡•Å ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® ‡§§‡§ü‡•Ä‡§Ø ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ñ‡§§‡§∞‡§æ ‡§â‡§§‡•ç‡§™‡§®‡•ç‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§\"),\n",
    "    (\"The research team published their findings in a leading journal.\", \"‡§Ö‡§®‡•Å‡§∏‡§Ç‡§ß‡§æ‡§® ‡§ü‡•Ä‡§Æ ‡§®‡•á ‡§Ö‡§™‡§®‡•á ‡§®‡§ø‡§∑‡•ç‡§ï‡§∞‡•ç‡§∑ ‡§è‡§ï ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§ú‡§∞‡•ç‡§®‡§≤ ‡§Æ‡•á‡§Ç ‡§™‡•ç‡§∞‡§ï‡§æ‡§∂‡§ø‡§§ ‡§ï‡§ø‡§è‡•§\"),\n",
    "    (\"Global cooperation is necessary to tackle pandemics.\", \"‡§Æ‡§π‡§æ‡§Æ‡§æ‡§∞‡•Ä ‡§∏‡•á ‡§®‡§ø‡§™‡§ü‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡•à‡§∂‡•ç‡§µ‡§ø‡§ï ‡§∏‡§π‡§Ø‡•ã‡§ó ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§π‡•à‡•§\"),\n",
    "    (\"India launched its first indigenous satellite.\", \"‡§≠‡§æ‡§∞‡§§ ‡§®‡•á ‡§Ö‡§™‡§®‡§æ ‡§™‡§π‡§≤‡§æ ‡§∏‡•ç‡§µ‡§¶‡•á‡§∂‡•Ä ‡§â‡§™‡§ó‡•ç‡§∞‡§π ‡§≤‡•â‡§®‡•ç‡§ö ‡§ï‡§ø‡§Ø‡§æ‡•§\"),\n",
    "    (\"The prime minister met foreign delegates at the summit.\", \"‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä ‡§®‡•á ‡§∂‡§ø‡§ñ‡§∞ ‡§∏‡§Æ‡•ç‡§Æ‡•á‡§≤‡§® ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§¶‡•á‡§∂‡•Ä ‡§™‡•ç‡§∞‡§§‡§ø‡§®‡§ø‡§ß‡§ø‡§Ø‡•ã‡§Ç ‡§∏‡•á ‡§Æ‡•Å‡§≤‡§æ‡§ï‡§æ‡§§ ‡§ï‡•Ä‡•§\"),\n",
    "    (\"This research focuses on low-resource machine translation.\", \"‡§Ø‡§π ‡§∂‡•ã‡§ß ‡§ï‡§Æ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§µ‡§æ‡§≤‡•Ä ‡§Æ‡§∂‡•Ä‡§® ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§™‡§∞ ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞‡§ø‡§§ ‡§π‡•à‡•§\"),\n",
    "    (\"Its movement was captured on CCTV.\", \"‡§á‡§∏‡§ï‡•á ‡§Ü‡§Ç‡§¶‡•ã‡§≤‡§® ‡§ï‡•ã ‡§∏‡•Ä‡§∏‡•Ä‡§ü‡•Ä‡§µ‡•Ä ‡§Æ‡•á‡§Ç ‡§ï‡•à‡§¶ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ‡•§\"),\n",
    "    (\"The two leaders discussed bilateral ties and cooperation in counter-terrorism.\", \"‡§¶‡•ã ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§®‡•á ‡§¶‡•ç‡§µ‡§ø‡§™‡§ï‡•ç‡§∑‡•Ä‡§Ø ‡§∏‡§Ç‡§¨‡§Ç‡§ß‡•ã‡§Ç ‡§î‡§∞ ‡§Ü‡§§‡§Ç‡§ï‡§µ‡§æ‡§¶ ‡§®‡§ø‡§∞‡•ã‡§ß‡§ï ‡§∏‡§π‡§Ø‡•ã‡§ó ‡§™‡§∞ ‡§ö‡§∞‡•ç‡§ö‡§æ ‡§ï‡•Ä‡•§\"),\n",
    "    (\"The data shows significant improvement in translation accuracy.\", \"‡§°‡•á‡§ü‡§æ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§ï‡•Ä ‡§∏‡§ü‡•Ä‡§ï‡§§‡§æ ‡§Æ‡•á‡§Ç ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§¶‡§ø‡§ñ‡§æ‡§§‡§æ ‡§π‡•à‡•§\"),\n",
    "    (\"He emphasized the importance of sustainable development.\", \"‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§∏‡§§‡§§ ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ï‡•á ‡§Æ‡§π‡§§‡•ç‡§µ ‡§™‡§∞ ‡§ú‡•ã‡§∞ ‡§¶‡§ø‡§Ø‡§æ‡•§\"),\n",
    "    (\"The company reported record profits this quarter.\", \"‡§ï‡§Ç‡§™‡§®‡•Ä ‡§®‡•á ‡§á‡§∏ ‡§§‡§ø‡§Æ‡§æ‡§π‡•Ä ‡§Æ‡•á‡§Ç ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§≤‡§æ‡§≠ ‡§ï‡•Ä ‡§∏‡•Ç‡§ö‡§®‡§æ ‡§¶‡•Ä‡•§\"),\n",
    "    (\"Students are encouraged to participate in research projects.\", \"‡§õ‡§æ‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§Ö‡§®‡•Å‡§∏‡§Ç‡§ß‡§æ‡§® ‡§™‡§∞‡§ø‡§Ø‡•ã‡§ú‡§®‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§ó ‡§≤‡•á‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•ç‡§∞‡•ã‡§§‡•ç‡§∏‡§æ‡§π‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§\"),\n",
    "    (\"The new model achieved higher BLEU scores than the baseline.\", \"‡§®‡§Ø‡§æ ‡§Æ‡•â‡§°‡§≤ ‡§¨‡•á‡§∏‡§≤‡§æ‡§á‡§® ‡§ï‡•Ä ‡§§‡•Å‡§≤‡§®‡§æ ‡§Æ‡•á‡§Ç ‡§â‡§ö‡•ç‡§ö BLEU ‡§∏‡•ç‡§ï‡•ã‡§∞ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§\"),\n",
    "    (\"Climate change is affecting global agriculture.\", \"‡§ú‡§≤‡§µ‡§æ‡§Ø‡•Å ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® ‡§µ‡•à‡§∂‡•ç‡§µ‡§ø‡§ï ‡§ï‡•É‡§∑‡§ø ‡§ï‡•ã ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§ø‡§§ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à‡•§\"),\n",
    "    (\"Vaccination campaigns have reduced disease incidence.\", \"‡§ü‡•Ä‡§ï‡§æ‡§ï‡§∞‡§£ ‡§Ö‡§≠‡§ø‡§Ø‡§æ‡§®‡•ã‡§Ç ‡§®‡•á ‡§∞‡•ã‡§ó ‡§ï‡•Ä ‡§ò‡§ü‡§®‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§ï‡§Æ ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à‡•§\"),\n",
    "    (\"Artificial intelligence is transforming industries rapidly.\", \"‡§ï‡•É‡§§‡•ç‡§∞‡§ø‡§Æ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§§‡•ç‡§§‡§æ ‡§â‡§¶‡•ç‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•ã ‡§§‡•á‡§ú‡•Ä ‡§∏‡•á ‡§¨‡§¶‡§≤ ‡§∞‡§π‡•Ä ‡§π‡•à‡•§\"),\n",
    "    (\"The movie received critical acclaim.\", \"‡§á‡§∏ ‡§´‡§ø‡§≤‡•ç‡§Æ ‡§®‡•á ‡§Ü‡§≤‡•ã‡§ö‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§™‡•ç‡§∞‡§∂‡§Ç‡§∏‡§æ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡•Ä‡•§\"),\n",
    "    (\"Electric vehicles are becoming more popular worldwide.\", \"‡§µ‡§ø‡§¶‡•ç‡§Ø‡•Å‡§§ ‡§µ‡§æ‡§π‡§® ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§≠‡§∞ ‡§Æ‡•á‡§Ç ‡§Ö‡§ß‡§ø‡§ï ‡§≤‡•ã‡§ï‡§™‡•ç‡§∞‡§ø‡§Ø ‡§π‡•ã ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§\"),\n",
    "    (\"Renewable energy sources are crucial for sustainability.\", \"‡§®‡§µ‡•Ä‡§ï‡§∞‡§£‡•Ä‡§Ø ‡§ä‡§∞‡•ç‡§ú‡§æ ‡§∏‡•ç‡§∞‡•ã‡§§ ‡§∏‡§§‡§§‡§§‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à‡§Ç‡•§\"),\n",
    "    (\"The government announced new education policies.\", \"‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§®‡•á ‡§®‡§à ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§®‡•Ä‡§§‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•Ä ‡§ò‡•ã‡§∑‡§£‡§æ ‡§ï‡•Ä‡•§\"),\n",
    "    (\"Space exploration has advanced significantly in recent years.\", \"‡§Ö‡§Ç‡§§‡§∞‡§ø‡§ï‡•ç‡§∑ ‡§Ö‡§®‡•ç‡§µ‡•á‡§∑‡§£ ‡§®‡•á ‡§π‡§æ‡§≤ ‡§ï‡•á ‡§µ‡§∞‡•ç‡§∑‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§™‡•ç‡§∞‡§ó‡§§‡§ø ‡§ï‡•Ä ‡§π‡•à‡•§\"),\n",
    "    (\"The sports team won the national championship.\", \"‡§ñ‡•á‡§≤ ‡§ü‡•Ä‡§Æ ‡§®‡•á ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§ö‡•à‡§Ç‡§™‡§ø‡§Ø‡§®‡§∂‡§ø‡§™ ‡§ú‡•Ä‡§§‡•Ä‡•§\"),\n",
    "    (\"Global trade agreements impact economic growth.\", \"‡§µ‡•à‡§∂‡•ç‡§µ‡§ø‡§ï ‡§µ‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞ ‡§∏‡§Æ‡§ù‡•å‡§§‡•á ‡§Ü‡§∞‡•ç‡§•‡§ø‡§ï ‡§µ‡•É‡§¶‡•ç‡§ß‡§ø ‡§ï‡•ã ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§ø‡§§ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§\"),\n",
    "]\n",
    "\n",
    "\n",
    "# =====================\n",
    "# Translate & save results\n",
    "# =====================\n",
    "results = []\n",
    "for en, hi_ref in test_samples:\n",
    "    baseline_out = translate(baseline_model, en, sp_en, sp_hi)\n",
    "    hybrid_out = translate(hybrid_model, en, sp_en, sp_hi)\n",
    "\n",
    "    print(f\"\\nEN: {en}\")\n",
    "    print(f\"Reference HI: {hi_ref}\")\n",
    "    print(f\"Baseline: {baseline_out}\")\n",
    "    print(f\"Hybrid CNN: {hybrid_out}\")\n",
    "\n",
    "    results.append({\n",
    "        \"EN\": en,\n",
    "        \"Reference\": hi_ref,\n",
    "        \"Baseline\": baseline_out,\n",
    "        \"2 layer CNN\": hybrid_out\n",
    "    })\n",
    "\n",
    "# Save results to file\n",
    "with open(\"translation_comparison.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for r in results:\n",
    "        f.write(f\"EN: {r['EN']}\\nReference HI: {r['Reference']}\\nBaseline: {r['Baseline']}\\nHybrid CNN: {r['Hybrid']}\\n\\n\")\n",
    "\n",
    "print(\"\\n‚úÖ Translations saved to 'translation_comparison.txt'\")\n",
    "\n",
    "# =====================\n",
    "# Compute BLEU for Hybrid model\n",
    "# =====================\n",
    "refs = [[r[\"Reference\"]] for r in results]  # list of list\n",
    "hyps = [r[\"Hybrid\"] for r in results]\n",
    "\n",
    "bleu = sacrebleu.corpus_bleu(hyps, refs)\n",
    "print(f\"\\nüåç BLEU Score (Hybrid CNN vs Reference): {bleu.score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\.conda\\envs\\mt_env\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Louk71JjPl8K"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\.conda\\envs\\mt_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: 800000 100000 100000\n",
      "Resuming from checkpoint_multiscale.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_4408\\4167527191.py:222: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded ‚Äî Resuming from epoch 22\n",
      "Training complete ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Install & Imports\n",
    "# =====================\n",
    "!pip install -q datasets sentencepiece sacrebleu torch torchvision torchaudio tqdm\n",
    "\n",
    "import os, random\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import sentencepiece as spm\n",
    "import sacrebleu\n",
    "\n",
    "# =====================\n",
    "# Config\n",
    "# =====================\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "VOCAB_SIZE = 16000\n",
    "BATCH_SIZE = 64\n",
    "MAX_LEN = 64\n",
    "MAX_GEN_LEN = 64\n",
    "EPOCHS = 20\n",
    "CLIP = 1.0\n",
    "LEARNING_RATE = 3e-4\n",
    "BEAM_SIZE = 5\n",
    "BEST_MODEL_PATH = Path(\"best_model_multiscale.pt\")\n",
    "CHECKPOINT_PATH = Path(\"checkpoint_multiscale.pt\")\n",
    "\n",
    "PATIENCE = 5\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# =====================\n",
    "# Load dataset\n",
    "# =====================\n",
    "full_dataset = load_dataset(\"ai4bharat/samanantar\", \"hi\", split=\"train\")\n",
    "full_dataset = full_dataset.shuffle(seed=SEED)\n",
    "\n",
    "NUM_EXAMPLES = min(1_000_000, len(full_dataset))\n",
    "subset = full_dataset.select(range(NUM_EXAMPLES))\n",
    "\n",
    "# Split 80/10/10\n",
    "train_end = int(0.8 * len(subset))\n",
    "val_end = int(0.9 * len(subset))\n",
    "train_data = subset.select(range(0, train_end))\n",
    "val_data = subset.select(range(train_end, val_end))\n",
    "test_data = subset.select(range(val_end, len(subset)))\n",
    "print(\"Dataset sizes:\", len(train_data), len(val_data), len(test_data))\n",
    "\n",
    "# =====================\n",
    "# SentencePiece\n",
    "# =====================\n",
    "SP_EN_MODEL = Path(\"spm_en.model\")\n",
    "SP_HI_MODEL = Path(\"spm_hi.model\")\n",
    "\n",
    "def write_lines(dataset_split, src_path, tgt_path):\n",
    "    with open(src_path, \"w\", encoding=\"utf-8\") as sf, open(tgt_path, \"w\", encoding=\"utf-8\") as tf:\n",
    "        for ex in dataset_split:\n",
    "            sf.write(ex[\"src\"].strip().lower() + \"\\n\")\n",
    "            tf.write(ex[\"tgt\"].strip() + \"\\n\")\n",
    "\n",
    "write_lines(train_data, \"train.en\", \"train.hi\")\n",
    "\n",
    "if not SP_EN_MODEL.exists() or not SP_HI_MODEL.exists():\n",
    "    print(\"Training SentencePiece...\")\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f\"--input=train.en --model_prefix=spm_en --vocab_size={VOCAB_SIZE} \"\n",
    "        f\"--character_coverage=1.0 --model_type=unigram\"\n",
    "    )\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f\"--input=train.hi --model_prefix=spm_hi --vocab_size={VOCAB_SIZE} \"\n",
    "        f\"--character_coverage=0.9995 --model_type=unigram\"\n",
    "    )\n",
    "\n",
    "sp_en = spm.SentencePieceProcessor()\n",
    "sp_hi = spm.SentencePieceProcessor()\n",
    "sp_en.load(str(SP_EN_MODEL))\n",
    "sp_hi.load(str(SP_HI_MODEL))\n",
    "\n",
    "PAD_EN, BOS_EN, EOS_EN = 0, 1, 2\n",
    "PAD_HI, BOS_HI, EOS_HI = 0, 1, 2\n",
    "\n",
    "# =====================\n",
    "# Dataset & DataLoader\n",
    "# =====================\n",
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, dataset, src_sp, tgt_sp, max_len=MAX_LEN):\n",
    "        self.dataset = dataset\n",
    "        self.src_sp = src_sp\n",
    "        self.tgt_sp = tgt_sp\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_text = self.dataset[idx][\"src\"].lower()\n",
    "        tgt_text = self.dataset[idx][\"tgt\"]\n",
    "        src_ids = [BOS_EN] + self.src_sp.encode(src_text)[:self.max_len-2] + [EOS_EN]\n",
    "        tgt_ids = [BOS_HI] + self.tgt_sp.encode(tgt_text)[:self.max_len-2] + [EOS_HI]\n",
    "        src_ids += [PAD_EN] * (self.max_len - len(src_ids))\n",
    "        tgt_ids += [PAD_HI] * (self.max_len - len(tgt_ids))\n",
    "        return torch.tensor(src_ids), torch.tensor(tgt_ids)\n",
    "\n",
    "def get_loader(dataset_split, shuffle=True):\n",
    "    return DataLoader(NMTDataset(dataset_split, sp_en, sp_hi),\n",
    "                      batch_size=BATCH_SIZE, shuffle=shuffle)\n",
    "\n",
    "train_loader = get_loader(train_data)\n",
    "val_loader = get_loader(val_data)\n",
    "test_loader = get_loader(test_data, shuffle=False)\n",
    "\n",
    "# =====================\n",
    "# Masks\n",
    "# =====================\n",
    "def create_padding_mask(seq, lang='en'):\n",
    "    pad_id = PAD_EN if lang == 'en' else PAD_HI\n",
    "    return (seq == pad_id)\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    return torch.triu(torch.ones(sz, sz, device=DEVICE) * float('-inf'), diagonal=1)\n",
    "\n",
    "# =====================\n",
    "# Multi-Scale CNN\n",
    "# =====================\n",
    "class MultiScaleCNN(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.conv3 = nn.Conv1d(embed_dim, embed_dim, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv1d(embed_dim, embed_dim, kernel_size=5, padding=2)\n",
    "        self.conv7 = nn.Conv1d(embed_dim, embed_dim, kernel_size=7, padding=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = x.transpose(1, 2)\n",
    "        out3 = self.conv3(x)\n",
    "        out5 = self.conv5(x)\n",
    "        out7 = self.conv7(x)\n",
    "        x = out3 + out5 + out7\n",
    "        x = self.relu(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        return self.norm(x + residual)\n",
    "\n",
    "# =====================\n",
    "# Hybrid Transformer + MultiScale CNN\n",
    "# =====================\n",
    "class HybridTransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=512, nhead=8,\n",
    "                 num_layers=3, dim_feedforward=1024, dropout=0.1, temperature=0.1):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab, d_model, padding_idx=PAD_EN)\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab, d_model, padding_idx=PAD_HI)\n",
    "        self.pos_enc = nn.Parameter(torch.zeros(1, MAX_LEN, d_model))\n",
    "        self.cnn_encoder = MultiScaleCNN(d_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            num_encoder_layers=num_layers, num_decoder_layers=num_layers,\n",
    "            dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def encode(self, src, src_key_padding_mask):\n",
    "        src_emb = self.src_emb(src) + self.pos_enc[:, :src.size(1), :]\n",
    "        src_cnn = self.cnn_encoder(src_emb)\n",
    "        return self.transformer.encoder(src_cnn, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask):\n",
    "        tgt_emb = self.tgt_emb(tgt) + self.pos_enc[:, :tgt.size(1), :]\n",
    "        return self.transformer.decoder(\n",
    "            tgt_emb, memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_key_padding_mask=memory_key_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None,\n",
    "                memory_key_padding_mask=None, tgt_mask=None):\n",
    "        memory = self.encode(src, src_key_padding_mask)\n",
    "        output = self.decode(tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask)\n",
    "        return self.fc_out(output)\n",
    "\n",
    "    # -----------------------\n",
    "    # Contrastive loss\n",
    "    # -----------------------\n",
    "    def contrastive_loss(self, anchor, positive, negative):\n",
    "        anchor = anchor.mean(dim=1)\n",
    "        positive = positive.mean(dim=1)\n",
    "        negative = negative.mean(dim=1)\n",
    "        pos_sim = torch.cosine_similarity(anchor, positive, dim=-1)\n",
    "        neg_sim = torch.cosine_similarity(anchor, negative, dim=-1)\n",
    "        loss = -torch.log(torch.exp(pos_sim / self.temperature) / (torch.exp(pos_sim / self.temperature) + torch.exp(neg_sim / self.temperature)))\n",
    "        return loss.mean()\n",
    "\n",
    "# =====================\n",
    "# Initialize model\n",
    "# =====================\n",
    "model = HybridTransformerModel(len(sp_en), len(sp_hi)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_HI)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=LEARNING_RATE, steps_per_epoch=len(train_loader), epochs=EPOCHS\n",
    ")\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "start_epoch = 1\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# =====================\n",
    "# Resume checkpoint\n",
    "# =====================\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    print(f\"Resuming from {CHECKPOINT_PATH}...\")\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_val_loss = checkpoint['best_val_loss']\n",
    "    epochs_no_improve = checkpoint['epochs_no_improve']\n",
    "    print(f\"Checkpoint loaded ‚Äî Resuming from epoch {start_epoch}\")\n",
    "else:\n",
    "    print(\"Starting training from scratch\")\n",
    "\n",
    "# =====================\n",
    "# Training Loop\n",
    "# =====================\n",
    "for epoch in range(start_epoch, EPOCHS + 1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    contrastive_loss_total = 0\n",
    "\n",
    "    for src, tgt in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\", unit=\"batch\"):\n",
    "        src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "        src_mask = create_padding_mask(src, 'en')\n",
    "        tgt_input, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "        tgt_mask = generate_square_subsequent_mask(tgt_input.size(1))\n",
    "        tgt_key_padding_mask = create_padding_mask(tgt_input, 'hi')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type=\"cuda\"):\n",
    "            logits = model(\n",
    "                src, tgt_input,\n",
    "                src_key_padding_mask=src_mask,\n",
    "                tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                memory_key_padding_mask=src_mask,\n",
    "                tgt_mask=tgt_mask\n",
    "            )\n",
    "            ce_loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "\n",
    "            # -----------------------------\n",
    "            # Contrastive loss\n",
    "            # -----------------------------\n",
    "            neg_tgt_input = tgt_input[torch.randperm(tgt_input.size(0))].to(DEVICE)\n",
    "            memory = model.encode(src, src_mask)\n",
    "            pos_repr = model.decode(tgt_input, memory, tgt_mask, src_mask, tgt_key_padding_mask)\n",
    "            neg_repr = model.decode(neg_tgt_input, memory, tgt_mask, src_mask, tgt_key_padding_mask)\n",
    "            cl_loss = model.contrastive_loss(pos_repr, pos_repr, neg_repr)\n",
    "\n",
    "            loss = ce_loss + 0.1 * cl_loss\n",
    "            contrastive_loss_total += cl_loss.item()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        train_loss += ce_loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_cl_loss = contrastive_loss_total / len(train_loader)\n",
    "    print(f\"Epoch {epoch} | CE Loss: {avg_train_loss:.4f} | Contrastive Loss: {avg_cl_loss:.4f}\")\n",
    "\n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in val_loader:\n",
    "            src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "            src_mask = create_padding_mask(src, 'en')\n",
    "            tgt_input, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "            tgt_mask = generate_square_subsequent_mask(tgt_input.size(1))\n",
    "            tgt_key_padding_mask = create_padding_mask(tgt_input, 'hi')\n",
    "\n",
    "            logits = model(\n",
    "                src, tgt_input,\n",
    "                src_key_padding_mask=src_mask,\n",
    "                tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                memory_key_padding_mask=src_mask,\n",
    "                tgt_mask=tgt_mask\n",
    "            )\n",
    "            loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # ---- Save Checkpoint & Early Stopping ----\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "        \"scaler_state_dict\": scaler.state_dict(),\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "        \"epochs_no_improve\": epochs_no_improve,\n",
    "    }, CHECKPOINT_PATH)\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        print(\"New best model saved!\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"Training complete ‚úÖ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArP2g9AbPl8O"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xn8Z8mEyPl8O"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "",
   "version": ""
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (mt_env)",
   "language": "python",
   "name": "mt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
