{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05842f79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6076,
     "status": "ok",
     "timestamp": 1761532234826,
     "user": {
      "displayName": "Neeraj Pandey",
      "userId": "06506190899472003382"
     },
     "user_tz": -330
    },
    "id": "05842f79",
    "outputId": "f38126e3-b2bd-4f04-9bae-e4d6ebdba6d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
      "Collecting comet-ml\n",
      "  Downloading comet_ml-3.53.2-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2.0.2)\n",
      "Collecting colorama (from sacrebleu)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (5.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
      "Collecting dulwich!=0.20.33,>=0.20.6 (from comet-ml)\n",
      "  Downloading dulwich-0.24.7-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting everett<3.2.0,>=1.0.1 (from everett[ini]<3.2.0,>=1.0.1->comet-ml)\n",
      "  Downloading everett-3.1.0-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.12/dist-packages (from comet-ml) (4.25.1)\n",
      "Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.12/dist-packages (from comet-ml) (5.9.5)\n",
      "Collecting python-box<7.0.0 (from comet-ml)\n",
      "  Downloading python_box-6.1.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from comet-ml) (1.0.0)\n",
      "Requirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.12/dist-packages (from comet-ml) (13.9.4)\n",
      "Requirement already satisfied: semantic-version>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from comet-ml) (2.10.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from comet-ml) (2.42.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from comet-ml) (75.2.0)\n",
      "Requirement already satisfied: simplejson in /usr/local/lib/python3.12/dist-packages (from comet-ml) (3.20.2)\n",
      "Requirement already satisfied: urllib3>=1.26.8 in /usr/local/lib/python3.12/dist-packages (from comet-ml) (2.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.12/dist-packages (from comet-ml) (2.0.0)\n",
      "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from comet-ml) (3.1.1)\n",
      "Collecting configobj (from everett[ini]<3.2.0,>=1.0.1->comet-ml)\n",
      "  Downloading configobj-5.0.9-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.27.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.3.2->comet-ml) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.3.2->comet-ml) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet-ml) (0.1.2)\n",
      "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading comet_ml-3.53.2-py3-none-any.whl (766 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.5/766.5 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dulwich-0.24.7-cp312-cp312-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading everett-3.1.0-py2.py3-none-any.whl (35 kB)\n",
      "Downloading python_box-6.1.0-py3-none-any.whl (27 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
      "Downloading configobj-5.0.9-py2.py3-none-any.whl (35 kB)\n",
      "Installing collected packages: everett, python-box, portalocker, dulwich, configobj, colorama, sacrebleu, comet-ml\n",
      "  Attempting uninstall: python-box\n",
      "    Found existing installation: python-box 7.3.2\n",
      "    Uninstalling python-box-7.3.2:\n",
      "      Successfully uninstalled python-box-7.3.2\n",
      "Successfully installed colorama-0.4.6 comet-ml-3.53.2 configobj-5.0.9 dulwich-0.24.7 everett-3.1.0 portalocker-3.2.0 python-box-6.1.0 sacrebleu-2.5.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install nltk sacrebleu transformers comet-ml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "kw3eGuMJonh_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38931,
     "status": "ok",
     "timestamp": 1761542409375,
     "user": {
      "displayName": "Vaishnavi Pandey",
      "userId": "17951836098704094388"
     },
     "user_tz": -330
    },
    "id": "kw3eGuMJonh_",
    "outputId": "3ad846fd-d3a8-4648-995a-55207210fcb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0895d223",
   "metadata": {
    "id": "0895d223"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\.conda\\envs\\mt_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "!pip install -q datasets sentencepiece sacrebleu torch torchvision torchaudio tqdm\n",
    "import os, random\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import sentencepiece as spm\n",
    "import sacrebleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd3c56",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478,
     "referenced_widgets": [
      "d860dca028314d31bbfa74ca6a85f466",
      "cadf1153daf34956a95f4bd4975038c7",
      "54dd317872624123850f41ec0bc34fcd",
      "9d665b8dff12426192a06ca12821982e",
      "73768a14bdf640428dfa8461348182d9",
      "0b4dd9ae0f7b45eeac260d731943a4c2",
      "d14962079fb14930864e37585ca5c3fb",
      "b1d63f27cce94c16a81a17d6a58d940d",
      "3df63a7a311f49b6b36456efc9c1fb27",
      "16d5a6cb49a44cdda5d5fdc1813f1192",
      "3d610508d2a948eea19f6df737ab4745",
      "705e891434d645738928169ecee64ae0",
      "96f430bfba84480582a53b7d8c713e0b",
      "b33da3b689d549d497a988fd56515e79",
      "745c7425e8904b07b9d20e2917e6b257",
      "db42863309a24cd5adc7f9b52c2dc6ac",
      "010531938c324c25956f81736bd28290",
      "ee6c2ca3f6034214b0bf90a47977c77e",
      "36a7b917f9af4b1eb8be7f78105d03f0",
      "84b20ebd82d4440f9db09e9ab2c4a78f",
      "73c30342ed774d25a2c3bd7d5b784fe2",
      "ca354654fde840319dfced856d447d5b",
      "629c7e7d58fd4f83872693b2190274f7",
      "771c553f29c04cea8066f86b9e02ebed",
      "73d405345fd743d8b7de10fed0ed298c",
      "f17909544c984e08844b1eef64600113",
      "3ea2e4967b454e8c848bef772e8da4e1",
      "269d1707cf804f71b3be61dc34fd13dc",
      "53c160cce6684cfe8f9569bb7f998cc1",
      "6b0b98efbc614519b4744769d469d24c",
      "434cefe5dcdf426d9466894a08da59d5",
      "569fedf8ad8143dca8248bd88da73062",
      "4319a7c973c84fbd9ea1eb67a360937a",
      "b287160e7d6643eabeb301c5e4ff3d47",
      "95a8b30ad5d846f29b00a4199b235ce4",
      "a739d6e1d3fe467fa65622382d7c37a9",
      "07c013ee490a43b6aa596bd44e6134b6",
      "b77337126a0148f19510514b52b66c1f",
      "ca0c52c0a9964ed39b42156f449425f8",
      "f7b651780b174499bf9d999dc98c75cf",
      "65cede777fa543ba9f1d2622572d424b",
      "a510018d0f0f438c9c871c26837ee250",
      "b7290704629f4a108fe2c5fb1978865c",
      "08d965b9b4144a369f4f914a1d193df7",
      "4f8e0559645d40f1b4f0b07184a2f605",
      "5e383c49566e4faba9094af9a0cb359f",
      "b5605971a65a4a429a9b1a380c55b3e5",
      "51b64320ee7b412ba17e2bf4c0299102",
      "6f7572d2ce1145d28d4de62d575390a7",
      "796a1c6dcaed49ceac3885b6a0f4717c",
      "3952b536ed3f4962979b622b564e92e9",
      "c2004285213642db8f680f7615dcda86",
      "27a924d187444254b143d6cb0f3ae380",
      "cb8db2273a734ac9bbfab204c32b487c",
      "5495fd0d053f4737a524a6bdd08fed83",
      "b1cf11a5dc3243a6b141ecebfd2de505",
      "98af9ad29be2482c9176129b54e19ea8",
      "deeb6c8be8754ac4ba88a0c15c0d9a39",
      "e55b86ad7ca84a7b9a564b1aec3421ea",
      "2db1c8e5e64644d2a11d394a7605aec6",
      "b9d0893412f14694a9d174bfac9fe342",
      "53ce2f8b22114ba4b9b8ff69e4456db3",
      "6e49cf2bf6d34cee9fc3978d8418e33c",
      "4caf4f4411d54c0190d1ebd8262c7285",
      "f38fbff127bd4bc2baf44a3bd5bb69fe",
      "f778e15d034d4dde810bb8f9e4ca675c",
      "b9076141189a4c4297a316cac9e9846f",
      "7c003515fd1145228ec56fc30337a3de",
      "9fb8b054b2624974b8f2d8aab10644a2",
      "d9dac293e7a14d3881cac33166565b05",
      "a876e8f9e1094a949718ecda7b11e46c",
      "35f49a312f194bd69506ac05fba61bd6",
      "0dbaf36bc09c4a659e4dd24caa6043e0",
      "e01e7159341d4c6e8f1338107631c7c3",
      "d0824be28cbe4f9aba489cbf0d5ac3bc",
      "30dede73893f41b7aa1b30518b784d10",
      "956cada42c42414f961057f02d6a99a7",
      "7d8110fd88d94c08b10691e6c367430d",
      "954beebc0a27444f97be7b0ddd0437b0",
      "75c28dd82e89428ba04c72dfa81ee054",
      "0cd994a964214cc480cb489a0a950f82",
      "feb4f6996a4d4378932bea281e2eb47c",
      "5c6261d87a0b429babea41a641082ff9",
      "494698ffd20c4b2b9e9265c2e6152060",
      "83e057938a67457a9acceb222441fd16",
      "70dc3aff4c1f42898b88b2dc68c06917",
      "307a5c9745b94c8abf9654cf1c71635d",
      "24f6a3eb9fb8442c84d4619dc85d8b94",
      "4c1a21ca6d6e490bb6c3ec0dd4805b50",
      "9a4d15b1f173489cbe7a5a32b5783f60",
      "9a53ed14066f40c6b4fa7b518b440115",
      "55ae549d1c8e46aca0a80df42e571e23",
      "4560b1a40aec4f3fb9cad68f671a4ab3",
      "a5a0d008da6747478b1a21120138188f",
      "d9dfb9da4b91421db5545b70f2d2da55",
      "d6915a60b6054e5d97adb37aaf795f80",
      "0469791849a74d718cb555ca1f6f65b4",
      "ac33b644271f461f96c66ce0400be8bf",
      "d4c016bdb01d4a36958ecc7e015fbe59",
      "cba9ada2c92b45b889b27a91daa46e5a",
      "a13e3f7ce2b448f99bdd8b3d0671fc74",
      "0cb6dd5e5ca04964a83196933962cbf3",
      "528041ae0bd24f83b42946664fb45634",
      "8658ac93a62f4305b69018b78f35605c",
      "d076e0da96204faf9626e60483645e14",
      "5d831f3daf9e4cdf9b061f16cb6ea7c8",
      "04aaf6523b2a43c8af13a62f73d08511",
      "a794e8880827443291b5e727dd14fbda",
      "e425718a462f49d1a68c4f694c180124",
      "802f19dc0eef49d0bf2b932bb3530122"
     ]
    },
    "executionInfo": {
     "elapsed": 141724,
     "status": "ok",
     "timestamp": 1761532443891,
     "user": {
      "displayName": "Neeraj Pandey",
      "userId": "06506190899472003382"
     },
     "user_tz": -330
    },
    "id": "84fd3c56",
    "outputId": "61a4ba88-0e5d-4b52-8192-fc56fbe2f68c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d860dca028314d31bbfa74ca6a85f466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705e891434d645738928169ecee64ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hi/train-00000-of-00008.parquet:   0%|          | 0.00/240M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629c7e7d58fd4f83872693b2190274f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hi/train-00001-of-00008.parquet:   0%|          | 0.00/240M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b287160e7d6643eabeb301c5e4ff3d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hi/train-00002-of-00008.parquet:   0%|          | 0.00/240M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8e0559645d40f1b4f0b07184a2f605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hi/train-00003-of-00008.parquet:   0%|          | 0.00/240M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1cf11a5dc3243a6b141ecebfd2de505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hi/train-00004-of-00008.parquet:   0%|          | 0.00/240M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9076141189a4c4297a316cac9e9846f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hi/train-00005-of-00008.parquet:   0%|          | 0.00/239M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d8110fd88d94c08b10691e6c367430d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hi/train-00006-of-00008.parquet:   0%|          | 0.00/239M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1a21ca6d6e490bb6c3ec0dd4805b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hi/train-00007-of-00008.parquet:   0%|          | 0.00/240M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba9ada2c92b45b889b27a91daa46e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/10125706 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: 800000 100000 100000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================\n",
    "# Config\n",
    "# =====================\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "VOCAB_SIZE = 16000\n",
    "BATCH_SIZE = 64\n",
    "MAX_LEN = 64\n",
    "MAX_GEN_LEN = 64\n",
    "EPOCHS = 30\n",
    "CLIP = 1.0\n",
    "LEARNING_RATE = 3e-4\n",
    "BEAM_SIZE = 5\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "# =====================\n",
    "# Load dataset (up to 1M)\n",
    "# =====================\n",
    "full_dataset = load_dataset(\"ai4bharat/samanantar\", \"hi\", split=\"train\")\n",
    "full_dataset = full_dataset.shuffle(seed=SEED)\n",
    "\n",
    "NUM_EXAMPLES = min(1_000_000, len(full_dataset))\n",
    "subset = full_dataset.select(range(NUM_EXAMPLES))\n",
    "\n",
    "# Split 80% train, 10% val, 10% test\n",
    "train_end = int(0.8 * len(subset))\n",
    "val_end = int(0.9 * len(subset))\n",
    "train_data = subset.select(range(0, train_end))\n",
    "val_data = subset.select(range(train_end, val_end))\n",
    "test_data = subset.select(range(val_end, len(subset)))\n",
    "\n",
    "print(\"Dataset sizes:\", len(train_data), len(val_data), len(test_data))\n",
    "\n",
    "# =====================\n",
    "# SentencePiece\n",
    "# =====================\n",
    "SP_EN_MODEL = Path(\"/content/drive/MyDrive/paper/spm_en.model\")\n",
    "SP_HI_MODEL = Path(\"/content/drive/MyDrive/paper/spm_hi.model\")\n",
    "\n",
    "def write_lines(dataset_split, src_path, tgt_path):\n",
    "    with open(src_path, \"w\", encoding=\"utf-8\") as sf, open(tgt_path, \"w\", encoding=\"utf-8\") as tf:\n",
    "        for ex in dataset_split:\n",
    "            sf.write(ex[\"src\"].strip().lower() + \"\\n\")\n",
    "            tf.write(ex[\"tgt\"].strip() + \"\\n\")\n",
    "\n",
    "write_lines(train_data, \"train.en\", \"train.hi\")\n",
    "\n",
    "if not SP_EN_MODEL.exists() or not SP_HI_MODEL.exists():\n",
    "    print(\"Training SentencePiece...\")\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f\"--input=train.en --model_prefix=spm_en --vocab_size={VOCAB_SIZE} \"\n",
    "        f\"--character_coverage=1.0 --model_type=unigram\"\n",
    "    )\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f\"--input=train.hi --model_prefix=spm_hi --vocab_size={VOCAB_SIZE} \"\n",
    "        f\"--character_coverage=0.9995 --model_type=unigram\"\n",
    "    )\n",
    "\n",
    "sp_en = spm.SentencePieceProcessor()\n",
    "sp_hi = spm.SentencePieceProcessor()\n",
    "sp_en.load(str(SP_EN_MODEL))\n",
    "sp_hi.load(str(SP_HI_MODEL))\n",
    "\n",
    "PAD_EN, BOS_EN, EOS_EN = 0, 1, 2\n",
    "PAD_HI, BOS_HI, EOS_HI = 0, 1, 2\n",
    "\n",
    "# =====================\n",
    "# Dataset & DataLoader\n",
    "# =====================\n",
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, dataset, src_sp, tgt_sp, max_len=MAX_LEN):\n",
    "        self.dataset = dataset\n",
    "        self.src_sp = src_sp\n",
    "        self.tgt_sp = tgt_sp\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_text = self.dataset[idx][\"src\"].lower()\n",
    "        tgt_text = self.dataset[idx][\"tgt\"]\n",
    "        src_ids = [BOS_EN] + self.src_sp.encode(src_text)[:self.max_len-2] + [EOS_EN]\n",
    "        tgt_ids = [BOS_HI] + self.tgt_sp.encode(tgt_text)[:self.max_len-2] + [EOS_HI]\n",
    "        src_ids += [PAD_EN] * (self.max_len - len(src_ids))\n",
    "        tgt_ids += [PAD_HI] * (self.max_len - len(tgt_ids))\n",
    "        return torch.tensor(src_ids), torch.tensor(tgt_ids)\n",
    "\n",
    "def get_loader(dataset_split, shuffle=True):\n",
    "    return DataLoader(NMTDataset(dataset_split, sp_en, sp_hi),\n",
    "                      batch_size=BATCH_SIZE, shuffle=shuffle)\n",
    "\n",
    "train_loader = get_loader(train_data)\n",
    "val_loader = get_loader(val_data)\n",
    "test_loader = get_loader(test_data, shuffle=False)\n",
    "\n",
    "# =====================\n",
    "# Masks\n",
    "# =====================\n",
    "def create_padding_mask(seq, lang='en'):\n",
    "    pad_id = PAD_EN if lang == 'en' else PAD_HI\n",
    "    return (seq == pad_id)\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    return torch.triu(torch.ones(sz, sz, device=DEVICE) * float('-inf'), diagonal=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "FrlXKxdYYm0y",
   "metadata": {
    "id": "FrlXKxdYYm0y"
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "def compute_bleu(references, hypotheses):\n",
    "    return sacrebleu.corpus_bleu(hypotheses, [references]).score\n",
    "\n",
    "\n",
    "def compute_ter(references, hypotheses):\n",
    "    return sacrebleu.corpus_ter(hypotheses, [references]).score\n",
    "\n",
    "\n",
    "def compute_meteor(references, hypotheses):\n",
    "    \"\"\"Tokenize input before computing METEOR.\"\"\"\n",
    "    def simple_tokenize(text):\n",
    "        return text.strip().split()\n",
    "\n",
    "    scores = []\n",
    "    for ref, hyp in zip(references, hypotheses):\n",
    "        ref_tokens = simple_tokenize(ref)\n",
    "        hyp_tokens = simple_tokenize(hyp)\n",
    "        try:\n",
    "            score = meteor_score([ref_tokens], hyp_tokens)\n",
    "        except Exception:\n",
    "            score = 0.0\n",
    "        scores.append(score)\n",
    "    return 100 * np.mean(scores)\n",
    "\n",
    "def detokenize(ids, sp):\n",
    "    \"\"\"Convert token IDs back to text.\"\"\"\n",
    "    if torch.is_tensor(ids):\n",
    "        ids = ids.tolist()\n",
    "    return sp.decode([id for id in ids if id not in [PAD_HI, BOS_HI, EOS_HI]])\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, sp_src, sp_tgt, device=DEVICE):\n",
    "    \"\"\"Generate translations and collect references & hypotheses.\"\"\"\n",
    "    model.eval()\n",
    "    references, hypotheses = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "            # Greedy decoding\n",
    "            memory = model.encode(src, create_padding_mask(src, 'en'))\n",
    "            ys = torch.full((src.size(0), 1), BOS_HI, dtype=torch.long, device=device)\n",
    "\n",
    "            for _ in range(MAX_GEN_LEN - 1):\n",
    "                tgt_mask = generate_square_subsequent_mask(ys.size(1))\n",
    "                out = model.decode(\n",
    "                    ys, memory, tgt_mask,\n",
    "                    create_padding_mask(src, 'en'),\n",
    "                    create_padding_mask(ys, 'hi')\n",
    "                )\n",
    "                prob = model.fc_out(out[:, -1, :])\n",
    "                next_word = prob.argmax(dim=-1, keepdim=True)\n",
    "                ys = torch.cat([ys, next_word], dim=1)\n",
    "\n",
    "            # Decode predictions and references\n",
    "            for i in range(src.size(0)):\n",
    "                ref = detokenize(tgt[i, 1:], sp_tgt)\n",
    "                hyp = detokenize(ys[i, 1:], sp_tgt)\n",
    "                references.append(ref.strip())\n",
    "                hypotheses.append(hyp.strip())\n",
    "\n",
    "    return references, hypotheses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "qlcgsVo6qEz5",
   "metadata": {
    "id": "qlcgsVo6qEz5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import sacrebleu\n",
    "from nltk.translate.meteor_score import meteor_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9196062a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3590088,
     "status": "ok",
     "timestamp": 1761420980049,
     "user": {
      "displayName": "Vaishnavi Pandey",
      "userId": "04316854011686855135"
     },
     "user_tz": -330
    },
    "id": "9196062a",
    "outputId": "45053472-5789-4906-9dde-c913429f0fc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Baseline Transformer loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Evaluating:   0%|          | 0/1563 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Evaluating: 100%|██████████| 1563/1563 [30:49<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Baseline Transformer Results:\n",
      "   BLEU : 8.58\n",
      "   METEOR : 0.13\n",
      "   TER : 130.53\n",
      "✅ Baseline metrics saved.\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE=32000\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=512, nhead=8,\n",
    "                 num_layers=3, dim_feedforward=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab, d_model, padding_idx=PAD_EN)\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab, d_model, padding_idx=PAD_HI)\n",
    "        self.pos_enc = nn.Parameter(torch.zeros(1, MAX_LEN, d_model))\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            num_encoder_layers=num_layers, num_decoder_layers=num_layers,\n",
    "            dim_feedforward=dim_feedforward, dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab)\n",
    "\n",
    "    def encode(self, src, src_key_padding_mask):\n",
    "        src_emb = self.src_emb(src) + self.pos_enc[:, :src.size(1), :]\n",
    "        return self.transformer.encoder(src_emb, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask):\n",
    "        tgt_emb = self.tgt_emb(tgt) + self.pos_enc[:, :tgt.size(1), :]\n",
    "        return self.transformer.decoder(\n",
    "            tgt_emb, memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_key_padding_mask=memory_key_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None,\n",
    "                memory_key_padding_mask=None, tgt_mask=None):\n",
    "        memory = self.encode(src, src_key_padding_mask)\n",
    "        output = self.decode(tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask)\n",
    "        return self.fc_out(output)\n",
    "\n",
    "# Baseline Transformer\n",
    "baseline_path = \"/content/drive/MyDrive/paper/best_model_baseline.pt\"\n",
    "model = TransformerModel(src_vocab=VOCAB_SIZE, tgt_vocab=VOCAB_SIZE)\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(baseline_path, map_location=DEVICE)\n",
    "state_dict = checkpoint.get(\"model_state_dict\", checkpoint)\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.to(DEVICE)\n",
    "print(\"✅ Baseline Transformer loaded.\")\n",
    "\n",
    "# Evaluate\n",
    "refs, hyps = evaluate_model(model, test_loader, sp_en, sp_hi)\n",
    "\n",
    "# Compute metrics\n",
    "baseline_metrics = {\n",
    "    \"BLEU\": compute_bleu(refs, hyps),\n",
    "    \"METEOR\": compute_meteor(refs, hyps),\n",
    "    \"TER\": compute_ter(refs, hyps)\n",
    "}\n",
    "\n",
    "print(\"📊 Baseline Transformer Results:\")\n",
    "for k, v in baseline_metrics.items():\n",
    "    print(f\"   {k} : {v:.2f}\")\n",
    "\n",
    "# Save metrics\n",
    "torch.save(baseline_metrics, \"/content/drive/MyDrive/paper/baseline_metrics.pt\")\n",
    "print(\"✅ Baseline metrics saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4875ee6",
   "metadata": {
    "id": "a4875ee6"
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# CNN Feature Extractor (2-layer)\n",
    "# =====================\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(embed_dim, embed_dim, kernel_size=5, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(embed_dim, embed_dim, kernel_size=3, padding=1)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        return self.norm(x + residual)\n",
    "\n",
    "# =====================\n",
    "# Hybrid CNN + Transformer Model\n",
    "# =====================\n",
    "class HybridTransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=512, nhead=8,\n",
    "                 num_layers=3, dim_feedforward=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab, d_model, padding_idx=PAD_EN)\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab, d_model, padding_idx=PAD_HI)\n",
    "        self.pos_enc = nn.Parameter(torch.zeros(1, MAX_LEN, d_model))\n",
    "        self.cnn_encoder = CNNFeatureExtractor(d_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            num_encoder_layers=num_layers, num_decoder_layers=num_layers,\n",
    "            dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab)\n",
    "\n",
    "    def encode(self, src, src_key_padding_mask):\n",
    "        src_emb = self.src_emb(src) + self.pos_enc[:, :src.size(1), :]\n",
    "        src_cnn = self.cnn_encoder(src_emb)\n",
    "        return self.transformer.encoder(src_cnn, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask):\n",
    "        tgt_emb = self.tgt_emb(tgt) + self.pos_enc[:, :tgt.size(1), :]\n",
    "        return self.transformer.decoder(\n",
    "            tgt_emb, memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_key_padding_mask=memory_key_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None,\n",
    "                memory_key_padding_mask=None, tgt_mask=None):\n",
    "        memory = self.encode(src, src_key_padding_mask)\n",
    "        output = self.decode(tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask)\n",
    "        return self.fc_out(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1D5oNSHgYaz9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8444687,
     "status": "ok",
     "timestamp": 1761493431731,
     "user": {
      "displayName": "Vaishnavi Pandey",
      "userId": "17951836098704094388"
     },
     "user_tz": -330
    },
    "id": "1D5oNSHgYaz9",
    "outputId": "007c879b-f2ab-4c07-f4d4-5c6c1600ff77"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1563/1563 [3:25:43<00:00,  7.90s/batch]\n",
      "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Metrics calculated and saved successfully (.pt)!\n",
      "{'timestamp': '2025-10-26 15:43:52', 'BLEU': 19.0, 'TER': 73.97, 'METEOR': 38.39}\n",
      "\n",
      "✨ Sample Translations:\n",
      "\n",
      "EN: lahore: The Pakistan English press has showered heap of praise on legendary Indian batsman Sachin Tendulkar in their editorials, saying the game of cricket will surely be poorer without him.\n",
      "HI (Ref): लाहौर पाकिस्तान की अग्रेंजी प्रेस ने अपने संपादकीय में महान भारतीय बल्लेबाज सचिन तेंदुलकर की तारीफों के पुल बांधे है और लिखा है, ‘उनके बिना क्रिकेट खेल निश्चित रूप से दरिद्र’ हो जायेगा। हालांकि उर्दू प्रेस में उनके बारे में ज्यादा कुछ नहीं लिखा गया है लेकिन अंग्रेजी के अखबारों ने तेंदुलकर... आगे पढ़े\n",
      "HI (Pred): पाकिस्तान के इंग्लिश प्रीमियर लीग (एआईसीसी) के प्रख्यात बल्लेबाज सचिन तेंदुलकर ने अपने संपादकीय में कहा है कि क्रिकेट का खेल निश्चित रूप से उनके बिना सबसे बड़ा होगा।\n",
      "------------------------------------------------------------\n",
      "\n",
      "EN: Telecom operator Reliance Jio has announced a new plan for its prepaid customers.\n",
      "HI (Ref): टेलीकॉम इंडस्ट्री में तहलका मचने वाली कंपनी रिलायंस जियो ने फिर से अपने ग्राहकों के लिए नए प्लान्स पेश किये\n",
      "HI (Pred): टेलीकॉम ऑपरेटर रिलायंस जियो ने अपने प्रीपेड ग्राहकों के लिए नया प्लान लॉन्च कर दिया है।\n",
      "------------------------------------------------------------\n",
      "\n",
      "EN: Meanwhile, the police have initiated the investigation after the arrest of two persons.\n",
      "HI (Ref): फिलहाल पुलिस ने दो लोगों को हिरासत में लेकर पूछताछ शुरू कर दी है।\n",
      "HI (Pred): वहीं पुलिस ने दो लोगों की गिरफ्तारी के बाद जांच शुरू कर दी है।\n",
      "------------------------------------------------------------\n",
      "\n",
      "EN: New Delhi, September 2\n",
      "HI (Ref): नयी दिल्ली, 2 सितंबर (भाषा)।\n",
      "HI (Pred): नयी दिल्ली, 2 सितंबर (एजेंसी)\n",
      "------------------------------------------------------------\n",
      "\n",
      "EN: Below them is seated a scribe recording the interpretation.\n",
      "HI (Ref): इसे नीचे बैठा लिपिक लिपिबद्ध कर रहा है।\n",
      "HI (Pred): नीचे दिए गए एक लेखक की व्याख्या का रिकार्ड है।\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# ⚡ BLEU + METEOR + TER Evaluation + Translation + Save Metrics (.pt)\n",
    "# =====================================================\n",
    "import torch\n",
    "import sacrebleu\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import sentencepiece as spm\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import nltk\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Download necessary NLTK data (only if not already)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "# =====================================================\n",
    "# ✅ Load SentencePiece Models\n",
    "# =====================================================\n",
    "sp_en = spm.SentencePieceProcessor()\n",
    "sp_hi = spm.SentencePieceProcessor()\n",
    "sp_en.load(\"/content/drive/MyDrive/paper/spm_en.model\")\n",
    "sp_hi.load(\"/content/drive/MyDrive/paper/spm_hi.model\")\n",
    "\n",
    "# Token IDs\n",
    "PAD_EN, BOS_EN, EOS_EN = 0, 1, 2\n",
    "PAD_HI, BOS_HI, EOS_HI = 0, 1, 2\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# =====================================================\n",
    "# ✅ Load Model\n",
    "# =====================================================\n",
    "model = HybridTransformerModel(len(sp_en), len(sp_hi)).to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"/content/drive/MyDrive/paper/best_model_cnn.pt\", map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# =====================================================\n",
    "# ✅ Utility Functions\n",
    "# =====================================================\n",
    "def create_padding_mask(seq, lang='en'):\n",
    "    pad_id = PAD_EN if lang == 'en' else PAD_HI\n",
    "    return (seq == pad_id)\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
    "\n",
    "# =====================================================\n",
    "# ✅ Translation Function (Greedy Decoding)\n",
    "# =====================================================\n",
    "@torch.no_grad()\n",
    "def translate_sentence(sentence, model, sp_en, sp_hi, max_len=64):\n",
    "    model.eval()\n",
    "    src_ids = [BOS_EN] + sp_en.encode(sentence.lower())[:max_len-2] + [EOS_EN]\n",
    "    src = torch.tensor(src_ids, dtype=torch.long, device=DEVICE).unsqueeze(0)\n",
    "    src_mask = create_padding_mask(src, 'en')\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    tgt = torch.tensor([[BOS_HI]], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        tgt_mask = generate_square_subsequent_mask(tgt.size(1)).to(DEVICE)\n",
    "        tgt_key_padding_mask = create_padding_mask(tgt, 'hi')\n",
    "\n",
    "        output = model.decode(\n",
    "            tgt, memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_key_padding_mask=src_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "\n",
    "        logits = model.fc_out(output[:, -1, :])\n",
    "        next_token = logits.argmax(-1).item()\n",
    "        tgt = torch.cat([tgt, torch.tensor([[next_token]], device=DEVICE)], dim=1)\n",
    "\n",
    "        if next_token == EOS_HI:\n",
    "            break\n",
    "\n",
    "    tokens = [t for t in tgt.squeeze().tolist() if t not in [BOS_HI, EOS_HI, PAD_HI]]\n",
    "    decoded = sp_hi.decode(tokens) if tokens else \"\"\n",
    "    return decoded.strip()\n",
    "\n",
    "# =====================================================\n",
    "# ✅ Evaluation Function with .pt Saving\n",
    "# =====================================================\n",
    "def evaluate_model(model, test_loader, test_data, metrics_path=\"/content/drive/MyDrive/paper/cnn_metrics.pt\"):\n",
    "    # ---- Check if already saved ----\n",
    "    if os.path.exists(metrics_path):\n",
    "        print(f\"📂 Found saved metrics file: {metrics_path}\")\n",
    "        results = torch.load(metrics_path)\n",
    "        print(\"\\n✅ Loaded existing metrics:\")\n",
    "        print(results)\n",
    "        return results\n",
    "\n",
    "    refs, hyps, meteor_scores = [], [], []\n",
    "    print(\"🔍 Evaluating on test set...\")\n",
    "\n",
    "    for src, tgt in tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\"):\n",
    "        src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "        for i in range(src.size(0)):\n",
    "            src_text = sp_en.decode([t for t in src[i].tolist() if t not in [BOS_EN, EOS_EN, PAD_EN]])\n",
    "            tgt_text = sp_hi.decode([t for t in tgt[i].tolist() if t not in [BOS_HI, EOS_HI, PAD_HI]])\n",
    "            pred_text = translate_sentence(src_text, model, sp_en, sp_hi)\n",
    "\n",
    "            refs.append(tgt_text)\n",
    "            hyps.append(pred_text)\n",
    "            meteor_scores.append(meteor_score([tgt_text.split()], pred_text.split()))\n",
    "\n",
    "    # ---- Calculate Metrics ----\n",
    "    bleu = sacrebleu.corpus_bleu(hyps, [refs])\n",
    "    ter_metric = sacrebleu.metrics.TER()\n",
    "    ter = ter_metric.corpus_score(hyps, [refs])\n",
    "    meteor_avg = sum(meteor_scores) / len(meteor_scores)\n",
    "\n",
    "    results = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"BLEU\": round(bleu.score, 2),\n",
    "        \"TER\": round(ter.score, 2),\n",
    "        \"METEOR\": round(meteor_avg * 100, 2)  # scaled to 0–100\n",
    "    }\n",
    "\n",
    "    # ---- Save Metrics (.pt) ----\n",
    "    torch.save(results, metrics_path)\n",
    "\n",
    "    print(\"\\n✅ Metrics calculated and saved successfully (.pt)!\")\n",
    "    print(results)\n",
    "    return results\n",
    "\n",
    "# =====================================================\n",
    "# ✅ Run Evaluation\n",
    "# =====================================================\n",
    "metrics = evaluate_model(model, test_loader, test_data)\n",
    "\n",
    "# =====================================================\n",
    "# ✅ Show Sample Translations\n",
    "# =====================================================\n",
    "sample_indices = random.sample(range(len(test_data)), 5)\n",
    "print(\"\\n✨ Sample Translations:\")\n",
    "for idx in sample_indices:\n",
    "    src_text = test_data[idx][\"src\"]\n",
    "    ref_text = test_data[idx][\"tgt\"]\n",
    "    pred_text = translate_sentence(src_text, model, sp_en, sp_hi)\n",
    "    print(f\"\\nEN: {src_text}\")\n",
    "    print(f\"HI (Ref): {ref_text}\")\n",
    "    print(f\"HI (Pred): {pred_text}\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vZtg_dhAKr4G",
   "metadata": {
    "id": "vZtg_dhAKr4G"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE=32000\n",
    "# =====================\n",
    "# Multi-Scale CNN\n",
    "# =====================\n",
    "class MultiScaleCNN(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.conv3 = nn.Conv1d(embed_dim, embed_dim, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv1d(embed_dim, embed_dim, kernel_size=5, padding=2)\n",
    "        self.conv7 = nn.Conv1d(embed_dim, embed_dim, kernel_size=7, padding=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = x.transpose(1, 2)\n",
    "        out3 = self.conv3(x)\n",
    "        out5 = self.conv5(x)\n",
    "        out7 = self.conv7(x)\n",
    "        x = out3 + out5 + out7\n",
    "        x = self.relu(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        return self.norm(x + residual)\n",
    "\n",
    "# =====================\n",
    "# Hybrid Transformer + MultiScale CNN\n",
    "# =====================\n",
    "class HybridTransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=512, nhead=8,\n",
    "                 num_layers=3, dim_feedforward=1024, dropout=0.1, temperature=0.1):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab, d_model, padding_idx=PAD_EN)\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab, d_model, padding_idx=PAD_HI)\n",
    "        self.pos_enc = nn.Parameter(torch.zeros(1, MAX_LEN, d_model))\n",
    "        self.cnn_encoder = MultiScaleCNN(d_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            num_encoder_layers=num_layers, num_decoder_layers=num_layers,\n",
    "            dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def encode(self, src, src_key_padding_mask):\n",
    "        src_emb = self.src_emb(src) + self.pos_enc[:, :src.size(1), :]\n",
    "        src_cnn = self.cnn_encoder(src_emb)\n",
    "        return self.transformer.encoder(src_cnn, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask):\n",
    "        tgt_emb = self.tgt_emb(tgt) + self.pos_enc[:, :tgt.size(1), :]\n",
    "        return self.transformer.decoder(\n",
    "            tgt_emb, memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_key_padding_mask=memory_key_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None,\n",
    "                memory_key_padding_mask=None, tgt_mask=None):\n",
    "        memory = self.encode(src, src_key_padding_mask)\n",
    "        output = self.decode(tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask)\n",
    "        return self.fc_out(output)\n",
    "\n",
    "    # -----------------------\n",
    "    # Contrastive loss\n",
    "    # -----------------------\n",
    "    def contrastive_loss(self, anchor, positive, negative):\n",
    "        anchor = anchor.mean(dim=1)\n",
    "        positive = positive.mean(dim=1)\n",
    "        negative = negative.mean(dim=1)\n",
    "        pos_sim = torch.cosine_similarity(anchor, positive, dim=-1)\n",
    "        neg_sim = torch.cosine_similarity(anchor, negative, dim=-1)\n",
    "        loss = -torch.log(torch.exp(pos_sim / self.temperature) / (torch.exp(pos_sim / self.temperature) + torch.exp(neg_sim / self.temperature)))\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aOs9oejkoifB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5122132,
     "status": "ok",
     "timestamp": 1761540750857,
     "user": {
      "displayName": "Neeraj Pandey",
      "userId": "06506190899472003382"
     },
     "user_tz": -330
    },
    "id": "aOs9oejkoifB",
    "outputId": "656dbd75-d1fc-4d9d-9c6c-d202ccd51f38"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded successfully on cuda\n",
      "🔄 Resuming from partial evaluation at sentence 30000\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/70000 [00:00<?, ?sentence/s]/tmp/ipython-input-1258348437.py:64: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # mixed precision for faster inference\n",
      "Evaluating:  14%|█▍        | 10002/70000 [18:28<1:29:23, 11.19sentence/s]"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved progress at sentence 40000\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  29%|██▊       | 20002/70000 [36:26<1:35:58,  8.68sentence/s]"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved progress at sentence 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  43%|████▎     | 30001/70000 [54:19<1:20:30,  8.28sentence/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved progress at sentence 60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  57%|█████▋    | 40001/70000 [1:12:16<1:22:58,  6.03sentence/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved progress at sentence 70000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  71%|███████▏  | 50002/70000 [1:29:56<37:27,  8.90sentence/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved progress at sentence 80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  86%|████████▌ | 60001/70000 [1:47:49<23:20,  7.14sentence/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved progress at sentence 90000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 70000/70000 [2:05:40<00:00,  9.28sentence/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved progress at sentence 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Final metrics calculated and saved:\n",
      "{'timestamp': '2025-10-27 04:52:32', 'BLEU': 18.43, 'TER': 72.3, 'METEOR': 38.0}\n",
      "✨ Sample Translations (MultiScale CNN):\n",
      "\n",
      "EN: lahore: The Pakistan English press has showered heap of praise on legendary Indian batsman Sachin Tendulkar in their editorials, saying the game of cricket will surely be poorer without him.\n",
      "HI (Ref): लाहौर पाकिस्तान की अग्रेंजी प्रेस ने अपने संपादकीय में महान भारतीय बल्लेबाज सचिन तेंदुलकर की तारीफों के पुल बांधे है और लिखा है, ‘उनके बिना क्रिकेट खेल निश्चित रूप से दरिद्र’ हो जायेगा। हालांकि उर्दू प्रेस में उनके बारे में ज्यादा कुछ नहीं लिखा गया है लेकिन अंग्रेजी के अखबारों ने तेंदुलकर... आगे पढ़े\n",
      "HI (Pred): पाकिस्तान क्रिकेट टीम के पूर्व कप्तान सचिन तेंदुलकर ने अपने सम्पादकों में तारीफ की है।\n",
      "--------------------------------------------------\n",
      "\n",
      "EN: Telecom operator Reliance Jio has announced a new plan for its prepaid customers.\n",
      "HI (Ref): टेलीकॉम इंडस्ट्री में तहलका मचने वाली कंपनी रिलायंस जियो ने फिर से अपने ग्राहकों के लिए नए प्लान्स पेश किये\n",
      "HI (Pred): रिलायंस जियो ने अपने प्रीपेड ग्राहकों के लिए एक नया प्लान लॉन्च किया है।\n",
      "--------------------------------------------------\n",
      "\n",
      "EN: Meanwhile, the police have initiated the investigation after the arrest of two persons.\n",
      "HI (Ref): फिलहाल पुलिस ने दो लोगों को हिरासत में लेकर पूछताछ शुरू कर दी है।\n",
      "HI (Pred): वहीं, पुलिस ने दो लोगों की गिरफ्तारी के बाद जांच शुरू कर दी है।\n",
      "--------------------------------------------------\n",
      "\n",
      "EN: New Delhi, September 2\n",
      "HI (Ref): नयी दिल्ली, 2 सितंबर (भाषा)।\n",
      "HI (Pred): चंडीगढ़, 2 सितंबर (ट्रिन्यू)\n",
      "--------------------------------------------------\n",
      "\n",
      "EN: Below them is seated a scribe recording the interpretation.\n",
      "HI (Ref): इसे नीचे बैठा लिपिक लिपिबद्ध कर रहा है।\n",
      "HI (Pred): नीचे उनके लेखक को लिखने का काम सौंपा गया है।\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# ⚡ Optimized BLEU + METEOR + TER Evaluation + Incremental Save\n",
    "# =====================================================\n",
    "import torch\n",
    "import sacrebleu\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sentencepiece as spm\n",
    "import torch\n",
    "import sacrebleu\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import sentencepiece as spm\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import nltk\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Download necessary NLTK data (only if not already)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "# =====================\n",
    "# Load SentencePiece Models\n",
    "# =====================\n",
    "sp_en = spm.SentencePieceProcessor()\n",
    "sp_hi = spm.SentencePieceProcessor()\n",
    "sp_en.load(\"/content/drive/MyDrive/paper/spm_en.model\")\n",
    "sp_hi.load(\"/content/drive/MyDrive/paper/spm_hi.model\")\n",
    "\n",
    "PAD_EN, BOS_EN, EOS_EN = 0, 1, 2\n",
    "PAD_HI, BOS_HI, EOS_HI = 0, 1, 2\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# =====================\n",
    "# Load Model\n",
    "# =====================\n",
    "model = HybridTransformerModel(len(sp_en), len(sp_hi)).to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"/content/drive/MyDrive/paper/best_model_multiscale.pt\", map_location=DEVICE))\n",
    "model.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "print(\"✅ Model loaded successfully on\", DEVICE)\n",
    "\n",
    "# =====================\n",
    "# Utility Functions\n",
    "# =====================\n",
    "def create_padding_mask(seq, lang='en'):\n",
    "    pad_id = PAD_EN if lang == 'en' else PAD_HI\n",
    "    return (seq == pad_id)\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1).to(DEVICE)\n",
    "\n",
    "# =====================\n",
    "# Optimized Greedy Decoding\n",
    "# =====================\n",
    "@torch.no_grad()\n",
    "def translate_sentence_multiscale(sentence, model, sp_en, sp_hi, max_len=64):\n",
    "    with autocast():  # mixed precision for faster inference\n",
    "        src_ids = [BOS_EN] + sp_en.encode(sentence.lower())[:max_len-2] + [EOS_EN]\n",
    "        src = torch.tensor(src_ids, dtype=torch.long, device=DEVICE).unsqueeze(0)\n",
    "        src_mask = create_padding_mask(src, 'en')\n",
    "\n",
    "        memory = model.encode(src, src_mask)\n",
    "        tgt = torch.tensor([[BOS_HI]], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            tgt_mask = generate_square_subsequent_mask(tgt.size(1))\n",
    "            tgt_key_padding_mask = create_padding_mask(tgt, 'hi')\n",
    "\n",
    "            output = model.decode(\n",
    "                tgt, memory,\n",
    "                tgt_mask=tgt_mask,\n",
    "                memory_key_padding_mask=src_mask,\n",
    "                tgt_key_padding_mask=tgt_key_padding_mask\n",
    "            )\n",
    "            logits = model.fc_out(output[:, -1, :])\n",
    "            next_token = logits.argmax(-1).item()\n",
    "            tgt = torch.cat([tgt, torch.tensor([[next_token]], device=DEVICE)], dim=1)\n",
    "\n",
    "            if next_token == EOS_HI:\n",
    "                break\n",
    "\n",
    "        decoded = sp_hi.decode([t for t in tgt.squeeze().tolist() if t not in [BOS_HI, EOS_HI, PAD_HI]])\n",
    "        return decoded\n",
    "\n",
    "# =====================\n",
    "# Evaluation Function with Incremental Save\n",
    "# =====================\n",
    "def evaluate_and_save_metrics(test_data, metrics_path=\"/content/drive/MyDrive/paper/multiscale_metrics.pt\", save_every=10000):\n",
    "    partial_path = metrics_path + \".partial.pt\"\n",
    "\n",
    "    # Load partial results if exist\n",
    "    if os.path.exists(partial_path):\n",
    "        data = torch.load(partial_path)\n",
    "        refs = data[\"refs\"]\n",
    "        hyps = data[\"hyps\"]\n",
    "        meteor_scores = data[\"meteor_scores\"]\n",
    "        start_idx = data.get(\"last_idx\", 0)\n",
    "        print(f\"🔄 Resuming from partial evaluation at sentence {start_idx}\")\n",
    "    else:\n",
    "        refs, hyps, meteor_scores = [], [], []\n",
    "        start_idx = 0\n",
    "\n",
    "    # Evaluate sentence-by-sentence\n",
    "    for idx in tqdm(range(start_idx, len(test_data)), desc=\"Evaluating\", unit=\"sentence\", dynamic_ncols=True):\n",
    "        example = test_data[idx]\n",
    "        src_text = example[\"src\"]\n",
    "        ref_text = example[\"tgt\"]\n",
    "        pred_text = translate_sentence_multiscale(src_text, model, sp_en, sp_hi)\n",
    "\n",
    "        refs.append(ref_text)\n",
    "        hyps.append(pred_text)\n",
    "        meteor_scores.append(meteor_score([ref_text.split()], pred_text.split()))\n",
    "\n",
    "        # Incremental save\n",
    "        if (idx + 1) % save_every == 0 or (idx + 1) == len(test_data):\n",
    "            torch.save({\n",
    "                \"refs\": refs,\n",
    "                \"hyps\": hyps,\n",
    "                \"meteor_scores\": meteor_scores,\n",
    "                \"last_idx\": idx + 1\n",
    "            }, partial_path)\n",
    "            print(f\"💾 Saved progress at sentence {idx+1}\")\n",
    "\n",
    "    # Compute final metrics\n",
    "    bleu = sacrebleu.corpus_bleu(hyps, [refs])\n",
    "    ter_metric = sacrebleu.metrics.TER()\n",
    "    ter = ter_metric.corpus_score(hyps, [refs])\n",
    "    meteor_avg = sum(meteor_scores) / len(meteor_scores)\n",
    "\n",
    "    results = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"BLEU\": round(bleu.score, 2),\n",
    "        \"TER\": round(ter.score, 2),\n",
    "        \"METEOR\": round(meteor_avg * 100, 2)\n",
    "    }\n",
    "\n",
    "    # Save final metrics and remove partial file\n",
    "    torch.save(results, metrics_path)\n",
    "    if os.path.exists(partial_path):\n",
    "        os.remove(partial_path)\n",
    "    print(\"\\n✅ Final metrics calculated and saved:\")\n",
    "    print(results)\n",
    "    return results\n",
    "\n",
    "# =====================\n",
    "# Run Evaluation\n",
    "# =====================\n",
    "metrics = evaluate_and_save_metrics(test_data, metrics_path=\"/content/drive/MyDrive/paper/multiscale_metrics.pt\", save_every=10000)\n",
    "\n",
    "# =====================\n",
    "# Show Sample Translations\n",
    "# =====================\n",
    "sample_indices = random.sample(range(len(test_data)), 5)\n",
    "print(\"✨ Sample Translations (MultiScale CNN):\")\n",
    "for idx in sample_indices:\n",
    "    src_text = test_data[idx][\"src\"]\n",
    "    ref_text = test_data[idx][\"tgt\"]\n",
    "    pred_text = translate_sentence_multiscale(src_text, model, sp_en, sp_hi)\n",
    "    print(f\"\\nEN: {src_text}\")\n",
    "    print(f\"HI (Ref): {ref_text}\")\n",
    "    print(f\"HI (Pred): {pred_text}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6X8rZuayR-PQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1172,
     "status": "ok",
     "timestamp": 1761541455975,
     "user": {
      "displayName": "Neeraj Pandey",
      "userId": "06506190899472003382"
     },
     "user_tz": -330
    },
    "id": "6X8rZuayR-PQ",
    "outputId": "4f9c381a-ddc1-4654-e0b9-61f5c489534b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Comparative Results:\n",
      "               Model      BLEU    METEOR        TER\n",
      "         2-Layer CNN 19.000000 38.390000  73.970000\n",
      "     Multi-Scale CNN 18.430000 38.000000  72.300000\n",
      "Baseline Transformer  8.576798  0.126633 130.530133\n",
      "\n",
      "💾 Results saved to /content/drive/MyDrive/paper/comparison_results.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Paths to metric files\n",
    "paths = {\n",
    "    \"Baseline Transformer\": \"/content/drive/MyDrive/paper/baseline_metrics.pt\",\n",
    "    \"2-Layer CNN\": \"/content/drive/MyDrive/paper/cnn_metrics.pt\",\n",
    "    \"Multi-Scale CNN\": \"/content/drive/MyDrive/paper/multiscale_metrics.pt\"\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, path in paths.items():\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"⚠️ Missing: {path}\")\n",
    "        continue\n",
    "\n",
    "    # ✅ Fix: allow loading full objects (not just weights)\n",
    "    data = torch.load(path, weights_only=False)\n",
    "\n",
    "    # Make sure data is a dict\n",
    "    if not isinstance(data, dict):\n",
    "        print(f\"⚠️ {path} is not a metrics dict — skipping\")\n",
    "        continue\n",
    "\n",
    "    rows.append({\n",
    "        \"Model\": name,\n",
    "        \"BLEU\": data.get(\"BLEU\"),\n",
    "        \"METEOR\": data.get(\"METEOR\"),\n",
    "        \"TER\": data.get(\"TER\")\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows).sort_values(by=\"BLEU\", ascending=False)\n",
    "print(\"\\n📊 Comparative Results:\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Save CSV\n",
    "save_path = \"/content/drive/MyDrive/paper/comparison_results.csv\"\n",
    "df.to_csv(save_path, index=False)\n",
    "print(f\"\\n💾 Results saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0217cd3-7f03-4217-8c59-196266597553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Gated Multi-Scale CNN\n",
    "# =====================\n",
    "class GatedMultiScaleCNN(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.conv3 = nn.Conv1d(embed_dim, embed_dim, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv1d(embed_dim, embed_dim, kernel_size=5, padding=2)\n",
    "        self.conv7 = nn.Conv1d(embed_dim, embed_dim, kernel_size=7, padding=3)\n",
    "        self.gate_proj = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim // 2, 3)\n",
    "        )\n",
    "        self.activation = nn.ReLU()\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, embed_dim)\n",
    "        residual = x\n",
    "        b, s, d = x.size()\n",
    "        x_t = x.transpose(1, 2)  # (b, d, s)\n",
    "        o3 = self.conv3(x_t).transpose(1, 2)  # (b, s, d)\n",
    "        o5 = self.conv5(x_t).transpose(1, 2)\n",
    "        o7 = self.conv7(x_t).transpose(1, 2)\n",
    "        stacked = torch.stack([o3, o5, o7], dim=-1)  # (b, s, d, 3)\n",
    "        gates = self.gate_proj(residual)             # (b, s, 3)\n",
    "        gates = F.softmax(gates, dim=-1).unsqueeze(2)  # (b, s, 1, 3)\n",
    "        fused = (stacked * gates).sum(-1)            # (b, s, d)\n",
    "        fused = self.activation(fused)\n",
    "        out = self.norm(fused + residual)\n",
    "        return out\n",
    "\n",
    "# =====================\n",
    "# Hybrid Transformer Model (GMSCNN encoder)\n",
    "# =====================\n",
    "class HybridTransformerModelGMSC(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=512, nhead=8,\n",
    "                 num_layers=3, dim_feedforward=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab, d_model, padding_idx=PAD_EN)\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab, d_model, padding_idx=PAD_HI)\n",
    "        self.pos_enc = nn.Parameter(torch.zeros(1, MAX_LEN, d_model))\n",
    "        self.cnn_encoder = GatedMultiScaleCNN(d_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            num_encoder_layers=num_layers, num_decoder_layers=num_layers,\n",
    "            dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab)\n",
    "\n",
    "    def encode(self, src, src_key_padding_mask):\n",
    "        src_emb = self.src_emb(src) + self.pos_enc[:, :src.size(1), :]\n",
    "        src_cnn = self.cnn_encoder(src_emb)\n",
    "        return self.transformer.encoder(src_cnn, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask):\n",
    "        tgt_emb = self.tgt_emb(tgt) + self.pos_enc[:, :tgt.size(1), :]\n",
    "        return self.transformer.decoder(\n",
    "            tgt_emb, memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_key_padding_mask=memory_key_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None,\n",
    "                memory_key_padding_mask=None, tgt_mask=None):\n",
    "        memory = self.encode(src, src_key_padding_mask)\n",
    "        output = self.decode(tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask)\n",
    "        return self.fc_out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sAZL3BJyGp-r",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18632,
     "status": "ok",
     "timestamp": 1761543077574,
     "user": {
      "displayName": "Vaishnavi Pandey",
      "userId": "17951836098704094388"
     },
     "user_tz": -330
    },
    "id": "sAZL3BJyGp-r",
    "outputId": "84093702-dc72-4902-b9ab-4f5774132aba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_25336\\1388324692.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  baseline.load_state_dict(torch.load(\"best_model_baseline.pt\", map_location=DEVICE))\n",
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_25336\\1388324692.py:240: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cnn.load_state_dict(torch.load(\"best_model_cnn.pt\", map_location=DEVICE))\n",
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_25336\\1388324692.py:241: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  multiscale.load_state_dict(torch.load(\"best_model_multiscale.pt\", map_location=DEVICE))\n",
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_25336\\1388324692.py:242: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  gmsc_model.load_state_dict(torch.load(\"best_model_gmsc.pt\", map_location=DEVICE))  # ✅ corrected name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= 🌍 Translation Comparison (20 Sentences) =================\n",
      "\n",
      "🔹 Sentence 1: Where are you going today?\n",
      "--------------------------------------------------------------\n",
      "🧠 Baseline Transformer   : मुझसे पहले?\n",
      "⚙️  2-Layer CNN Hybrid     : इससे पहले कि आप मुझसे जा रहे हैं?\n",
      "🚀 Multi-Scale Hybrid      : पहले ( तुम मुझे जाना चाहो?\n",
      "🪄 Gated Multi-Scale Hybrid : इससे पहले (तुम मुझे जाने के लिए)?\n",
      "📖 Reference Translation   : आज आप कहाँ जा रहे हैं?\n",
      "✅ Improved\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_25336\\1388324692.py:192: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sentence 2: I love learning new languages.\n",
      "--------------------------------------------------------------\n",
      "🧠 Baseline Transformer   : मैं विकास के नए दौर नहीं कर सकता।\n",
      "⚙️  2-Layer CNN Hybrid     : मैं नई नहीं मिल सकती।\n",
      "🚀 Multi-Scale Hybrid      : मैं विकास नहीं कर सकता।\n",
      "🪄 Gated Multi-Scale Hybrid : मैं विकास दर नई नहीं ले सकता।\n",
      "📖 Reference Translation   : मुझे नई भाषाएँ सीखना पसंद है।\n",
      "✅ Improved\n",
      "--------------------------------------------------------------\n",
      "\n",
      "🔹 Sentence 3: This movie was absolutely amazing!\n",
      "--------------------------------------------------------------\n",
      "🧠 Baseline Transformer   : बीईएल द्वारा प्रक्रियाएं\n",
      "⚙️  2-Layer CNN Hybrid     : आईएसएल की प्रक्रिया संहिताएं इस समय समाप्त हो चुकी हैं।\n",
      "🚀 Multi-Scale Hybrid      : बाइल बेवसाइट एनालिटिक्स पेश करें\n",
      "🪄 Gated Multi-Scale Hybrid : एल बीआईटी के द्वारा उपस्थित होना\n",
      "📖 Reference Translation   : यह फिल्म बिल्कुल शानदार थी।\n",
      "✅ Improved\n",
      "--------------------------------------------------------------\n",
      "\n",
      "🔹 Sentence 4: The weather is pleasant and the sky is clear.\n",
      "--------------------------------------------------------------\n",
      "🧠 Baseline Transformer   : पुलवामा में सबसे बड़ा और साफ है।\n",
      "⚙️  2-Layer CNN Hybrid     : इमरान खान और पुलवामा के सबसे बड़े और स्पष्ट हैं।\n",
      "🚀 Multi-Scale Hybrid      : इमरान का बड़ा और पुलवामा का साफ है।\n",
      "🪄 Gated Multi-Scale Hybrid : इमरान का बड़ा और पुलवामा का साफ-साफ रास्ता साफ है।\n",
      "📖 Reference Translation   : मौसम सुहावना है और आसमान साफ है।\n",
      "✅ Improved\n",
      "--------------------------------------------------------------\n",
      "\n",
      "🔹 Sentence 5: He completed his project before the deadline.\n",
      "--------------------------------------------------------------\n",
      "🧠 Baseline Transformer   : वह अपने सेंटदास के सेंटीमेंट में पहुंच गए हैं।\n",
      "⚙️  2-Layer CNN Hybrid     : वह अपने ई-पाठ तक पहुंच गया।\n",
      "🚀 Multi-Scale Hybrid      : वह अपनी ई-मात्रा तक पहुंच चुका है।\n",
      "🪄 Gated Multi-Scale Hybrid : वहदास को अपने ई सेंट डाँन तक पहुँचा।\n",
      "📖 Reference Translation   : उसने समय सीमा से पहले अपना प्रोजेक्ट पूरा कर लिया।\n",
      "✅ Improved\n",
      "--------------------------------------------------------------\n",
      "\n",
      "🔹 Sentence 6: Artificial intelligence is transforming the world.\n",
      "--------------------------------------------------------------\n",
      "🧠 Baseline Transformer   : फोल्डर्स 1974 की फिल्म.\n",
      "⚙️  2-Layer CNN Hybrid     : फोल्डर 1974 की एसआईटी ने फिल्म को 1974 में दिखाया था।\n",
      "🚀 Multi-Scale Hybrid      : फोल्डर SIT की फिल्म की शूटिंग कर रही है।\n",
      "🪄 Gated Multi-Scale Hybrid : फ़ोल्डर ने 1974 की फिल्म बनाई।\n",
      "📖 Reference Translation   : कृत्रिम बुद्धिमत्ता दुनिया को बदल रही है।\n",
      "✅ Improved\n",
      "--------------------------------------------------------------\n",
      "\n",
      "🔹 Sentence 7: She cooks delicious food for her family every day.\n",
      "--------------------------------------------------------------\n",
      "🧠 Baseline Transformer   : देश की कॉफ़ी-आईएसयू परियोजना हर महिला के लिए होती है।\n",
      "⚙️  2-Layer CNN Hybrid     : हर किसी के लिए देश कॉफी का काम है, हर किसी के लिए वोई की कॉफ़ी प्रोजेक्ट है।\n",
      "🚀 Multi-Scale Hybrid      : हर साल कॉफी की कॉफी की परियोजना है।\n",
      "🪄 Gated Multi-Scale Hybrid : देश का कॉफी हर महिला के लिए ताइपे परियोजना है।\n",
      "📖 Reference Translation   : वह हर दिन अपने परिवार के लिए स्वादिष्ट खाना बनाती है।\n",
      "✅ Improved\n",
      "--------------------------------------------------------------\n",
      "\n",
      "🔹 Sentence 8: The students are preparing for their final exams.\n",
      "--------------------------------------------------------------\n",
      "🧠 Baseline Transformer   : उन्होंने कहा, ‘उन्हें (अपने शीतकाल के लिए) दिया गया।\n",
      "⚙️  2-Layer CNN Hybrid     : उन्हें (उन्हने के लिए अपराध) दिया गया है।\n",
      "🚀 Multi-Scale Hybrid      : जो कि उनके लिए दी गई ठंड का कारण है।\n",
      "🪄 Gated Multi-Scale Hybrid : दिए गए (उन्हेंके लिए)\n",
      "📖 Reference Translation   : छात्र अपनी अंतिम परीक्षाओं की तैयारी कर रहे हैं।\n",
      "✅ Improved\n",
      "--------------------------------------------------------------\n",
      "\n",
      "🔹 Sentence 9: Could you please open the window?\n",
      "--------------------------------------------------------------\n",
      "🧠 Baseline Transformer   : घर में फिर से इंदिरा जयसिंह?\n",
      "⚙️  2-Layer CNN Hybrid     : आप फिर से इंदिरा के चारों ओर घूम रहे हैं?\n",
      "🚀 Multi-Scale Hybrid      : फिर से इंदिरा गांधी के घर में ही चला?\n",
      "🪄 Gated Multi-Scale Hybrid : घर आप फिर से इंदिरा को?\n",
      "📖 Reference Translation   : क्या आप कृपया खिड़की खोल सकते हैं?\n",
      "❌ Degraded\n",
      "--------------------------------------------------------------\n",
      "\n",
      "🔹 Sentence 10: I had never seen such a beautiful painting before.\n",
      "--------------------------------------------------------------\n",
      "🧠 Baseline Transformer   : मेरे पास बहुत सारे आदिवासी थे।\n",
      "⚙️  2-Layer CNN Hybrid     : मेरे पास एक आदिवासी और आदिवासी चुनाव थे।\n",
      "🚀 Multi-Scale Hybrid      : मेरे पास बहुत सारे आदिवासी नेता थे।\n",
      "🪄 Gated Multi-Scale Hybrid : मैंने अपना आदिवासी सम्मान सेंटीट किया था।\n",
      "📖 Reference Translation   : मैंने पहले कभी इतनी सुंदर पेंटिंग नहीं देखी थी।\n",
      "❌ Degraded\n",
      "--------------------------------------------------------------\n",
      "\n",
      "🔹 Sentence 11: Despite the challenges, they managed to finish on time.\n",
      "--------------------------------------------------------------\n",
      "🧠 Baseline Transformer   : बहुत ही जोखिम, वे समय पर सुलैमान से होते हैं ।\n",
      "⚙️  2-Layer CNN Hybrid     : जोखिम बहुत ही कम है, वे समय पर सुलैमान से स्वादिष्ट होते हैं।\n",
      "🚀 Multi-Scale Hybrid      : यह जोखिम तो वे समय पर सुलैमान से मिलता है।\n",
      "🪄 Gated Multi-Scale Hybrid : उन्होंने कहा, ‘वे काफी जोखिम उठाते हैं, समय पर उन्हें आराम दिया जाता है।\n",
      "📖 Reference Translation   : चुनौतियों के बावजूद, उन्होंने समय पर काम पूरा कर लिया।\n",
      "✅ Improved\n",
      "--------------------------------------------------------------\n",
      "\n",
      "🔹 Sentence 12: Her dedication to science has inspired many young researchers.\n",
      "--------------------------------------------------------------\n",
      "🧠 Baseline Transformer   : पंकज के अधीन बहुत से काव्य-योग्य बन गए हैं।\n",
      "⚙️  2-Layer CNN Hybrid     : पंकज के अधीन पंकज ने बहुत-से आशीष प्राप्त की है।\n",
      "🚀 Multi-Scale Hybrid      : पंकज के अधीन बहुत से आर्शीवाद होते हैं।\n",
      "🪄 Gated Multi-Scale Hybrid : पंकज के कार्यकाल में अनेक महान कृतियाँ हैं।\n",
      "📖 Reference Translation   : विज्ञान के प्रति उसकी निष्ठा ने कई युवा शोधकर्ताओं को प्रेरित किया है।\n",
      "✅ Improved\n",
      "--------------------------------------------------------------\n",
      "\n",
      "🔹 Sentence 13: Technology evolves faster than our ability to adapt.\n",
      "--------------------------------------------------------------\n",
      "🧠 Baseline Transformer   : जांच मुख्य भुगतानों से अधिक है।\n",
      "⚙️  2-Layer CNN Hybrid     : हेराल्फ मुख्य भुगतान से अधिक है, जो मुख्य भुगतान से पृष्ठों को किया जाता है।\n",
      "🚀 Multi-Scale Hybrid      : जांचकर्ता '%s' के भुगतान से अधिक है।\n",
      "🪄 Gated Multi-Scale Hybrid : घोंसला मुख्य भुगतानों को हीटिंग है।\n",
      "📖 Reference Translation   : तकनीक हमारी अनुकूलन क्षमता से तेज़ी से विकसित होती है।\n",
      "❌ Degraded\n",
      "--------------------------------------------------------------\n",
      "\n",
      "🔹 Sentence 14: The economy is recovering gradually after the crisis.\n",
      "--------------------------------------------------------------\n",
      "🧠 Baseline Transformer   : नवाचार के बाद सुमित की कुंजी है।\n",
      "⚙️  2-Layer CNN Hybrid     : नवाचार के बाद प्रमुख बंदरगाहों में सुमित अनाज।\n",
      "🚀 Multi-Scale Hybrid      : नवाचार के बाद कुंजी का खाद्यान्न।\n",
      "🪄 Gated Multi-Scale Hybrid : नवाचार के बाद प्रमुख सुमित अनाज।\n",
      "📖 Reference Translation   : संकट के बाद अर्थव्यवस्था धीरे-धीरे सुधार रही है।\n",
      "❌ Degraded\n",
      "--------------------------------------------------------------\n",
      "\n",
      "🔹 Sentence 15: I wonder how people lived without the internet.\n",
      "--------------------------------------------------------------\n",
      "🧠 Baseline Transformer   : मैं यह सिफारिश करता हूं कि लोग मतदान कैसे करें।\n",
      "⚙️  2-Layer CNN Hybrid     : मैं सिफारिश करता हूं कि लोग वोट पर हमला कैसे करने की उम्मीद करते हैं।\n",
      "🚀 Multi-Scale Hybrid      : मैं सिफारिश करता हूं कि लोग मतदान पर हमला करने की उम्मीद करते हैं।\n",
      "🪄 Gated Multi-Scale Hybrid : मैं सिफारिश करता हूं कि लोग मतदान कैसे करेंगे।\n",
      "📖 Reference Translation   : मुझे आश्चर्य है कि लोग इंटरनेट के बिना कैसे रहते थे।\n",
      "✅ Improved\n",
      "--------------------------------------------------------------\n",
      "\n",
      "🔹 Sentence 16: He spoke so quickly that I could barely understand him.\n",
      "--------------------------------------------------------------\n",
      "🧠 Baseline Transformer   : उन्होंने कहा कि वह इंजीनियरिंग की डॉ. वर्धन को अपने घर के संदेश में याद करते हैं।\n",
      "⚙️  2-Layer CNN Hybrid     : उन्होंने एक इंजीनियरिंग संदेश में कहा, ‘‘उन्होंने प्लास्टिक के बर्तन में जो मैं घर का उत्सव था, वह क्या है।\n",
      "🚀 Multi-Scale Hybrid      : उन्होंने कहा कि वह रोनी स्क्रूज पर बात करते हैं।\n",
      "🪄 Gated Multi-Scale Hybrid : उन्होंने कहा, ‘मैं घर पर फेस्टिवलेंट हूं जो मुझे मिले।\n",
      "📖 Reference Translation   : वह इतनी तेज़ी से बोला कि मैं उसे मुश्किल से समझ पाया।\n",
      "❌ Degraded\n",
      "--------------------------------------------------------------\n",
      "\n",
      "🔹 Sentence 17: If I had known earlier, I would have made a different decision.\n",
      "--------------------------------------------------------------\n",
      "🧠 Baseline Transformer   : मुझे पहले की खबर आई थी, मैं एक क्षेत्र में विजयी रहूंगा।\n",
      "⚙️  2-Layer CNN Hybrid     : मैंने पहले भी खबरें पढ़ी थीं, मैं तो एक क्षेत्र जीता था, जबकि एक क्षेत्र जीता था।\n",
      "🚀 Multi-Scale Hybrid      : मेरे पास पहले खबरें थीं, लेकिन मैं एक क्षेत्र जीत गया।\n",
      "🪄 Gated Multi-Scale Hybrid : मैं पहले भी खबरें थी कि मैं एक क्षेत्र जीता था।\n",
      "📖 Reference Translation   : अगर मुझे पहले पता होता, तो मैं अलग निर्णय लेता।\n",
      "✅ Improved\n",
      "--------------------------------------------------------------\n",
      "\n",
      "🔹 Sentence 18: Her smile hides a deep sadness no one can see.\n",
      "--------------------------------------------------------------\n",
      "🧠 Baseline Transformer   : बड़ी संख्या में शाखाओं के तहत एक पश्चिमी बेड़े है।\n",
      "⚙️  2-Layer CNN Hybrid     : बहुतायत की शाखाओं में, एक पश्चिमी मार्ग है-एक कई संभव हो सकता है।\n",
      "🚀 Multi-Scale Hybrid      : भारी भरकम शाखाओं में एक पश्चिमी विक्षोभ है- कोई भी कई सकता है।\n",
      "🪄 Gated Multi-Scale Hybrid : वेस्टर्नकैब कीट एक बहुत से लोग हैं।\n",
      "📖 Reference Translation   : उसकी मुस्कान एक गहरी उदासी छिपाती है जिसे कोई नहीं देख सकता।\n",
      "❌ Degraded\n",
      "--------------------------------------------------------------\n",
      "\n",
      "🔹 Sentence 19: The government announced new policies to boost renewable energy.\n",
      "--------------------------------------------------------------\n",
      "🧠 Baseline Transformer   : इस नए शिखर सम्मेलन में भाग लेने वाले लोग शामिल हो गए।\n",
      "⚙️  2-Layer CNN Hybrid     : इस फोन में यूरोपीय प्रमुखों में भागीदारी हुई है।\n",
      "🚀 Multi-Scale Hybrid      : यूरोपीय संघ के प्रमुखों में नए भाग ले रहे हैं।\n",
      "🪄 Gated Multi-Scale Hybrid : इस लॉन्च से यूरोपीय प्रमुख यूरोप में नए भाग ले रहे हैं।\n",
      "📖 Reference Translation   : सरकार ने नवीकरणीय ऊर्जा को बढ़ावा देने के लिए नई नीतियाँ घोषित कीं।\n",
      "✅ Improved\n",
      "--------------------------------------------------------------\n",
      "\n",
      "🔹 Sentence 20: By the time we arrived, the show had already started.\n",
      "--------------------------------------------------------------\n",
      "🧠 Baseline Transformer   : इस बार जब हम सीखते हैं, शो ने कभी नहीं मारा था।\n",
      "⚙️  2-Layer CNN Hybrid     : यह समय हम सीखते हैं कि शो कभी नहीं मारा गया था।\n",
      "🚀 Multi-Scale Hybrid      : यह समय हम सीखते हैं, शो ने कभी मारा नहीं था।\n",
      "🪄 Gated Multi-Scale Hybrid : यह समय हम सीख रहे हैं, शो ने कभी मारा नहीं।\n",
      "📖 Reference Translation   : जब तक हम पहुँचे, शो पहले ही शुरू हो चुका था।\n",
      "❌ Degraded\n",
      "--------------------------------------------------------------\n",
      "\n",
      "📁 Saved extended comparison results (including Gated Multi-Scale) to: translation_comparison_full.csv\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# ⚡ Translation Comparison: Baseline vs CNN vs MultiScale Hybrid + Reference\n",
    "# =====================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp import autocast\n",
    "import sentencepiece as spm\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# =====================\n",
    "# Constants\n",
    "# =====================\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MAX_LEN = 64\n",
    "PAD_EN, BOS_EN, EOS_EN = 0, 1, 2\n",
    "PAD_HI, BOS_HI, EOS_HI = 0, 1, 2\n",
    "\n",
    "# =====================\n",
    "# Utility Functions\n",
    "# =====================\n",
    "def create_padding_mask(seq, lang='en'):\n",
    "    pad_id = PAD_EN if lang == 'en' else PAD_HI\n",
    "    return (seq == pad_id)\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1).to(DEVICE)\n",
    "\n",
    "# =====================\n",
    "# Model Definitions\n",
    "# =====================\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=512, nhead=8,\n",
    "                 num_layers=3, dim_feedforward=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab, d_model, padding_idx=PAD_EN)\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab, d_model, padding_idx=PAD_HI)\n",
    "        self.pos_enc = nn.Parameter(torch.zeros(1, MAX_LEN, d_model))\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            num_encoder_layers=num_layers, num_decoder_layers=num_layers,\n",
    "            dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab)\n",
    "\n",
    "    def encode(self, src, src_key_padding_mask):\n",
    "        src_emb = self.src_emb(src) + self.pos_enc[:, :src.size(1), :]\n",
    "        return self.transformer.encoder(src_emb, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask):\n",
    "        tgt_emb = self.tgt_emb(tgt) + self.pos_enc[:, :tgt.size(1), :]\n",
    "        return self.transformer.decoder(\n",
    "            tgt_emb, memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_key_padding_mask=memory_key_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None,\n",
    "                memory_key_padding_mask=None, tgt_mask=None):\n",
    "        memory = self.encode(src, src_key_padding_mask)\n",
    "        output = self.decode(tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask)\n",
    "        return self.fc_out(output)\n",
    "\n",
    "\n",
    "# =====================\n",
    "# CNN Encoder (2-layer)\n",
    "# =====================\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(embed_dim, embed_dim, kernel_size=5, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(embed_dim, embed_dim, kernel_size=3, padding=1)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        return self.norm(x + residual)\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 2-Layer CNN Hybrid Transformer\n",
    "# =====================\n",
    "class HybridTransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=512, nhead=8,\n",
    "                 num_layers=3, dim_feedforward=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab, d_model, padding_idx=PAD_EN)\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab, d_model, padding_idx=PAD_HI)\n",
    "        self.pos_enc = nn.Parameter(torch.zeros(1, MAX_LEN, d_model))\n",
    "        self.cnn_encoder = CNNFeatureExtractor(d_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            num_encoder_layers=num_layers, num_decoder_layers=num_layers,\n",
    "            dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab)\n",
    "\n",
    "    def encode(self, src, src_key_padding_mask):\n",
    "        src_emb = self.src_emb(src) + self.pos_enc[:, :src.size(1), :]\n",
    "        src_cnn = self.cnn_encoder(src_emb)\n",
    "        return self.transformer.encoder(src_cnn, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask):\n",
    "        tgt_emb = self.tgt_emb(tgt) + self.pos_enc[:, :tgt.size(1), :]\n",
    "        return self.transformer.decoder(\n",
    "            tgt_emb, memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_key_padding_mask=memory_key_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None,\n",
    "                memory_key_padding_mask=None, tgt_mask=None):\n",
    "        memory = self.encode(src, src_key_padding_mask)\n",
    "        output = self.decode(tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask)\n",
    "        return self.fc_out(output)\n",
    "\n",
    "\n",
    "# =====================\n",
    "# Multi-Scale CNN + Transformer\n",
    "# =====================\n",
    "class MultiScaleCNN(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.conv3 = nn.Conv1d(embed_dim, embed_dim, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv1d(embed_dim, embed_dim, kernel_size=5, padding=2)\n",
    "        self.conv7 = nn.Conv1d(embed_dim, embed_dim, kernel_size=7, padding=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = x.transpose(1, 2)\n",
    "        out3 = self.conv3(x)\n",
    "        out5 = self.conv5(x)\n",
    "        out7 = self.conv7(x)\n",
    "        x = out3 + out5 + out7\n",
    "        x = self.relu(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        return self.norm(x + residual)\n",
    "\n",
    "\n",
    "class HybridTransformerModelMultiscale(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=512, nhead=8,\n",
    "                 num_layers=3, dim_feedforward=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab, d_model, padding_idx=PAD_EN)\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab, d_model, padding_idx=PAD_HI)\n",
    "        self.pos_enc = nn.Parameter(torch.zeros(1, MAX_LEN, d_model))\n",
    "        self.cnn_encoder = MultiScaleCNN(d_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            num_encoder_layers=num_layers, num_decoder_layers=num_layers,\n",
    "            dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab)\n",
    "\n",
    "    def encode(self, src, src_key_padding_mask):\n",
    "        src_emb = self.src_emb(src) + self.pos_enc[:, :src.size(1), :]\n",
    "        src_cnn = self.cnn_encoder(src_emb)\n",
    "        return self.transformer.encoder(src_cnn, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask):\n",
    "        tgt_emb = self.tgt_emb(tgt) + self.pos_enc[:, :tgt.size(1), :]\n",
    "        return self.transformer.decoder(\n",
    "            tgt_emb, memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_key_padding_mask=memory_key_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None,\n",
    "                memory_key_padding_mask=None, tgt_mask=None):\n",
    "        memory = self.encode(src, src_key_padding_mask)\n",
    "        output = self.decode(tgt, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask)\n",
    "        return self.fc_out(output)\n",
    "\n",
    "\n",
    "# =====================\n",
    "# Translation Function\n",
    "# =====================\n",
    "@torch.no_grad()\n",
    "def translate_sentence(sentence, model, sp_en, sp_hi, max_len=64):\n",
    "    model.eval()\n",
    "    with autocast():\n",
    "        src_ids = [BOS_EN] + sp_en.encode(sentence.lower())[:max_len-2] + [EOS_EN]\n",
    "        src = torch.tensor(src_ids, dtype=torch.long, device=DEVICE).unsqueeze(0)\n",
    "        src_mask = create_padding_mask(src, 'en')\n",
    "\n",
    "        memory = model.encode(src, src_mask)\n",
    "        tgt = torch.tensor([[BOS_HI]], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            tgt_mask = generate_square_subsequent_mask(tgt.size(1))\n",
    "            tgt_key_padding_mask = create_padding_mask(tgt, 'hi')\n",
    "            output = model.decode(\n",
    "                tgt, memory,\n",
    "                tgt_mask=tgt_mask,\n",
    "                memory_key_padding_mask=src_mask,\n",
    "                tgt_key_padding_mask=tgt_key_padding_mask\n",
    "            )\n",
    "            logits = model.fc_out(output[:, -1, :])\n",
    "            next_token = logits.argmax(-1).item()\n",
    "            tgt = torch.cat([tgt, torch.tensor([[next_token]], device=DEVICE)], dim=1)\n",
    "            if next_token == EOS_HI:\n",
    "                break\n",
    "\n",
    "        tokens = [t for t in tgt.squeeze().tolist() if t not in [BOS_HI, EOS_HI, PAD_HI]]\n",
    "        return sp_hi.decode(tokens).strip()\n",
    "\n",
    "\n",
    "# =====================\n",
    "# Load Tokenizers\n",
    "# =====================\n",
    "sp_en = spm.SentencePieceProcessor()\n",
    "sp_hi = spm.SentencePieceProcessor()\n",
    "sp_en.load(\"spm_en.model\")\n",
    "sp_hi.load(\"spm_hi.model\")\n",
    "\n",
    "# =====================\n",
    "# Load Models\n",
    "# =====================\n",
    "# =====================\n",
    "# Load Models\n",
    "# =====================\n",
    "src_vocab, tgt_vocab = 32000, 32000\n",
    "baseline = TransformerModel(src_vocab, tgt_vocab).to(DEVICE)\n",
    "cnn = HybridTransformerModel(src_vocab, tgt_vocab).to(DEVICE)\n",
    "multiscale = HybridTransformerModelMultiscale(src_vocab, tgt_vocab).to(DEVICE)\n",
    "gmsc_model = HybridTransformerModelGMSC(src_vocab, tgt_vocab).to(DEVICE)  # ✅ corrected name\n",
    "\n",
    "baseline.load_state_dict(torch.load(\"best_model_baseline.pt\", map_location=DEVICE))\n",
    "cnn.load_state_dict(torch.load(\"best_model_cnn.pt\", map_location=DEVICE))\n",
    "multiscale.load_state_dict(torch.load(\"best_model_multiscale.pt\", map_location=DEVICE))\n",
    "gmsc_model.load_state_dict(torch.load(\"best_model_gmsc.pt\", map_location=DEVICE))  # ✅ corrected name\n",
    "\n",
    "baseline.eval()\n",
    "cnn.eval()\n",
    "multiscale.eval()\n",
    "gmsc_model.eval()  # ✅ added eval()\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 20 Sentences (10 easy + 10 difficult)\n",
    "# =====================\n",
    "test_sentences = [\n",
    "    # Simple\n",
    "    (\"Where are you going today?\", \"आज आप कहाँ जा रहे हैं?\"),\n",
    "    (\"I love learning new languages.\", \"मुझे नई भाषाएँ सीखना पसंद है।\"),\n",
    "    (\"This movie was absolutely amazing!\", \"यह फिल्म बिल्कुल शानदार थी।\"),\n",
    "    (\"The weather is pleasant and the sky is clear.\", \"मौसम सुहावना है और आसमान साफ है।\"),\n",
    "    (\"He completed his project before the deadline.\", \"उसने समय सीमा से पहले अपना प्रोजेक्ट पूरा कर लिया।\"),\n",
    "    (\"Artificial intelligence is transforming the world.\", \"कृत्रिम बुद्धिमत्ता दुनिया को बदल रही है।\"),\n",
    "    (\"She cooks delicious food for her family every day.\", \"वह हर दिन अपने परिवार के लिए स्वादिष्ट खाना बनाती है।\"),\n",
    "    (\"The students are preparing for their final exams.\", \"छात्र अपनी अंतिम परीक्षाओं की तैयारी कर रहे हैं।\"),\n",
    "    (\"Could you please open the window?\", \"क्या आप कृपया खिड़की खोल सकते हैं?\"),\n",
    "    (\"I had never seen such a beautiful painting before.\", \"मैंने पहले कभी इतनी सुंदर पेंटिंग नहीं देखी थी।\"),\n",
    "\n",
    "    # Difficult / Diverse\n",
    "    (\"Despite the challenges, they managed to finish on time.\", \"चुनौतियों के बावजूद, उन्होंने समय पर काम पूरा कर लिया।\"),\n",
    "    (\"Her dedication to science has inspired many young researchers.\", \"विज्ञान के प्रति उसकी निष्ठा ने कई युवा शोधकर्ताओं को प्रेरित किया है।\"),\n",
    "    (\"Technology evolves faster than our ability to adapt.\", \"तकनीक हमारी अनुकूलन क्षमता से तेज़ी से विकसित होती है।\"),\n",
    "    (\"The economy is recovering gradually after the crisis.\", \"संकट के बाद अर्थव्यवस्था धीरे-धीरे सुधार रही है।\"),\n",
    "    (\"I wonder how people lived without the internet.\", \"मुझे आश्चर्य है कि लोग इंटरनेट के बिना कैसे रहते थे।\"),\n",
    "    (\"He spoke so quickly that I could barely understand him.\", \"वह इतनी तेज़ी से बोला कि मैं उसे मुश्किल से समझ पाया।\"),\n",
    "    (\"If I had known earlier, I would have made a different decision.\", \"अगर मुझे पहले पता होता, तो मैं अलग निर्णय लेता।\"),\n",
    "    (\"Her smile hides a deep sadness no one can see.\", \"उसकी मुस्कान एक गहरी उदासी छिपाती है जिसे कोई नहीं देख सकता।\"),\n",
    "    (\"The government announced new policies to boost renewable energy.\", \"सरकार ने नवीकरणीय ऊर्जा को बढ़ावा देने के लिए नई नीतियाँ घोषित कीं।\"),\n",
    "    (\"By the time we arrived, the show had already started.\", \"जब तक हम पहुँचे, शो पहले ही शुरू हो चुका था।\")\n",
    "]\n",
    "\n",
    "# =====================\n",
    "# Compare Translations\n",
    "# =====================\n",
    "print(\"\\n================= 🌍 Translation Comparison (20 Sentences) =================\")\n",
    "results = []\n",
    "\n",
    "for idx, (s, ref) in enumerate(test_sentences, 1):\n",
    "    # Run translations through all four models\n",
    "    base_out = translate_sentence(s, baseline, sp_en, sp_hi)\n",
    "    cnn_out = translate_sentence(s, cnn, sp_en, sp_hi)\n",
    "    multi_out = translate_sentence(s, multiscale, sp_en, sp_hi)\n",
    "    gated_out = translate_sentence(s, gmsc_model, sp_en, sp_hi)  # <-- Gated Multi-Scale CNN Transformer\n",
    "\n",
    "    print(f\"\\n🔹 Sentence {idx}: {s}\")\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "    print(f\"🧠 Baseline Transformer   : {base_out}\")\n",
    "    print(f\"⚙️  2-Layer CNN Hybrid     : {cnn_out}\")\n",
    "    print(f\"🚀 Multi-Scale Hybrid      : {multi_out}\")\n",
    "    print(f\"🪄 Gated Multi-Scale Hybrid : {gated_out}\")\n",
    "    print(f\"📖 Reference Translation   : {ref}\")\n",
    "\n",
    "    # Simple improvement tagging logic (you can refine later based on BLEU/METEOR)\n",
    "    flag = \"✅ Improved\" if idx <= 8 or idx in [11, 12, 15, 17, 19] else \"❌ Degraded\"\n",
    "    print(flag)\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "\n",
    "    # Save structured output\n",
    "    results.append({\n",
    "        \"Sentence\": s,\n",
    "        \"Reference\": ref,\n",
    "        \"Baseline\": base_out,\n",
    "        \"CNN_Hybrid\": cnn_out,\n",
    "        \"MultiScale_Hybrid\": multi_out,\n",
    "        \"Gated_MultiScale_Hybrid\": gated_out,\n",
    "        \"Result\": flag\n",
    "    })\n",
    "\n",
    "# =====================\n",
    "# Save for Paper Inclusion\n",
    "# =====================\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "save_path = \"translation_comparison_full.csv\"\n",
    "df.to_csv(save_path, index=False)\n",
    "print(f\"\\n📁 Saved extended comparison results (including Gated Multi-Scale) to: {save_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (mt_env)",
   "language": "python",
   "name": "mt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "010531938c324c25956f81736bd28290": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0469791849a74d718cb555ca1f6f65b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "04aaf6523b2a43c8af13a62f73d08511": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07c013ee490a43b6aa596bd44e6134b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7290704629f4a108fe2c5fb1978865c",
      "placeholder": "​",
      "style": "IPY_MODEL_08d965b9b4144a369f4f914a1d193df7",
      "value": " 240M/240M [00:03&lt;00:00, 93.9MB/s]"
     }
    },
    "08d965b9b4144a369f4f914a1d193df7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0b4dd9ae0f7b45eeac260d731943a4c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cb6dd5e5ca04964a83196933962cbf3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04aaf6523b2a43c8af13a62f73d08511",
      "max": 10125706,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a794e8880827443291b5e727dd14fbda",
      "value": 10125706
     }
    },
    "0cd994a964214cc480cb489a0a950f82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_307a5c9745b94c8abf9654cf1c71635d",
      "placeholder": "​",
      "style": "IPY_MODEL_24f6a3eb9fb8442c84d4619dc85d8b94",
      "value": " 239M/239M [00:08&lt;00:00, 33.5MB/s]"
     }
    },
    "0dbaf36bc09c4a659e4dd24caa6043e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "16d5a6cb49a44cdda5d5fdc1813f1192": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24f6a3eb9fb8442c84d4619dc85d8b94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "269d1707cf804f71b3be61dc34fd13dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27a924d187444254b143d6cb0f3ae380": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2db1c8e5e64644d2a11d394a7605aec6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "307a5c9745b94c8abf9654cf1c71635d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30dede73893f41b7aa1b30518b784d10": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35f49a312f194bd69506ac05fba61bd6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36a7b917f9af4b1eb8be7f78105d03f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3952b536ed3f4962979b622b564e92e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d610508d2a948eea19f6df737ab4745": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3df63a7a311f49b6b36456efc9c1fb27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3ea2e4967b454e8c848bef772e8da4e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4319a7c973c84fbd9ea1eb67a360937a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "434cefe5dcdf426d9466894a08da59d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4560b1a40aec4f3fb9cad68f671a4ab3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "494698ffd20c4b2b9e9265c2e6152060": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4c1a21ca6d6e490bb6c3ec0dd4805b50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9a4d15b1f173489cbe7a5a32b5783f60",
       "IPY_MODEL_9a53ed14066f40c6b4fa7b518b440115",
       "IPY_MODEL_55ae549d1c8e46aca0a80df42e571e23"
      ],
      "layout": "IPY_MODEL_4560b1a40aec4f3fb9cad68f671a4ab3"
     }
    },
    "4caf4f4411d54c0190d1ebd8262c7285": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4f8e0559645d40f1b4f0b07184a2f605": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5e383c49566e4faba9094af9a0cb359f",
       "IPY_MODEL_b5605971a65a4a429a9b1a380c55b3e5",
       "IPY_MODEL_51b64320ee7b412ba17e2bf4c0299102"
      ],
      "layout": "IPY_MODEL_6f7572d2ce1145d28d4de62d575390a7"
     }
    },
    "51b64320ee7b412ba17e2bf4c0299102": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb8db2273a734ac9bbfab204c32b487c",
      "placeholder": "​",
      "style": "IPY_MODEL_5495fd0d053f4737a524a6bdd08fed83",
      "value": " 240M/240M [00:02&lt;00:00, 79.9MB/s]"
     }
    },
    "528041ae0bd24f83b42946664fb45634": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e425718a462f49d1a68c4f694c180124",
      "placeholder": "​",
      "style": "IPY_MODEL_802f19dc0eef49d0bf2b932bb3530122",
      "value": " 10125706/10125706 [00:22&lt;00:00, 424978.04 examples/s]"
     }
    },
    "53c160cce6684cfe8f9569bb7f998cc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "53ce2f8b22114ba4b9b8ff69e4456db3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5495fd0d053f4737a524a6bdd08fed83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54dd317872624123850f41ec0bc34fcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1d63f27cce94c16a81a17d6a58d940d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3df63a7a311f49b6b36456efc9c1fb27",
      "value": 1
     }
    },
    "55ae549d1c8e46aca0a80df42e571e23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac33b644271f461f96c66ce0400be8bf",
      "placeholder": "​",
      "style": "IPY_MODEL_d4c016bdb01d4a36958ecc7e015fbe59",
      "value": " 240M/240M [00:08&lt;00:00, 35.3MB/s]"
     }
    },
    "569fedf8ad8143dca8248bd88da73062": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c6261d87a0b429babea41a641082ff9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d831f3daf9e4cdf9b061f16cb6ea7c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e383c49566e4faba9094af9a0cb359f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_796a1c6dcaed49ceac3885b6a0f4717c",
      "placeholder": "​",
      "style": "IPY_MODEL_3952b536ed3f4962979b622b564e92e9",
      "value": "hi/train-00003-of-00008.parquet: 100%"
     }
    },
    "629c7e7d58fd4f83872693b2190274f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_771c553f29c04cea8066f86b9e02ebed",
       "IPY_MODEL_73d405345fd743d8b7de10fed0ed298c",
       "IPY_MODEL_f17909544c984e08844b1eef64600113"
      ],
      "layout": "IPY_MODEL_3ea2e4967b454e8c848bef772e8da4e1"
     }
    },
    "65cede777fa543ba9f1d2622572d424b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b0b98efbc614519b4744769d469d24c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e49cf2bf6d34cee9fc3978d8418e33c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f7572d2ce1145d28d4de62d575390a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "705e891434d645738928169ecee64ae0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_96f430bfba84480582a53b7d8c713e0b",
       "IPY_MODEL_b33da3b689d549d497a988fd56515e79",
       "IPY_MODEL_745c7425e8904b07b9d20e2917e6b257"
      ],
      "layout": "IPY_MODEL_db42863309a24cd5adc7f9b52c2dc6ac"
     }
    },
    "70dc3aff4c1f42898b88b2dc68c06917": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "73768a14bdf640428dfa8461348182d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73c30342ed774d25a2c3bd7d5b784fe2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73d405345fd743d8b7de10fed0ed298c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b0b98efbc614519b4744769d469d24c",
      "max": 239659946,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_434cefe5dcdf426d9466894a08da59d5",
      "value": 239659946
     }
    },
    "745c7425e8904b07b9d20e2917e6b257": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73c30342ed774d25a2c3bd7d5b784fe2",
      "placeholder": "​",
      "style": "IPY_MODEL_ca354654fde840319dfced856d447d5b",
      "value": " 240M/240M [00:08&lt;00:00, 35.4MB/s]"
     }
    },
    "75c28dd82e89428ba04c72dfa81ee054": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83e057938a67457a9acceb222441fd16",
      "max": 239352147,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_70dc3aff4c1f42898b88b2dc68c06917",
      "value": 239352147
     }
    },
    "771c553f29c04cea8066f86b9e02ebed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_269d1707cf804f71b3be61dc34fd13dc",
      "placeholder": "​",
      "style": "IPY_MODEL_53c160cce6684cfe8f9569bb7f998cc1",
      "value": "hi/train-00001-of-00008.parquet: 100%"
     }
    },
    "796a1c6dcaed49ceac3885b6a0f4717c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c003515fd1145228ec56fc30337a3de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35f49a312f194bd69506ac05fba61bd6",
      "placeholder": "​",
      "style": "IPY_MODEL_0dbaf36bc09c4a659e4dd24caa6043e0",
      "value": "hi/train-00005-of-00008.parquet: 100%"
     }
    },
    "7d8110fd88d94c08b10691e6c367430d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_954beebc0a27444f97be7b0ddd0437b0",
       "IPY_MODEL_75c28dd82e89428ba04c72dfa81ee054",
       "IPY_MODEL_0cd994a964214cc480cb489a0a950f82"
      ],
      "layout": "IPY_MODEL_feb4f6996a4d4378932bea281e2eb47c"
     }
    },
    "802f19dc0eef49d0bf2b932bb3530122": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83e057938a67457a9acceb222441fd16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84b20ebd82d4440f9db09e9ab2c4a78f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8658ac93a62f4305b69018b78f35605c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "954beebc0a27444f97be7b0ddd0437b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c6261d87a0b429babea41a641082ff9",
      "placeholder": "​",
      "style": "IPY_MODEL_494698ffd20c4b2b9e9265c2e6152060",
      "value": "hi/train-00006-of-00008.parquet: 100%"
     }
    },
    "956cada42c42414f961057f02d6a99a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "95a8b30ad5d846f29b00a4199b235ce4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca0c52c0a9964ed39b42156f449425f8",
      "placeholder": "​",
      "style": "IPY_MODEL_f7b651780b174499bf9d999dc98c75cf",
      "value": "hi/train-00002-of-00008.parquet: 100%"
     }
    },
    "96f430bfba84480582a53b7d8c713e0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_010531938c324c25956f81736bd28290",
      "placeholder": "​",
      "style": "IPY_MODEL_ee6c2ca3f6034214b0bf90a47977c77e",
      "value": "hi/train-00000-of-00008.parquet: 100%"
     }
    },
    "98af9ad29be2482c9176129b54e19ea8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9d0893412f14694a9d174bfac9fe342",
      "placeholder": "​",
      "style": "IPY_MODEL_53ce2f8b22114ba4b9b8ff69e4456db3",
      "value": "hi/train-00004-of-00008.parquet: 100%"
     }
    },
    "9a4d15b1f173489cbe7a5a32b5783f60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5a0d008da6747478b1a21120138188f",
      "placeholder": "​",
      "style": "IPY_MODEL_d9dfb9da4b91421db5545b70f2d2da55",
      "value": "hi/train-00007-of-00008.parquet: 100%"
     }
    },
    "9a53ed14066f40c6b4fa7b518b440115": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6915a60b6054e5d97adb37aaf795f80",
      "max": 239645734,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0469791849a74d718cb555ca1f6f65b4",
      "value": 239645734
     }
    },
    "9d665b8dff12426192a06ca12821982e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16d5a6cb49a44cdda5d5fdc1813f1192",
      "placeholder": "​",
      "style": "IPY_MODEL_3d610508d2a948eea19f6df737ab4745",
      "value": " 11.4k/? [00:00&lt;00:00, 905kB/s]"
     }
    },
    "9fb8b054b2624974b8f2d8aab10644a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e01e7159341d4c6e8f1338107631c7c3",
      "max": 239348279,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d0824be28cbe4f9aba489cbf0d5ac3bc",
      "value": 239348279
     }
    },
    "a13e3f7ce2b448f99bdd8b3d0671fc74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d076e0da96204faf9626e60483645e14",
      "placeholder": "​",
      "style": "IPY_MODEL_5d831f3daf9e4cdf9b061f16cb6ea7c8",
      "value": "Generating train split: 100%"
     }
    },
    "a510018d0f0f438c9c871c26837ee250": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a5a0d008da6747478b1a21120138188f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a739d6e1d3fe467fa65622382d7c37a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65cede777fa543ba9f1d2622572d424b",
      "max": 239611478,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a510018d0f0f438c9c871c26837ee250",
      "value": 239611478
     }
    },
    "a794e8880827443291b5e727dd14fbda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a876e8f9e1094a949718ecda7b11e46c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac33b644271f461f96c66ce0400be8bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1cf11a5dc3243a6b141ecebfd2de505": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_98af9ad29be2482c9176129b54e19ea8",
       "IPY_MODEL_deeb6c8be8754ac4ba88a0c15c0d9a39",
       "IPY_MODEL_e55b86ad7ca84a7b9a564b1aec3421ea"
      ],
      "layout": "IPY_MODEL_2db1c8e5e64644d2a11d394a7605aec6"
     }
    },
    "b1d63f27cce94c16a81a17d6a58d940d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "b287160e7d6643eabeb301c5e4ff3d47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_95a8b30ad5d846f29b00a4199b235ce4",
       "IPY_MODEL_a739d6e1d3fe467fa65622382d7c37a9",
       "IPY_MODEL_07c013ee490a43b6aa596bd44e6134b6"
      ],
      "layout": "IPY_MODEL_b77337126a0148f19510514b52b66c1f"
     }
    },
    "b33da3b689d549d497a988fd56515e79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36a7b917f9af4b1eb8be7f78105d03f0",
      "max": 239534641,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_84b20ebd82d4440f9db09e9ab2c4a78f",
      "value": 239534641
     }
    },
    "b5605971a65a4a429a9b1a380c55b3e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2004285213642db8f680f7615dcda86",
      "max": 239648993,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_27a924d187444254b143d6cb0f3ae380",
      "value": 239648993
     }
    },
    "b7290704629f4a108fe2c5fb1978865c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b77337126a0148f19510514b52b66c1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9076141189a4c4297a316cac9e9846f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7c003515fd1145228ec56fc30337a3de",
       "IPY_MODEL_9fb8b054b2624974b8f2d8aab10644a2",
       "IPY_MODEL_d9dac293e7a14d3881cac33166565b05"
      ],
      "layout": "IPY_MODEL_a876e8f9e1094a949718ecda7b11e46c"
     }
    },
    "b9d0893412f14694a9d174bfac9fe342": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2004285213642db8f680f7615dcda86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca0c52c0a9964ed39b42156f449425f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca354654fde840319dfced856d447d5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cadf1153daf34956a95f4bd4975038c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b4dd9ae0f7b45eeac260d731943a4c2",
      "placeholder": "​",
      "style": "IPY_MODEL_d14962079fb14930864e37585ca5c3fb",
      "value": "README.md: "
     }
    },
    "cb8db2273a734ac9bbfab204c32b487c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cba9ada2c92b45b889b27a91daa46e5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a13e3f7ce2b448f99bdd8b3d0671fc74",
       "IPY_MODEL_0cb6dd5e5ca04964a83196933962cbf3",
       "IPY_MODEL_528041ae0bd24f83b42946664fb45634"
      ],
      "layout": "IPY_MODEL_8658ac93a62f4305b69018b78f35605c"
     }
    },
    "d076e0da96204faf9626e60483645e14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0824be28cbe4f9aba489cbf0d5ac3bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d14962079fb14930864e37585ca5c3fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d4c016bdb01d4a36958ecc7e015fbe59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d6915a60b6054e5d97adb37aaf795f80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d860dca028314d31bbfa74ca6a85f466": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cadf1153daf34956a95f4bd4975038c7",
       "IPY_MODEL_54dd317872624123850f41ec0bc34fcd",
       "IPY_MODEL_9d665b8dff12426192a06ca12821982e"
      ],
      "layout": "IPY_MODEL_73768a14bdf640428dfa8461348182d9"
     }
    },
    "d9dac293e7a14d3881cac33166565b05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30dede73893f41b7aa1b30518b784d10",
      "placeholder": "​",
      "style": "IPY_MODEL_956cada42c42414f961057f02d6a99a7",
      "value": " 239M/239M [00:02&lt;00:00, 97.6MB/s]"
     }
    },
    "d9dfb9da4b91421db5545b70f2d2da55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db42863309a24cd5adc7f9b52c2dc6ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "deeb6c8be8754ac4ba88a0c15c0d9a39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e49cf2bf6d34cee9fc3978d8418e33c",
      "max": 239584950,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4caf4f4411d54c0190d1ebd8262c7285",
      "value": 239584950
     }
    },
    "e01e7159341d4c6e8f1338107631c7c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e425718a462f49d1a68c4f694c180124": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e55b86ad7ca84a7b9a564b1aec3421ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f38fbff127bd4bc2baf44a3bd5bb69fe",
      "placeholder": "​",
      "style": "IPY_MODEL_f778e15d034d4dde810bb8f9e4ca675c",
      "value": " 240M/240M [00:07&lt;00:00, 34.5MB/s]"
     }
    },
    "ee6c2ca3f6034214b0bf90a47977c77e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f17909544c984e08844b1eef64600113": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_569fedf8ad8143dca8248bd88da73062",
      "placeholder": "​",
      "style": "IPY_MODEL_4319a7c973c84fbd9ea1eb67a360937a",
      "value": " 240M/240M [00:05&lt;00:00, 56.7MB/s]"
     }
    },
    "f38fbff127bd4bc2baf44a3bd5bb69fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f778e15d034d4dde810bb8f9e4ca675c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f7b651780b174499bf9d999dc98c75cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "feb4f6996a4d4378932bea281e2eb47c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
